# üî¨ Scientific LLM Benchmark Full Report (December 2025)

## 1. Executive Summary
–≠—Ç–æ—Ç –æ—Ç—á–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ SOTA –º–æ–¥–µ–ª–µ–π (GPT-5.2, Llama 4, Mistral Large 3, Qwen 3 Max, Gemini 3 Flash).

## 2. Methodology & Parameters
| Parameter | Value |
| :--- | :--- |
| **Judge Model** | Gemini 2.5 Pro Preview (OpenRouter) |
| **Iterations** | 15 per each (Lang x Level x Task Type) |
| **Temperature** | 0.8 (Testing stability) |
| **Metrics** | Mean Score, Standard Deviation (Stability), Latency |

## 3. Global Leaderboard
| Model           |   Mean Score |   Stability (Std Dev) |   Avg Latency (s) |
|:----------------|-------------:|----------------------:|------------------:|
| Gemini 3 Flash  |         8.33 |                  2.36 |              3.68 |
| GPT-5.2         |         8.07 |                  2.03 |              9.75 |
| Qwen 3 Max      |         7.18 |                  2.75 |              4.09 |
| Mistral Large 3 |         6.09 |                  2.57 |              2.18 |
| Llama 4         |         5.35 |                  3.22 |              1.23 |

## 4. Performance Heatmap (Scores)
|                   |   GPT-5.2 |   Gemini 3 Flash |   Llama 4 |   Mistral Large 3 |   Qwen 3 Max |
|:------------------|----------:|-----------------:|----------:|------------------:|-------------:|
| ('English', 'B2') |      7.93 |             7.57 |      5.17 |              6.97 |         6.57 |
| ('Polish', 'A1')  |      9.00 |             9.03 |      5.83 |              7.00 |         6.87 |
| ('Polish', 'B2')  |      8.07 |             8.33 |      4.97 |              6.27 |         7.50 |
| ('Russian', 'A1') |      7.23 |             7.63 |      4.77 |              4.27 |         7.40 |
| ('Russian', 'B2') |      8.10 |             9.07 |      6.00 |              5.97 |         7.57 |

## 5. Full Audit Log
–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–Ω–æ–º–∞–ª–∏–π.

### üåê Language: ENGLISH | Level: B2
|   iteration | model           | task_type       |   score |   latency | reason                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|------------:|:----------------|:----------------|--------:|----------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|           1 | GPT-5.2         | Multiple Choice |       8 |     19.2  | The task is excellent and accurately targets the B2 level. It tests the use of a present participle clause ('citing') to give a reason, which is a sophisticated structure relevant to the writing skills described. The distractors are well-chosen and test understanding of conjunctions and linking words. The only minor flaw is that the 'correctAnswer' field is a string instead of an array, which misinterprets a slightly ambiguous instruction.                                                                                   |
|           1 | GPT-5.2         | Fill Blank      |       8 |     10.27 | The candidate created a high-quality B2 grammar task testing the distinction between prepositions ('despite') and conjunctions ('even though'). The sentence is natural and the context is appropriate. The primary weakness is that the answer is not strictly unique, as 'In spite of' is also a valid answer, which goes against the prompt's guideline for a deterministic answer. However, the task itself is well-conceived and targets a key B2 skill.                                                                                 |
|           1 | Gemini 3 Flash  | Multiple Choice |       9 |      1.23 | An excellent and challenging task that is well-suited for the B2/C1 level. It tests knowledge of formal vocabulary (the phrasal verb 'adhere to') in a professional context. It also implicitly tests the subjunctive mood ('insisted that the team adhere...'), a key feature of more advanced grammar. This aligns well with writing formal reports. The only minor issue is the 'correctAnswer' format being a string instead of an array.                                                                                                 |
|           1 | Gemini 3 Flash  | Fill Blank      |       6 |      1.12 | The vocabulary word 'justification' and the formal context are well-suited for the B2 level. However, the task's effectiveness is severely diminished because the hint '(justification)' is the answer itself. Additionally, the answer is not deterministic, as both 'reason' and 'explanation' are also perfectly suitable answers.                                                                                                                                                                                                         |
|           1 | Llama 4         | Multiple Choice |       6 |      0.39 | The task is grammatically correct and clearly constructed, but the skill it tests‚Äîusing the present simple for a general truth‚Äîis more characteristic of the B1 level. A B2 learner would be expected to have mastered this point. While the sentence context is pleasant, the task does not sufficiently challenge a B2 student or align with the complexity described in the proficiency level.                                                                                                                                             |
|           1 | Llama 4         | Fill Blank      |       7 |      0.66 | This is an excellent grammar task that tests the past perfect continuous, a core B2-level tense, in a well-constructed sentence that makes the answer highly deterministic. The quality of the linguistic task is very high. However, it completely fails to follow the instruction to include a hint for the missing word in parentheses, which is a significant omission.                                                                                                                                                                   |
|           1 | Mistral Large 3 | Multiple Choice |       9 |      2.15 | This is an outstanding B2/C1 level task. It tests a nuanced grammatical point: the use of the perfect participle ('having been stuck') to sequence past events clearly. This is a key skill for creating detailed narratives, aligning perfectly with the proficiency description. The distractors are grammatically relevant, and the task correctly follows all formatting guidelines, including the array format for 'correctAnswer'.                                                                                                      |
|           1 | Mistral Large 3 | Fill Blank      |       5 |      1.44 | The task correctly identifies a B2-level phrasal verb ('go ahead with'). However, it fails on two key points: 1) The hint '(go ahead)' is the answer itself, making the task trivial. 2) The answer is not unique; 'proceed' is also a valid and common alternative. This undermines the task's utility as an assessment.                                                                                                                                                                                                                     |
|           1 | Qwen 3 Max      | Multiple Choice |       7 |      8.56 | A solid B2 task focusing on vocabulary precision and collocation ('disappoint their fans'). The sentence structure is appropriate for the level, using a concessive clause ('Despite...') and a relative clause. However, the vocabulary itself is fairly common, making the task slightly less challenging than other candidates. The 'correctAnswer' format is a string, not an array.                                                                                                                                                      |
|           1 | Qwen 3 Max      | Fill Blank      |       4 |      2.22 | This submission has several flaws. The vocabulary word 'attend' is closer to a B1 level than B2. Similar to other candidates, it provides the answer as the hint, which removes any challenge. Furthermore, the answer is not unique ('go to' is a common alternative), violating a key instruction.                                                                                                                                                                                                                                          |
|           2 | GPT-5.2         | Multiple Choice |       8 |      8.48 | This is a strong B2 vocabulary task. The context of writing a report directly aligns with the proficiency description. The options test for precise word choice ('allows' vs. 'persuades'), which is appropriate for the level. The only minor issue is the `correctAnswer` format, which the instructions ambiguously specified as an array.                                                                                                                                                                                                 |
|           2 | GPT-5.2         | Fill Blank      |       8 |     11.01 | The task correctly identifies a key B2 grammar point (the third conditional). The JSON is valid. However, it fails on the 'only one correct answer' constraint. While 'had known' is a good answer, other options like 'had been informed' or 'had been told' are also grammatically and semantically correct in this context but were not included in the `correctAnswer` array.                                                                                                                                                             |
|           2 | Gemini 3 Flash  | Multiple Choice |       9 |      1.29 | An excellent B2-level task that tests nuanced vocabulary and collocation ('hindered by'). The context, an analyst's report, is perfectly aligned with the target proficiency description. The task is clear, deterministic, and all options are plausible. It's a very strong submission, only slightly behind the top candidate due to a minor formatting interpretation.                                                                                                                                                                    |
|           2 | Gemini 3 Flash  | Fill Blank      |       9 |      1.21 | This is a very strong B2-level vocabulary task. The formal context (committee, proposal, opposition) and the target word ('proceed') are perfectly aligned with the B2 proficiency description. The task is well-constructed, and like Candidate 2, it rightly uses the parenthetical hint to guarantee a single, deterministic answer.                                                                                                                                                                                                       |
|           2 | Llama 4         | Multiple Choice |      10 |      1.41 | This is an excellent candidate that meets all criteria perfectly. It tests a subtle but important B2-level grammar point: using the simple present tense ('filters') to describe a general truth within a past narrative context. The context is appropriate, the options are good distractors, and it uniquely followed the ambiguous instruction to format the `correctAnswer` as an array.                                                                                                                                                 |
|           2 | Llama 4         | Fill Blank      |      10 |      2.43 | This is an outstanding B2-level task. It perfectly targets a key grammatical structure for this level: the past perfect continuous. The sentence context ('By the time I arrived...') makes the required tense form unambiguous, leading to a single correct answer. This is an excellent example of a well-designed, deterministic grammar question.                                                                                                                                                                                         |
|           2 | Mistral Large 3 | Multiple Choice |       6 |      1.66 | The task tests participial clauses, a valid B2 grammar point. However, it violates guideline #8 by not being deterministic. Both 'reviewing' and 'having reviewed' are grammatically correct options in this context, creating ambiguity and allowing for multiple correct interpretations, which is a significant flaw in a multiple-choice question.                                                                                                                                                                                        |
|           2 | Mistral Large 3 | Fill Blank      |       9 |      1.53 | This is a strong B2-level task. It tests a common three-part phrasal verb ('go ahead with') within a natural sentence structure using 'Despite...'. The use of the hint in parentheses is a clever and standard testing method to ensure a single correct answer, fully complying with the instructions. The format is perfect.                                                                                                                                                                                                               |
|           2 | Qwen 3 Max      | Multiple Choice |       7 |      3.65 | The task is grammatically correct and deterministic. However, the grammatical point being tested (verb pattern 'insist on' + gerund) is more characteristic of a B1 level. While a B2 learner should know this, it doesn't effectively challenge them or align with the higher-level skills described in the B2 profile.                                                                                                                                                                                                                      |
|           2 | Qwen 3 Max      | Fill Blank      |       6 |      3.15 | The JSON format is correct and the sentence is well-formed. However, the task's difficulty is not appropriate for the B2 level. The target vocabulary word, 'attend', is typically mastered at the B1 level. The task does not effectively test a key B2 skill as required by the instructions.                                                                                                                                                                                                                                               |
|           3 | GPT-5.2         | Multiple Choice |       9 |      5.13 | Excellent B2-level vocabulary task in a relevant professional context. The distractors are well-chosen, and the task aligns with the goal of testing language for writing reports. A point is deducted because the 'correctAnswer' field is a string, whereas the instructions' example format strongly implied an array containing the string.                                                                                                                                                                                               |
|           3 | GPT-5.2         | Fill Blank      |       6 |     20.11 | The task tests an appropriate B2 grammar point (present perfect continuous). However, it critically fails on instruction adherence. The hint provided in parentheses, '(has continued to)', does not match the correct answer, 'has been'. This makes the task confusing and instructionally flawed for a learner.                                                                                                                                                                                                                            |
|           3 | Gemini 3 Flash  | Multiple Choice |       9 |      1.39 | An excellent task testing formal phrasal verbs/collocations ('adhere to'), a key skill at the B2 level, especially for professional writing. The context is highly appropriate. It loses one point for using a string instead of an array for the 'correctAnswer' field, contrary to the instruction's formatting example.                                                                                                                                                                                                                    |
|           3 | Gemini 3 Flash  | Fill Blank      |      10 |      1.01 | This is an excellent response that perfectly meets all requirements. The task tests a key B2-level collocation ('meet the deadline'), the sentence structure is appropriate, and it successfully adheres to the 'only one correct answer' rule by testing a strong, idiomatic phrase. The JSON format is valid and follows all instructions.                                                                                                                                                                                                  |
|           3 | Llama 4         | Multiple Choice |       8 |      0.51 | This is a good B2-level task testing easily confused phrases and it correctly follows the JSON array format for the answer. However, the question sentence is overly long and somewhat rambling. While technically a single sentence, its lack of conciseness slightly detracts from its quality as a focused test item.                                                                                                                                                                                                                      |
|           3 | Llama 4         | Fill Blank      |       1 |      0.97 | The candidate failed to produce a valid or complete JSON output. The response is an incomplete string fragment, violating the most fundamental instruction of the prompt. While the sentence fragment itself was promising for a B2 level, the output is unusable.                                                                                                                                                                                                                                                                            |
|           3 | Mistral Large 3 | Multiple Choice |      10 |      2.12 | Perfect execution. The task tests a key B2 grammar point (perfect participle clauses) that is essential for writing more complex sentences. The distractors represent common learner errors. It follows all instructions precisely, including the JSON format for the 'correctAnswer' field as an array.                                                                                                                                                                                                                                      |
|           3 | Mistral Large 3 | Fill Blank      |       7 |      1.39 | The sentence structure using 'Despite...' is appropriate for B2. However, the task violates the strict guideline of having only one correct answer. The verb 'resume' is a perfectly valid and common alternative to 'continue' in this context, making the question ambiguous.                                                                                                                                                                                                                                                               |
|           3 | Qwen 3 Max      | Multiple Choice |       9 |      4.57 | A very strong B2 vocabulary task that tests nuanced word choice. The context is clear and the distractors are plausible. The task is well-aligned with the B2 level. A point is deducted for not following the specified array format for the 'correctAnswer' field, providing a string instead.                                                                                                                                                                                                                                              |
|           3 | Qwen 3 Max      | Fill Blank      |       6 |      2.68 | Similar to Candidate 2, the sentence structure is good for the B2 level. However, it clearly violates the 'only one correct answer' rule. A learner could easily and correctly use 'go to' instead of 'attend', which makes the task ambiguous and less effective for testing the specific vocabulary word.                                                                                                                                                                                                                                   |
|           4 | GPT-5.2         | Multiple Choice |       8 |      4.86 | This is a solid B2-level grammar task testing the use of a gerund after the verb 'recommend'. The context is appropriate and the distractors are relevant verb forms. The task is clear and has a deterministic answer. It loses points because the `correctAnswer` field is a string, not an array of strings as specified in the instructions.                                                                                                                                                                                              |
|           4 | GPT-5.2         | Fill Blank      |       8 |     22.54 | This is a strong B2-level task testing connectors of concession ('despite' vs. 'in spite of'), which aligns well with the proficiency description of writing reports and giving reasons. The professional context is appropriate. The only minor weakness is that 'in spite of' is also a correct answer, but it was not included in the 'correctAnswer' array. However, for a single blank, 'despite' is the more concise and likely intended answer.                                                                                        |
|           4 | Gemini 3 Flash  | Multiple Choice |       9 |      1.48 | This is a high-quality B2 vocabulary task. The target word 'undermined' is perfectly suited for the level, and the distractors are excellent choices, being semantically related or morphologically similar. The business context is appropriate and the sentence is natural. The task is clear and deterministic. The only flaw is a minor format deviation, where `correctAnswer` is a string instead of the requested array.                                                                                                               |
|           4 | Gemini 3 Flash  | Fill Blank      |       6 |      1.18 | The sentence features excellent B2-level vocabulary and a relevant professional context ('board of directors', 'proposal', 'aligns with'). However, the task fails on the 'only one correct answer' guideline. The blank could be filled with many synonyms like 'reviewing', 'evaluating', 'discussing', or 'analyzing', making it highly ambiguous without the hint.                                                                                                                                                                        |
|           4 | Llama 4         | Multiple Choice |       2 |      3.21 | This candidate is deeply flawed. Firstly, it violates a guideline by lifting a phrase directly from the level description in the prompt ('highlights the personal significance of events and experiences'). More critically, the task is grammatically incorrect; the parallel structure 'both engaging and ___' requires an adjective ('objective'), but the provided `correctAnswer` is an adverb ('objectively'). This makes the question invalid. The only positive is that it correctly formatted the `correctAnswer` field as an array. |
|           4 | Llama 4         | Fill Blank      |       9 |      2.07 | This is an excellent B2 grammar task. It correctly identifies and tests a key structure for this level: the Past Perfect Continuous tense. The time markers 'By the time I arrived' and 'for months' create a strong context that makes the required tense almost unique and unambiguous. This is a well-designed, deterministic grammar question.                                                                                                                                                                                            |
|           4 | Mistral Large 3 | Multiple Choice |       7 |      2.02 | The task tests the use of perfect participle clauses ('having been stuck'), which is a good B2/C1 grammar point. However, the task violates the guideline for a deterministic answer, as the option 'being stuck' is also grammatically correct and very common in this context, making the question ambiguous. It also fails to follow the specified format for the `correctAnswer` field (string instead of array).                                                                                                                         |
|           4 | Mistral Large 3 | Fill Blank      |       5 |      1.31 | The sentence structure with 'Despite' is appropriate for B2. However, the task itself is weak. The blank can be filled with numerous other verbs besides 'continue' (e.g., 'start', 'begin', 'make', 'pursue'), making the question highly ambiguous. It relies entirely on the parenthetical hint '(continue)' to be solvable, which indicates poor question design.                                                                                                                                                                         |
|           4 | Qwen 3 Max      | Multiple Choice |       9 |      2.4  | An excellent and well-designed B2 vocabulary task. It correctly tests the meaning of the phrasal verb 'proceed with' in a clear context. The distractors are logical antonyms, making the question a good test of comprehension. The answer is deterministic and the level is appropriate. It only loses a point for a minor format error, providing the `correctAnswer` as a string instead of an array.                                                                                                                                     |
|           4 | Qwen 3 Max      | Fill Blank      |       5 |      4.57 | Similar to Candidate 2, the sentence frame is B2 level, but the task is flawed. The blank is not deterministic, as several other verbs would fit the context perfectly (e.g., 'go to', 'watch'). The question is only answerable because of the hint '(attend)', not because of linguistic constraints in the sentence, which makes it a weak assessment item.                                                                                                                                                                                |
|           5 | GPT-5.2         | Multiple Choice |       8 |      6.45 | The task is well-formed, accurate, and follows all instructions. It tests knowledge of contrasting conjunctions ('even though'). However, this specific grammar point is often mastered at the B1 level, making the task feel more like a B1 review or low-B2 question rather than a challenging B2 exercise.                                                                                                                                                                                                                                 |
|           5 | GPT-5.2         | Fill Blank      |       8 |     18.34 | The candidate provides a high-quality B2-level task testing the common collocation 'take into account'. The format is correct and it adheres closely to the instructions. While 'factor' could also be a possible answer, 'take' is by far the most idiomatic and expected response, making this a strong, nearly deterministic question.                                                                                                                                                                                                     |
|           5 | Gemini 3 Flash  | Multiple Choice |      10 |      1.55 | An outstanding task that perfectly aligns with the B2 level. The sentence structure is complex and authentic, using business-related vocabulary. The question tests knowledge of an important idiomatic expression ('on track to achieve'), which is a hallmark of upper-intermediate proficiency. The distractors are plausible but incorrect.                                                                                                                                                                                               |
|           5 | Gemini 3 Flash  | Fill Blank      |       7 |      1.29 | The candidate created a good B2-level task with appropriate business context and vocabulary (the collocation 'meet expectations'). The format is correct. However, it violates the instruction for the answer to be deterministic or to list all possible answers, as 'satisfy' and 'fulfill' are also correct and common verbs in this context but were not included in the 'correctAnswer' array.                                                                                                                                           |
|           5 | Llama 4         | Multiple Choice |       9 |      1.16 | This is a solid B2 grammar question that correctly follows all guidelines. It tests the nuanced use of the present perfect tense ('have changed') to describe changes over time, a concept consolidated at the B2 level. The sentence is well-contextualized, guiding the learner to the correct tense.                                                                                                                                                                                                                                       |
|           5 | Llama 4         | Fill Blank      |       3 |      1.31 | This candidate fails to follow several key instructions. The 'question' is not a fill-in-the-blank but a multiple-choice question with the options embedded in the text `(has been preparing/have been preparing)`. The sentence is unnecessarily long. Furthermore, the answer provided ('have been preparing') only accounts for British English usage, ignoring the standard American English form ('has been preparing'), thus failing the determinism requirement.                                                                       |
|           5 | Mistral Large 3 | Multiple Choice |      10 |      2.29 | This is an excellent B2-level task. It correctly tests the use of perfect participle clauses ('having been stuck'), a grammatical structure that allows for more complex and sophisticated writing, which is a key skill at this level. The options provide good distractors, and the context is natural.                                                                                                                                                                                                                                     |
|           5 | Mistral Large 3 | Fill Blank      |       5 |      2.07 | The task is grammatically correct and follows the JSON format, but it fails on two key points. Firstly, the vocabulary ('attend a concert') is more suited for a B1 level than B2. Secondly, it violates the strict constraint of having only one correct answer, as 'go to' is an equally valid and common response, making the task ambiguous.                                                                                                                                                                                              |
|           5 | Qwen 3 Max      | Multiple Choice |       9 |      3.72 | A strong B2 vocabulary task. It effectively tests the learner's ability to distinguish between words with similar meanings ('disappoint' vs. 'discourage', etc.) within a complex sentence. This skill of choosing the precise word is crucial for the clear and detailed writing expected at B2. The context is clear and the options are well-chosen.                                                                                                                                                                                       |
|           5 | Qwen 3 Max      | Fill Blank      |       5 |      2.52 | This output is identical to Candidate 2. It is grammatically correct and follows the JSON format, but it fails on two key points. The vocabulary ('attend a concert') is more suited for a B1 level than B2. More importantly, it violates the strict constraint of having only one correct answer, as 'go to' is an equally valid and common response.                                                                                                                                                                                       |
|           6 | GPT-5.2         | Multiple Choice |       9 |      3.61 | Excellent task that meets all guidelines. It tests a nuanced, context-specific B2-level collocation ('address concerns') in a professional setting. The distractors are plausible verbs but are clearly incorrect in this specific context, making the question fair and deterministic. The JSON format is perfect.                                                                                                                                                                                                                           |
|           6 | GPT-5.2         | Fill Blank      |       8 |     18.5  | The task correctly targets a key B2 grammar point (third conditional). The sentence is natural and the answer 'had had' is deterministically correct. The score is slightly reduced because the 'had had' structure can be phonetically confusing, and the parenthetical hint `(had more time)` is a slightly awkward interpretation of the prompt's instruction to provide the 'missing word/phrase in English'.                                                                                                                             |
|           6 | Gemini 3 Flash  | Multiple Choice |       6 |      1.45 | This is a clean, well-structured task that follows all formatting guidelines. However, the linguistic skill it tests‚Äîchoosing the correct word form from a word family ('confident' vs. 'confidence')‚Äîis typically mastered at the B1 level. A B2 task should present a more nuanced lexical or grammatical challenge.                                                                                                                                                                                                                        |
|           6 | Gemini 3 Flash  | Fill Blank      |       5 |      1.03 | While the sentence uses appropriate B2-level vocabulary and a relevant business context, it fails significantly as a fill-in-the-blank task. It violates the core instruction to have only one correct answer. Many verbs like 'reviewing', 'evaluating', and 'discussing' fit the blank perfectly, making the question highly ambiguous and non-deterministic.                                                                                                                                                                               |
|           6 | Llama 4         | Multiple Choice |       5 |      1.15 | While the vocabulary and context are appropriate for the B2 level, the candidate failed to follow a critical negative constraint. It includes instructions ('Complete the sentence with the most suitable word:') within the 'question' field, directly violating guideline #9, which states 'Do not include any instructions for the task'.                                                                                                                                                                                                  |
|           6 | Llama 4         | Fill Blank      |       7 |      1.15 | The task targets a suitable advanced grammar point (past perfect continuous). However, it has two flaws. First, it violates the formatting guidelines by omitting the required parenthetical hint in the question string. Second, the answer is not strictly deterministic, as the past perfect simple ('had worked on') could also be considered grammatically acceptable.                                                                                                                                                                   |
|           6 | Mistral Large 3 | Multiple Choice |       7 |      1.74 | The task targets a good B2-level vocabulary challenge (distinguishing similar verbs). However, the options 'adjusted' and 'adapted' can be nearly interchangeable in the given context for many speakers, which slightly violates the 'deterministic' answer guideline. Additionally, the 'correctAnswer' field is formatted as an array instead of a string, which is a minor deviation from the standard interpretation of the prompt.                                                                                                      |
|           6 | Mistral Large 3 | Fill Blank      |       6 |      3.91 | The task tests a relevant B2 phrasal verb ('go ahead with') in a good contextual sentence. However, it fails the strict guideline of having only one correct answer. The word 'proceed' is a very strong and equally correct alternative, making the question ambiguous.                                                                                                                                                                                                                                                                      |
|           6 | Qwen 3 Max      | Multiple Choice |       6 |      4    | The task is well-formed and follows all formatting rules. However, the difficulty is more appropriate for a B1 level than B2. The context ('Despite the heavy rain' and 'as scheduled') makes the correct answer ('proceed with') overly obvious when contrasted with the antonymous distractors ('cancel', 'postpone', 'abandon').                                                                                                                                                                                                           |
|           6 | Qwen 3 Max      | Fill Blank      |      10 |      2.53 | This is an excellent task that perfectly adheres to all instructions. It tests a crucial B2 grammar point‚Äîthe use of present perfect continuous with the simple past and 'since'. The answer 'graduated' is unambiguously correct due to the context ('in 2020'). The format is perfect, and the difficulty is ideal for the target level.                                                                                                                                                                                                    |
|           7 | GPT-5.2         | Multiple Choice |       8 |      6.09 | A solid B2-level grammar question testing concessive clauses. The task is clear, the options are good distractors, and it follows all instructions. The question is a bit of a textbook classic but is undeniably appropriate for the level.                                                                                                                                                                                                                                                                                                  |
|           7 | GPT-5.2         | Fill Blank      |       8 |     11.95 | The candidate produced a valid JSON with a high-quality B2-level question. The vocabulary item 'postpone' is appropriate for the level and context. However, it violates the strict instruction that the missing word must have only one correct answer, as 'delay' (the word in the hint) and 'reschedule' are also valid and natural-sounding options. Despite this flaw, it is a strong attempt at a challenging task.                                                                                                                     |
|           7 | Gemini 3 Flash  | Multiple Choice |      10 |      1.87 | This is an outstanding B2 task. It uses a complex sentence structure and a context (a debate) that directly aligns with the level's writing description. The vocabulary test is precise, requiring the user to understand the specific meaning of 'maintain' as 'to assert a belief', which is a hallmark of higher-level language proficiency.                                                                                                                                                                                               |
|           7 | Gemini 3 Flash  | Fill Blank      |       7 |      1.27 | This is a good attempt with valid JSON and a high-quality sentence testing the B2 adjective 'convincing' in an appropriate context. The task is well-designed, but it fails the key constraint of having a single unique answer. Several other adjectives like 'persuasive', 'compelling', or 'strong' fit the blank perfectly, making the intended answer non-deterministic.                                                                                                                                                                 |
|           7 | Llama 4         | Multiple Choice |       8 |      0.37 | This is a good B2-level task testing vocabulary, specifically collocations ('follow a schedule'). The context is relevant and the answer is clear. The JSON format for 'correctAnswer' is an array, which is a literal interpretation of an ambiguously written instruction, but the task itself is well-constructed.                                                                                                                                                                                                                         |
|           7 | Llama 4         | Fill Blank      |       1 |      0.59 | The candidate completely failed to follow the instructions. Instead of generating the requested language task in the specified JSON format, it returned a description of the prompt itself. The output is technically valid JSON, but it contains none of the required content or structure.                                                                                                                                                                                                                                                  |
|           7 | Mistral Large 3 | Multiple Choice |      10 |      1.92 | An excellent task that tests a nuanced grammar point (perfect participles) appropriate for a high B2 level. The context is natural, and the options represent common learner errors, making it a well-designed and effective question. It perfectly aligns with building more complex sentence structures for writing.                                                                                                                                                                                                                        |
|           7 | Mistral Large 3 | Fill Blank      |       8 |      1.27 | This candidate provided a valid JSON object testing a relevant B2-level phrasal verb ('go ahead with'). The sentence is natural and the context is clear. It shares a similar flaw with other candidates by not adhering to the 'only one correct answer' rule, as 'proceed with' is a perfectly acceptable alternative. The task is well-constructed otherwise.                                                                                                                                                                              |
|           7 | Qwen 3 Max      | Multiple Choice |       4 |      5.11 | This task is flawed because it violates the instruction for the answer to be deterministic. While the intended answer is 'carry out', the option 'put on' (as in 'put on a concert') is also grammatically correct and arguably more idiomatic in this context. This ambiguity makes it a poor question.                                                                                                                                                                                                                                      |
|           7 | Qwen 3 Max      | Fill Blank      |       6 |      3.31 | The JSON is valid and the sentence is grammatically correct. However, the task is somewhat weak for the B2 level, as 'attend' is typically learned at B1. More importantly, it fails the uniqueness constraint significantly, as 'go to' is a very common and obvious alternative, making the question less deterministic than required.                                                                                                                                                                                                      |
|           8 | GPT-5.2         | Multiple Choice |       9 |      8.08 | Excellent B2-level grammar task testing the passive participle in a formal, work-related context. The vocabulary ('proposal', 'pilot study') is appropriate, and the question is unambiguous. It adheres to all instructions, including the JSON format. A very strong submission.                                                                                                                                                                                                                                                            |
|           8 | GPT-5.2         | Fill Blank      |       9 |     18.66 | Excellent task testing a core B2 grammar point (the third conditional). The sentence structure makes the answer highly deterministic, and all formatting instructions were followed correctly. A near-perfect submission.                                                                                                                                                                                                                                                                                                                     |
|           8 | Gemini 3 Flash  | Multiple Choice |      10 |      1.52 | This is an exemplary submission that perfectly meets all requirements. The task tests nuanced B2-level vocabulary (verbs with 'over-') within a complex sentence and a relevant context. It strictly adheres to all guidelines regarding format, content, and the absence of instructions, resulting in a high-quality, unambiguous language task.                                                                                                                                                                                            |
|           8 | Gemini 3 Flash  | Fill Blank      |       5 |      1.12 | This task appropriately tests a B2-level skill (using a participial phrase). However, it completely fails the critical instruction to have only one correct answer. Multiple verbs like 'detailing', 'explaining', and 'describing' are perfect synonyms for 'outlining' in this context, making the question highly ambiguous.                                                                                                                                                                                                               |
|           8 | Llama 4         | Multiple Choice |       4 |      1.59 | While the linguistic content is excellent for a B2 vocabulary task, the candidate fails significantly on following instructions. It includes instructions ('Complete the sentence...') inside the question field, violating a direct negative constraint. It also fails to use the specified JSON structure for the correct answer, providing an index instead of the string value.                                                                                                                                                           |
|           8 | Llama 4         | Fill Blank      |       6 |      1.79 | This candidate correctly identified an advanced B2 grammar point (the subjunctive mood), which is commendable. However, it fails on two counts: it violates a direct instruction by omitting the missing word in parentheses, and the answer is not unique, as 'use' is an equally valid alternative to 'take'.                                                                                                                                                                                                                               |
|           8 | Mistral Large 3 | Multiple Choice |       8 |      1.81 | A solid B2 grammar task testing the use of a passive gerund ('being stuck') after a preposition. The task is clear and follows all formatting rules. While the context is slightly less complex than other candidates, the grammatical point is perfectly suited for the B2 level.                                                                                                                                                                                                                                                            |
|           8 | Mistral Large 3 | Fill Blank      |       5 |      1.39 | The task is grammatically correct but fails on two key points. Firstly, the level is closer to B1, as it tests a simple infinitive structure rather than a complex B2 skill. Secondly, it violates the 'only one correct answer' rule, as words like 'resume' or 'begin' would also fit the blank.                                                                                                                                                                                                                                            |
|           8 | Qwen 3 Max      | Multiple Choice |       5 |      3.66 | This task is weaker because it violates the 'avoid ambiguity' rule. The provided correct answer ('doing' her run) is a less common and natural collocation than other possibilities (e.g., 'going for' or 'taking'), which could confuse a learner. The difficulty level is also closer to B1 than the requested B2.                                                                                                                                                                                                                          |
|           8 | Qwen 3 Max      | Fill Blank      |       9 |      2.83 | An excellent task that correctly identifies a key B2 grammar point (the future perfect tense). The time marker 'by tomorrow' makes the answer highly specific and deterministic in a testing context. The submission follows all instructions perfectly.                                                                                                                                                                                                                                                                                      |
|           9 | GPT-5.2         | Multiple Choice |       9 |      4.96 | A very strong task that correctly tests connectors of concession ('Despite'), a key skill for B2-level writing. The context of a 'detailed report' aligns perfectly with the proficiency description. The options are clear, and the answer is unambiguous. The format is correct.                                                                                                                                                                                                                                                            |
|           9 | GPT-5.2         | Fill Blank      |      10 |     27    | This is an excellent B2-level task. It correctly tests the second conditional, a key grammatical structure for this level. The context is relevant and natural. Crucially, this was the only candidate to interpret the instruction for a hint (e.g., '(possessed)') in a pedagogically sound way, providing a synonym rather than the answer itself. This creates a genuine test of the learner's knowledge, unlike the other candidates. The format is perfect.                                                                             |
|           9 | Gemini 3 Flash  | Multiple Choice |      10 |      1.56 | This is an outstanding B2-level task. It tests nuanced vocabulary by requiring the selection of the most precise adjective ('detrimental') in a formal context. This skill is directly relevant to the B2 ability to write clear, detailed reports. The distractors are plausible but less appropriate, making the correct answer clear and deterministic.                                                                                                                                                                                    |
|           9 | Gemini 3 Flash  | Fill Blank      |       4 |      1.34 | This candidate has multiple flaws. First, like others, it gives the answer away in the hint ('reach/arrive at'). Second, it violates the instructions by creating ambiguity: the hint suggests two possible correct answers ('reach' and 'arrive at'), but the `correctAnswer` field only lists one ('reach'). The instructions explicitly state to return all correct answers in the array. This internal inconsistency makes it a poorly constructed task.                                                                                  |
|           9 | Llama 4         | Multiple Choice |      10 |      1.74 | An excellent task that perfectly meets all instructions. It tests word forms ('anecdotal'), a crucial skill for writing accuracy at the B2 level. The vocabulary is appropriate, the context is modern and engaging, and the options create a clear, unambiguous choice. The JSON format, including the array for 'correctAnswer', is a valid interpretation of the prompt.                                                                                                                                                                   |
|           9 | Llama 4         | Fill Blank      |       7 |      0.47 | The task tests the past perfect continuous, an excellent and challenging grammar point for the B2 level, and the sentence construction is perfect for it. The task is of high quality in principle. However, like other candidates, it provides the exact answer in the hint, which fundamentally undermines the purpose of the assessment. It scores slightly higher than others with the same flaw due to the strength of the chosen grammar point.                                                                                         |
|           9 | Mistral Large 3 | Multiple Choice |       8 |      1.77 | This is a solid grammar task testing the use of a gerund after a preposition ('After being stuck'). The format is correct and the answer is unambiguous. However, the grammatical point is arguably at the lower end of the B2 level, making it slightly less challenging than other candidates' submissions.                                                                                                                                                                                                                                 |
|           9 | Mistral Large 3 | Fill Blank      |       6 |      1.58 | The task correctly identifies a B2-level phrasal verb ('go ahead with') and places it in a natural sentence structure. However, the task is critically flawed because the hint provided in parentheses is the exact answer, turning a vocabulary test into a simple copying exercise. This fails to assess the learner's actual knowledge.                                                                                                                                                                                                    |
|           9 | Qwen 3 Max      | Multiple Choice |       8 |      3.98 | A good B2 vocabulary task focusing on collocations ('lift her mood'). The context is appropriate. The primary weakness is that 'elevate' could also be considered a possible, if less common, answer, which slightly reduces the determinism of the question. 'Lift' is the most idiomatic choice, but the ambiguity is a minor flaw.                                                                                                                                                                                                         |
|           9 | Qwen 3 Max      | Fill Blank      |       6 |      3.57 | This candidate successfully targets a common B2-level collocation ('make a breakthrough') within a relevant context. The task's value is significantly diminished, however, because the hint '(made)' is the literal answer. This removes any challenge and does not effectively test the learner's vocabulary knowledge.                                                                                                                                                                                                                     |
|          10 | GPT-5.2         | Multiple Choice |       0 |     16.79 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|          10 | GPT-5.2         | Fill Blank      |       9 |     12.82 | This is an excellent B2-level task. It tests a key grammatical structure for this level (the third conditional) in a relevant context (writing a report). Crucially, it adheres to the guideline of having a single, deterministic correct answer ('had had'), a point where most other candidates failed. The JSON format is correct. The only minor point is the somewhat unusual hint '(possessed)' instead of the base verb '(have)', but it is a valid and challenging way to prompt the correct verb.                                   |
|          10 | Gemini 3 Flash  | Multiple Choice |       0 |      1.29 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|          10 | Gemini 3 Flash  | Fill Blank      |       5 |      1.06 | The task's level and context are appropriate for B2. However, the output has multiple issues. It fails the determinism guideline, as words like 'support' or 'endorse' could also fit the blank. Additionally, the hint is confusingly presented as '(approve / give the go-ahead to)', but the 'correctAnswer' array only contains 'approve', creating an internal inconsistency. This lack of clarity and failure to account for other valid answers weakens the task significantly.                                                        |
|          10 | Llama 4         | Multiple Choice |       0 |      1.62 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|          10 | Llama 4         | Fill Blank      |       6 |      1.32 | The sentence itself is very well-constructed for a B2 level, using a complex structure and relevant business vocabulary ('policy', 'productivity'). However, the output fails on two clear instructions. First, it completely omits the required hint in parentheses within the 'question' string. Second, the answer is not deterministic ('contributed' is another strong possibility) and the alternative is not listed in the 'correctAnswer' array.                                                                                      |
|          10 | Mistral Large 3 | Multiple Choice |       0 |      1.91 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|          10 | Mistral Large 3 | Fill Blank      |       6 |      1.39 | The candidate correctly identifies a B2-level phrasal verb ('go ahead with') and places it in a natural-sounding sentence. The format is valid. However, the task violates the key guideline of being deterministic. Other verbs, such as 'proceed' or 'continue', would also fit the blank grammatically and contextually. The candidate should have either constructed a more constrained sentence or listed all possible correct answers in the array.                                                                                     |
|          10 | Qwen 3 Max      | Multiple Choice |       0 |      4.52 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|          10 | Qwen 3 Max      | Fill Blank      |       5 |      3.98 | This candidate's task is too simple for the B2 level. The target vocabulary word, 'attend', is typically learned at the B1 level. Furthermore, like other candidates, it fails the determinism test, as 'go to' is an equally valid and common answer which was not included in the 'correctAnswer' array. The sentence structure is acceptable, but the core task does not meet the required proficiency standard.                                                                                                                           |
|          11 | GPT-5.2         | Multiple Choice |       8 |      6.6  | The task is excellent and perfectly aligned with the B2 level, testing cohesive devices crucial for essay and report writing. The context is appropriate, and all options are plausible distractors. The only deduction is for a minor format error: the 'correctAnswer' field should contain an array with the string, not just the string itself, as specified in the instructions ('in array').                                                                                                                                            |
|          11 | GPT-5.2         | Fill Blank      |       6 |     13.72 | The task is well-structured for B2, using appropriate vocabulary and context. However, it fails the critical 'only one correct answer' rule. Words like 'pinpoint,' 'determine,' or the hint-word 'recognize' are all valid alternatives to 'identify', making the question ambiguous.                                                                                                                                                                                                                                                        |
|          11 | Gemini 3 Flash  | Multiple Choice |       6 |      1.56 | The core linguistic task is of high quality, using B2-level vocabulary in a context (formal report) that is perfectly aligned with the proficiency description. However, the candidate fails a key negative constraint by including instructions ('Choose the most appropriate word...') in the 'question' field, which was explicitly forbidden. It also has a minor format error with the 'correctAnswer' field.                                                                                                                            |
|          11 | Gemini 3 Flash  | Fill Blank      |       9 |      1.22 | This is an excellent B2-level task. It tests relevant vocabulary ('proposal,' 'residents,' 'opposed') within a suitable context. Crucially, it best adheres to the 'only one correct answer' rule. The strong collocation of 'strongly opposed to' makes 'opposed' the most natural and expected answer, effectively minimizing ambiguity.                                                                                                                                                                                                    |
|          11 | Llama 4         | Multiple Choice |       2 |      0.69 | This candidate fails on multiple fundamental guidelines. The 'question' field is not a single sentence; it contains a long preamble that copies parts of the original instruction and explicitly includes instructions for the user ('I need to choose the correct word...'). This violates guidelines #1, #9, and #10. The output demonstrates a poor understanding of the prompt's constraints.                                                                                                                                             |
|          11 | Llama 4         | Fill Blank      |       5 |      1.19 | While the business context and vocabulary are highly appropriate for the B2 level, the task is extremely ambiguous. 'Increase,' 'improve,' and 'raise' are all perfect synonyms for 'boost' in this context, directly violating the strict 'only one correct answer' guideline.                                                                                                                                                                                                                                                               |
|          11 | Mistral Large 3 | Multiple Choice |       9 |      1.92 | This is a strong candidate that follows all instructions, including the JSON format for 'correctAnswer' as an array. The task effectively tests B2-level vocabulary by distinguishing between similar words and different word forms ('adapt' vs 'adopt', 'adjustment', 'adaptation'). While the context is general, the task is well-constructed and deterministic.                                                                                                                                                                          |
|          11 | Mistral Large 3 | Fill Blank      |       5 |      1.48 | The sentence structure is acceptable, but the overall vocabulary and the target word 'continue' are closer to a B1 level. More importantly, the task is ambiguous, as 'have our picnic' or 'hold our picnic' are equally valid and common answers, violating a key instruction.                                                                                                                                                                                                                                                               |
|          11 | Qwen 3 Max      | Multiple Choice |       5 |      2.75 | The task is grammatically correct, but the skill tested (gerund after a preposition) is more characteristic of a B1 level than B2. It does not adequately challenge a B2 learner's ability to write detailed essays or reports as described in the proficiency description. It also fails to format the 'correctAnswer' as an array.                                                                                                                                                                                                          |
|          11 | Qwen 3 Max      | Fill Blank      |       7 |      3.96 | This candidate correctly targets a B2 grammar point ('insisted on' + gerund), which is a strong feature. The sentence is natural. However, it does not have a unique answer, as 'going to' is a very common and correct alternative to 'attending', making the task ambiguous.                                                                                                                                                                                                                                                                |
|          12 | GPT-5.2         | Multiple Choice |       8 |     10.63 | The task effectively tests a common B2-level collocation ('meet a deadline') within a relevant context. The sentence structure is appropriate, and the distractors are plausible. The JSON format is valid, although the `correctAnswer` field did not follow the specified array format.                                                                                                                                                                                                                                                     |
|          12 | GPT-5.2         | Fill Blank      |       8 |     13.29 | Excellent choice of a B2/C1 grammar point (inversion) which results in a truly deterministic question with only one possible answer, strictly adhering to a key guideline. The sentence structure is complex and appropriate for the level. It loses points only because its literal interpretation of the instructions (placing the answer in parentheses) makes the task trivial for the learner, although it is technically compliant.                                                                                                     |
|          12 | Gemini 3 Flash  | Multiple Choice |      10 |      1.14 | An outstanding task that perfectly aligns with the B2 writing proficiency description (writing reports, presenting arguments). The vocabulary ('primarily', 'innovative') and sentence structure are ideal for the level. The answer is unambiguous, and the distractors are well-crafted.                                                                                                                                                                                                                                                    |
|          12 | Gemini 3 Flash  | Fill Blank      |       6 |      1.22 | This candidate shows a superior interpretation of the instructions by providing synonyms as a hint ('considering/thinking about') instead of the answer itself. However, it fundamentally fails by not including 'considering' in the `correctAnswer` array, even though it's a valid and even more common answer. This makes the provided solution incorrect and violates the deterministic answer rule.                                                                                                                                     |
|          12 | Llama 4         | Multiple Choice |       7 |      1.41 | A solid grammar task testing the use of a gerund after a preposition. The context is appropriate, and the answer is clear. While the grammar point can be introduced at B1, the complexity of the options makes it suitable for B2. This candidate was the only one to correctly format the `correctAnswer` as an array, as specified in the prompt.                                                                                                                                                                                          |
|          12 | Llama 4         | Fill Blank      |       4 |      1.21 | The task uses good B2-level vocabulary and context ('came into effect'). However, it fails on two instructions: it completely omits the required hint in parentheses, and the question is not deterministic as 'went into effect' is also a correct answer. This violates two key guidelines.                                                                                                                                                                                                                                                 |
|          12 | Mistral Large 3 | Multiple Choice |       6 |      1.93 | The task is grammatically sound, but it is flawed because it has two potentially correct answers. Both 'reviewing' and 'having reviewed' can be grammatically acceptable after the preposition 'After', which violates the guideline requiring a single, deterministic correct answer. This ambiguity weakens the question.                                                                                                                                                                                                                   |
|          12 | Mistral Large 3 | Fill Blank      |       5 |      1.37 | The task tests a relevant B2-level phrasal verb ('go ahead with'). However, it violates the critical instruction for the answer to be deterministic, as 'proceed with' is also a valid and common answer. Like other candidates, it also gives the answer away in the question's hint, reducing its value as a test item.                                                                                                                                                                                                                     |
|          12 | Qwen 3 Max      | Multiple Choice |       9 |      4.55 | This is an excellent B2 vocabulary task. It tests nuanced word choice ('disappoint') in a clear context with well-chosen distractors. The sentence complexity and vocabulary are appropriate for the level, and the answer is unambiguous.                                                                                                                                                                                                                                                                                                    |
|          12 | Qwen 3 Max      | Fill Blank      |       3 |      2.49 | The task is too simple for the B2 level; the vocabulary word 'attend' is closer to B1. More importantly, it fails the 'only one correct answer' constraint, as 'go to' is a perfectly acceptable and common alternative. It also gives the answer away in the hint.                                                                                                                                                                                                                                                                           |
|          13 | GPT-5.2         | Multiple Choice |       9 |      7.04 | Excellent task that perfectly aligns with the B2 writing context mentioned in the prompt ('report'). It tests a relevant phrasal verb ('point out'), and the distractors are plausible but grammatically incorrect with the preposition 'out'. The submission follows all instructions and format requirements.                                                                                                                                                                                                                               |
|          13 | GPT-5.2         | Fill Blank      |       9 |     25.96 | Excellent choice of a B2-level grammatical structure (inversion with 'Not only'). The question is unambiguous and has a single correct answer. The format is a valid JSON. The only minor flaw is that the parenthetical hint '(past auxiliary verb used for inversion)' is a grammatical description rather than the word itself as shown in the examples, which makes the task slightly easier than intended. However, it is still the strongest candidate.                                                                                 |
|          13 | Gemini 3 Flash  | Multiple Choice |      10 |      1.44 | An outstanding B2-level task. It tests a key professional collocation ('meet the deadline'), which requires the nuanced vocabulary knowledge characteristic of this level. The distractors are excellent, as they are synonyms that do not fit the specific context, making it a challenging and well-designed question. It perfectly adheres to all guidelines.                                                                                                                                                                              |
|          13 | Gemini 3 Flash  | Fill Blank      |       3 |      1.21 | The candidate followed the instructions literally, which resulted in a flawed and ineffective task. By placing the answer '(ahead of schedule)' in the question as the hint, it created a simple copying exercise with zero pedagogical value. It fails to test any skill, which is the primary purpose of a language task.                                                                                                                                                                                                                   |
|          13 | Llama 4         | Multiple Choice |       1 |      1.38 | The output is a critical failure. The generated JSON is incomplete and therefore invalid and unparseable. The task itself is truncated, making it impossible to evaluate its linguistic merit. It fails the most fundamental requirement of the prompt.                                                                                                                                                                                                                                                                                       |
|          13 | Llama 4         | Fill Blank      |       7 |      0.45 | This is a very strong grammar task, testing the past perfect continuous ('had been working on'), which is appropriate for the B2 level and is largely unambiguous. However, it completely fails to follow guideline #10, as it omits the required parenthetical hint for the missing phrase.                                                                                                                                                                                                                                                  |
|          13 | Mistral Large 3 | Multiple Choice |       8 |      1.88 | A strong B2-level grammar question testing the use of a passive gerund ('being stuck') after a preposition. The context is appropriate, and the task is clear and unambiguous. It fully adheres to all instructions.                                                                                                                                                                                                                                                                                                                          |
|          13 | Mistral Large 3 | Fill Blank      |       6 |      4.4  | The task tests a B2-level collocation ('on time'). However, it violates the strict guideline to 'Avoid ambiguity' and have 'only one correct answer'. Another valid answer, 'in time', is also possible and has a subtly different meaning, making the question ambiguous for a learner.                                                                                                                                                                                                                                                      |
|          13 | Qwen 3 Max      | Multiple Choice |       7 |      2.63 | A valid and clear task that correctly tests the fixed phrase 'as planned'. It follows all instructions. However, the difficulty is on the lower end of the B2 level, verging on B1, making it slightly less challenging than ideal for the target proficiency.                                                                                                                                                                                                                                                                                |
|          13 | Qwen 3 Max      | Fill Blank      |       6 |      5    | This task correctly identifies a B2-level phrasal verb ('go ahead'). However, similar to candidate 2, it fails the 'only one correct answer' rule. A synonym like 'proceed' would also fit the blank, creating ambiguity that the instructions specifically forbade.                                                                                                                                                                                                                                                                          |
|          14 | GPT-5.2         | Multiple Choice |       8 |     10.45 | This is a solid B2-level task testing the appropriate use of conjunctions to link contrasting ideas, a key skill for writing at this level. The distractors are well-chosen. The only issue is a minor format violation: the 'correctAnswer' field should contain an array of strings, but it contains a single string.                                                                                                                                                                                                                       |
|          14 | GPT-5.2         | Fill Blank      |       7 |     20.38 | The task tests a B2-level conjunctive adverb, which is appropriate. However, it violates a key instruction by providing a hint ('however') that is different from the correct answer ('nevertheless'). Both words are valid in the blank, which introduces ambiguity and directly contradicts the hint provided in the question.                                                                                                                                                                                                              |
|          14 | Gemini 3 Flash  | Multiple Choice |       8 |      1.44 | This is a strong B2-level vocabulary question. It requires the test-taker to understand the nuance of the entire sentence to choose the correct adjective. The context and vocabulary are appropriate for the level. The score is reduced only because it failed to follow the specific JSON format for 'correctAnswer', which should be an array, not a string.                                                                                                                                                                              |
|          14 | Gemini 3 Flash  | Fill Blank      |      10 |      1.15 | This is an excellent response that perfectly meets all requirements. The context (summarizing complex arguments) aligns with the B2 writing skills description. The vocabulary is level-appropriate, the sentence is natural, and the answer 'summarize' is the most fitting choice, making it highly deterministic. The JSON format is also correct.                                                                                                                                                                                         |
|          14 | Llama 4         | Multiple Choice |       6 |      0.87 | While the vocabulary tested ('poses a threat') is perfectly appropriate for the B2 level, this candidate fails on a key negative constraint. It includes instructions ('Complete the sentence with the most suitable word: ...') which was explicitly forbidden by guideline #9. It also has a minor JSON format error for the 'correctAnswer' field.                                                                                                                                                                                         |
|          14 | Llama 4         | Fill Blank      |       1 |      0.57 | The candidate failed to follow the instructions. It did not generate a language task, instead returning a JSON object containing a descriptive string that partially repeats the prompt. It's a complete failure to execute the request.                                                                                                                                                                                                                                                                                                      |
|          14 | Mistral Large 3 | Multiple Choice |      10 |      1.78 | This candidate is excellent. It perfectly adheres to all instructions, including the JSON format for 'correctAnswer'. The task tests a common point of confusion for learners (adapt vs. adopt) and also requires knowledge of the correct word form (verb vs. noun), making it a well-rounded B2-level question.                                                                                                                                                                                                                             |
|          14 | Mistral Large 3 | Fill Blank      |       6 |      1.41 | The task follows the format, but the target vocabulary ('continue') is too simple for the B2 level, being more appropriate for A2/B1. Additionally, the sentence is ambiguous as other words like 'have' or 'start' could also fit, violating the 'only one correct answer' rule.                                                                                                                                                                                                                                                             |
|          14 | Qwen 3 Max      | Multiple Choice |       7 |      3.89 | The task is grammatically sound and follows most instructions. However, testing the verb pattern 'insist on + gerund' is arguably more of a B1-level skill, making it slightly easy for the requested B2 level. It also failed to follow the JSON format guideline, providing the 'correctAnswer' as a string instead of an array.                                                                                                                                                                                                            |
|          14 | Qwen 3 Max      | Fill Blank      |       8 |      2.75 | This is a good candidate. The task correctly identifies a B2-level phrasal verb ('go ahead with') and places it in a natural context. The only minor weakness is that another phrasal verb, 'proceed with', could also be considered a correct answer, slightly undermining the 'only one correct answer' constraint.                                                                                                                                                                                                                         |
|          15 | GPT-5.2         | Multiple Choice |       9 |      5.98 | A strong B2-level vocabulary task. The sentence structure and vocabulary ('weighed the pros and cons', 'resignation') are appropriate for the level. The options test nuanced understanding of verbs in a professional context. The distractors are plausible but clearly incorrect, making the answer deterministic. It fully adheres to the format and guidelines.                                                                                                                                                                          |
|          15 | GPT-5.2         | Fill Blank      |       8 |     16.89 | The task is well-suited for the B2 level, testing knowledge of contrasting linkers. The JSON format is correct. However, it violates the strict instruction to provide a deterministic answer or list all possible answers. Both 'Despite' and 'In spite of' are correct and interchangeable here, but the 'correctAnswer' array only lists 'Despite'. The hint '(in spite of)' makes this omission even more noticeable.                                                                                                                     |
|          15 | Gemini 3 Flash  | Multiple Choice |      10 |      1.57 | Outstanding performance. The task directly aligns with the B2 writing proficiency description provided in the prompt by setting the context within report writing ('balanced argument', 'advantages and disadvantages'). It tests knowledge of B2-level phrasal verbs ('weighing up') in a formal context. The task is well-constructed, deterministic, and perfectly follows all instructions.                                                                                                                                               |
|          15 | Gemini 3 Flash  | Fill Blank      |       9 |      1.17 | A very strong candidate that follows all instructions. The format is correct. The task tests B2-level reporting verbs in a relevant context. It does an excellent job of adhering to the 'only one correct answer' rule. While a synonym like 'refuted' could be argued, 'denied' is by far the most common and direct fit for the grammatical structure '...____ that...', making the question highly effective and nearly deterministic.                                                                                                    |
|          15 | Llama 4         | Multiple Choice |       2 |      1.63 | This candidate fails on multiple critical guidelines. 1) It violates the 'no instructions' rule by adding 'Complete the sentence...' to the question. 2) The answer is not deterministic; all four options are grammatically correct and plausible ways to make someone feel at ease, making the question subjective. 3) The JSON format is incorrect, including an unrequested 'correct' field. 4) The language complexity is closer to B1 than B2.                                                                                          |
|          15 | Llama 4         | Fill Blank      |       1 |      1    | This candidate fails on multiple fundamental requirements. The JSON format is invalid and does not match the requested structure. It violates guideline #10 by omitting the English translation in parentheses. Most importantly, the generated task ('The company will ____ the contract...') is highly ambiguous with many possible answers ('sign', 'renew', 'terminate', 'extend'), directly contradicting the 'only one correct answer' rule.                                                                                            |
|          15 | Mistral Large 3 | Multiple Choice |      10 |      2.03 | An excellent B2 grammar task. It precisely tests the use of the passive gerund ('being stuck') after a preposition, a key grammar point at this level. The context is relatable, and the distractors represent common learner errors, making it a well-designed and effective question. It follows all instructions perfectly.                                                                                                                                                                                                                |
|          15 | Mistral Large 3 | Fill Blank      |       7 |      1.6  | This task correctly targets B2-level vocabulary (phrasal verbs) and uses a natural context. The format is correct. The main weakness is its failure to adhere to the 'only one correct answer' rule. Besides 'carry out', other phrasal verbs like 'go ahead with' or 'follow through with' would also fit the context, making the question ambiguous.                                                                                                                                                                                        |
|          15 | Qwen 3 Max      | Multiple Choice |       9 |      3.32 | A very good B2-level task focusing on phrasal verbs and context-specific vocabulary. The sentence uses a B2-level structure ('Despite...'), and the correct answer ('proceed with') requires understanding beyond simple word definition. The distractors are thematically relevant but semantically incorrect, ensuring a single right answer.                                                                                                                                                                                               |
|          15 | Qwen 3 Max      | Fill Blank      |      10 |      2.85 | This candidate is excellent and perfectly follows all instructions. The JSON is valid. The task tests a key B2 grammar point (present perfect continuous with 'since'). Crucially, it adheres to the 'only one correct answer' constraint, as 'since' is the only grammatically correct and natural option in this context. The level and context are entirely appropriate.                                                                                                                                                                   |

### üåê Language: POLISH | Level: A1
|   iteration | model           | task_type       |   score |   latency | reason                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|------------:|:----------------|:----------------|--------:|----------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|           1 | GPT-5.2         | Multiple Choice |      10 |      3.58 | The task is excellent. It perfectly aligns with the A1 skill description of 'fill in forms with personal details' by testing the user's ability to identify the correct type of information (a phone number) for a specific field ('Telefon'). The question is a single, clear sentence fragment. The options are distinct and well-chosen, making the answer deterministic. It creatively adapts the multiple-choice format to test a skill related to writing production and follows all guidelines flawlessly.                                                         |
|           1 | GPT-5.2         | Fill Blank      |       8 |      1.67 | The task is highly relevant to the A1 level description, which explicitly mentions writing a postcard. The Polish sentence is grammatically correct, and 'poczt√≥wkƒô' is the correct accusative form. However, the instruction to 'avoid ambiguity' and have 'only one correct answer' is not perfectly met, as 'kartƒô pocztowƒÖ' (used by Candidate 3) is an equally valid answer. The task is good but not strictly deterministic as required.                                                                                                                            |
|           1 | Gemini 3 Flash  | Multiple Choice |      10 |      1.06 | This is an outstanding task. It tests a crucial A1 grammar point (the locative case with 'mieszkam w...') within a single, natural sentence. This skill is directly applicable to writing personal details on a form or in a short introductory text, aligning perfectly with the proficiency description. The options are the different grammatical cases of the same noun, creating a focused and effective question for an A1 learner. It adheres strictly to all guidelines.                                                                                          |
|           1 | Gemini 3 Flash  | Fill Blank      |      10 |      1.3  | This is another excellent A1 task. It tests a core A1 verb ('mieszkaƒá' - to live) in the context of a personal introduction, which relates to the A1 skill of providing personal details. The sentence is grammatically correct, natural, and 'mieszkam' is the single, unambiguous correct answer. The candidate followed all instructions perfectly, including the JSON format.                                                                                                                                                                                         |
|           1 | Llama 4         | Multiple Choice |       2 |      1.89 | This candidate fails on multiple critical points. It violates the 'single sentence' guideline by providing a three-sentence context. More importantly, the task is fundamentally broken due to a grammatical error. The correct answer requires the locative case ('w parku'), but the option provided is the nominative/accusative ('park'), making none of the options both contextually and grammatically correct. The context also does not align closely with the specified writing skill.                                                                           |
|           1 | Llama 4         | Fill Blank      |       1 |      1.28 | The candidate failed to produce a valid output. The JSON is incomplete and unparseable, violating the primary instruction to return a valid JSON object.                                                                                                                                                                                                                                                                                                                                                                                                                  |
|           1 | Mistral Large 3 | Multiple Choice |       4 |      2.03 | The task contains two significant flaws. First, it violates the guideline 'Do not include any instructions for the task' by including 'Wybierz poprawnƒÖ formƒô czasownika:' in the question string. Second, the question 'Codziennie ______ kawƒô w kawiarni' is ambiguous without an explicit subject pronoun (e.g., Ja, Ty, On), making multiple options potentially correct depending on the assumed context. This violates the 'deterministic' answer guideline.                                                                                                        |
|           1 | Mistral Large 3 | Fill Blank      |      10 |      1.52 | This is an excellent A1 task. It tests fundamental vocabulary ('jestem z...') and grammar (the verb 'byƒá') used for personal introductions. This aligns perfectly with the A1 skill of filling in personal details. The sentence is natural, and 'jestem' is the only correct and unambiguous answer. The JSON format is valid and all instructions were followed.                                                                                                                                                                                                        |
|           1 | Qwen 3 Max      | Multiple Choice |       6 |      4.69 | This task has a strong concept that directly relates to the A1 skill of filling in a form. However, it violates a key negative constraint by including a direct command, 'Wpisz swoje imiƒô i nazwisko w formularzu:', in the question field, which the instructions explicitly forbade ('Do not include any instructions for the task'). If the question had been framed as a sentence to complete, it would have been excellent.                                                                                                                                         |
|           1 | Qwen 3 Max      | Fill Blank      |       8 |      3.88 | Similar to Candidate 1, this task is very well-aligned with the A1 level description concerning sending holiday greetings. The sentence is grammatically correct and 'kartƒô pocztowƒÖ' is a correct answer. The issue is the same as with Candidate 1: 'poczt√≥wkƒô' is also a valid answer, which means the task is not as deterministic as the instructions required.                                                                                                                                                                                                      |
|           2 | GPT-5.2         | Multiple Choice |       9 |     17.86 | This is an excellent task that perfectly matches the A1 level and the specified skill of filling in forms. The context 'W formularzu:' is a direct and effective cue. The question tests a fundamental grammar point (1st person singular conjugation of 'byƒá') with clear, relevant distractors. It adheres to all guidelines, including having no instructions in the question. The only minor imperfection is that the `correctAnswer` is a string instead of an array, but this is a reasonable interpretation given the conflicting examples in the original prompt. |
|           2 | GPT-5.2         | Fill Blank      |      10 |      1.19 | Excellent task. The context 'Pozdrowienia z...' (Greetings from...) directly aligns with the A1 level description of writing a postcard. The answer 'g√≥r' correctly tests both vocabulary (mountains) and a key grammatical concept for this level (the genitive case after the preposition 'z'). The task is unambiguous and follows all instructions perfectly.                                                                                                                                                                                                         |
|           2 | Gemini 3 Flash  | Multiple Choice |       6 |      1.42 | The vocabulary tested (personal details like 'imiƒô', 'nazwisko') is perfectly suited for the A1 level and the context of filling in a form. The task is clear and the correct answer is unambiguous. However, like Candidate 2, it violates guideline #9 by including instructions ('Proszƒô wype≈Çniƒá formularz.') in the question field, which is a major deviation from the prompt's requirements.                                                                                                                                                                       |
|           2 | Gemini 3 Flash  | Fill Blank      |      10 |      0.99 | This is a perfect A1 task. It aligns with the 'personal details' part of the level description. It tests a core A1 verb ('mieszkaƒá') in its first-person conjugation, which is a fundamental skill. Most importantly, the answer 'mieszkam' is unambiguous in this context, fulfilling all the prompt's guidelines flawlessly.                                                                                                                                                                                                                                            |
|           2 | Llama 4         | Multiple Choice |      10 |      0.95 | This is an outstanding response that flawlessly meets all requirements. The task directly and cleverly targets the A1 skill of filling in personal details on a form. It tests a practical and important piece of knowledge: using numerals for addresses. The distractors are well-chosen to test different forms of the number. The JSON format is perfect, adhering to all instructions, including providing the `correctAnswer` in an array.                                                                                                                          |
|           2 | Llama 4         | Fill Blank      |       5 |      1.28 | Similar to Candidate 2, this task is level-appropriate but fails on the grounds of ambiguity. While 'pochodzƒô' is a correct answer for '(am from)', so is 'jestem'. The task violates the guideline requiring a single, deterministic answer (or providing all possible correct answers), which makes it a flawed assessment item.                                                                                                                                                                                                                                        |
|           2 | Mistral Large 3 | Multiple Choice |       5 |      2.31 | The task itself, testing present tense verb conjugation, is appropriate for A1. However, it explicitly violates guideline #9 by including instructions ('Wybierz poprawnƒÖ formƒô czasownika:') within the 'question' field. This is a significant failure to follow the prompt's negative constraints. Additionally, the context of 'running in the park' is less directly related to the specified writing skills (forms, short messages) than other candidates' submissions.                                                                                             |
|           2 | Mistral Large 3 | Fill Blank      |       5 |      1.62 | The task is level-appropriate, testing the verb 'byƒá' in a personal introduction context. However, it violates a key guideline by being ambiguous. Both 'jestem' and 'pochodzƒô' are correct and common answers for '(am from)'. The instruction states the answer must be deterministic or all correct answers must be provided. This task fails on that criterion.                                                                                                                                                                                                       |
|           2 | Qwen 3 Max      | Multiple Choice |       7 |      5.41 | The candidate successfully created a task that follows the structural rules and uses a relevant context ('napisa≈Çem kr√≥tkƒÖ wiadomo≈õƒá'). However, the grammatical complexity of the sentence, which uses a subordinate clause ('≈ºe...'), and the inclusion of a conditional form ('by≈Çbym') as a distractor, pushes the difficulty slightly beyond the A1 level and closer to A2. While testing the past tense is appropriate, the overall sentence structure is more challenging than ideal for an A1 learner.                                                            |
|           2 | Qwen 3 Max      | Fill Blank      |       3 |      3.76 | The concept of sending a postcard is highly relevant to the A1 level description. However, the task contains a significant linguistic error. The Polish word for 'postcard' is 'kartka pocztowa' or 'poczt√≥wka', not 'karta'. The provided answers ('kartƒô', 'kartƒô pocztowƒÖ') are grammatically incorrect forms of the wrong noun, making the task inaccurate and misleading for a learner.                                                                                                                                                                              |
|           3 | GPT-5.2         | Multiple Choice |       9 |      1.81 | Excellent task that directly tests a skill described in the proficiency description (filling forms). The question is clear, and the distractors are very well-chosen for the A1 level, testing the difference between the country name, adjective, and nationality. It only loses a point for a minor format deviation (`correctAnswer` as a string instead of an array), which was caused by an ambiguous instruction.                                                                                                                                                   |
|           3 | GPT-5.2         | Fill Blank      |      10 |      1.44 | The task is perfectly aligned with the A1 level description, specifically referencing the context of 'writing a short, simple postcard'. The vocabulary ('wakacje') and the phrase 'byƒá na wakacjach' are core to the A1 level. The sentence is natural, the answer is unambiguous, and it follows all guidelines flawlessly.                                                                                                                                                                                                                                             |
|           3 | Gemini 3 Flash  | Multiple Choice |      10 |      1.12 | An exemplary response. The task perfectly aligns with the A1 level, testing a fundamental grammar point (1st person verb conjugation) within a natural and relevant context (personal information). It adheres to all instructions, including the 'no instructions' rule, and provides clear, unambiguous options.                                                                                                                                                                                                                                                        |
|           3 | Gemini 3 Flash  | Fill Blank      |       9 |      1    | An excellent and highly appropriate A1 task. It tests a core A1 verb ('mieszkaƒá') in the context of providing personal information, which directly relates to the level description. The sentence is simple, natural, and the answer is unambiguous.                                                                                                                                                                                                                                                                                                                      |
|           3 | Llama 4         | Multiple Choice |       3 |      1.07 | The task has a fatal flaw: the answer is not deterministic, violating a core guideline. All four options are grammatically correct city names in the locative case. The choice of 'Warszawie' is arbitrary, turning the question into a guessing game rather than a language proficiency test.                                                                                                                                                                                                                                                                            |
|           3 | Llama 4         | Fill Blank      |       1 |      1.22 | The candidate failed to produce a valid output. The generated text is an incomplete and unparseable JSON fragment, representing a complete failure to adhere to the most basic instruction.                                                                                                                                                                                                                                                                                                                                                                               |
|           3 | Mistral Large 3 | Multiple Choice |       4 |      2.65 | The task violates a key guideline by including explicit instructions ('Wybierz poprawne s≈Çowo:'). Additionally, the sentence structure ('Dzisiaj ta pogoda...') is grammatically possible but sounds slightly unnatural for a simple statement at the A1 level, where more common phrasing is expected.                                                                                                                                                                                                                                                                   |
|           3 | Mistral Large 3 | Fill Blank      |       9 |      1.44 | This is a classic and well-formed A1 task. It tests fundamental grammar ('byƒá' conjugation) and vocabulary related to personal introductions, which aligns with the 'fill in forms with personal details' part of the level description. The task is clear, natural, and has only one correct answer.                                                                                                                                                                                                                                                                     |
|           3 | Qwen 3 Max      | Multiple Choice |       2 |      5.65 | This candidate fails on multiple points. It includes a direct instruction ('Wpisz...'), violating a guideline. More importantly, the task quality is very low; it's a simple comprehension task with completely unrelated distractors, rather than a test of a specific grammar or vocabulary point suitable for writing skills.                                                                                                                                                                                                                                          |
|           3 | Qwen 3 Max      | Fill Blank      |       6 |      3.87 | The task's topic is relevant, but it has two flaws. Firstly, it violates the 'only one correct answer' rule, as 'poczt√≥wkƒô' is a common synonym for 'kartƒô pocztowƒÖ' and would also fit. Secondly, the grammatical complexity (past tense verb + multiple noun cases) is more appropriate for an A2 level than A1.                                                                                                                                                                                                                                                        |
|           4 | GPT-5.2         | Multiple Choice |       8 |     17.91 | The task is excellent and directly targets the specified A1 skill of 'filling in forms' with a relevant vocabulary question. The sentence is natural and the options are well-chosen. However, it fails to strictly follow the JSON format guideline. The `correctAnswer` field should be an array (e.g., `["dane"]`) as implied by the prompt's structure, but it was provided as a string.                                                                                                                                                                              |
|           4 | GPT-5.2         | Fill Blank      |      10 |      1.29 | Excellent task directly related to the 'writing a postcard' context from the level description. It tests a key vocabulary item ('g√≥ry') and its correct grammatical case (genitive) within a very common, natural phrase ('Pozdrawiam... z...'). The task is perfectly level-appropriate and adheres to all instructions.                                                                                                                                                                                                                                                 |
|           4 | Gemini 3 Flash  | Multiple Choice |       8 |      1.56 | This is a perfect A1 task testing fundamental verb conjugation, which is highly relevant to the level and writing skill. The context is excellent and the task is clear. However, like Candidate 1, it fails to adhere to the strict JSON format requirement for the `correctAnswer` field, providing a string ('mieszkam') instead of an array `["mieszkam"]`.                                                                                                                                                                                                           |
|           4 | Gemini 3 Flash  | Fill Blank      |       9 |      1.13 | An excellent A1 task for self-introduction, conceptually similar to Candidate 2. It tests the most fundamental verb ('byƒá') in a core sentence structure. The English cue '(am)' is simple and effective. It's a high-quality, accurate, and well-formatted response.                                                                                                                                                                                                                                                                                                     |
|           4 | Llama 4         | Multiple Choice |      10 |      1.42 | A flawless execution of the prompt. The task is a perfectly constructed A1 grammar question testing the locative case, a key skill for the level. The context of stating a location is highly relevant for writing. It adheres strictly to all guidelines, including providing a clean question without instructions and using the correct array format for the `correctAnswer` field. The distractors are excellent, representing common case-related errors.                                                                                                            |
|           4 | Llama 4         | Fill Blank      |       9 |      1.99 | A solid, classic A1 task focused on providing personal details ('Mieszkam w...'). It correctly tests a key grammatical concept (the locative case) and basic vocabulary. While slightly more generic than the postcard-themed tasks, it's highly effective, accurate, and level-appropriate.                                                                                                                                                                                                                                                                              |
|           4 | Mistral Large 3 | Multiple Choice |       6 |      2.03 | The task is a decent A1 grammar question testing the accusative case. It correctly uses an array for the `correctAnswer` field. However, it explicitly violates guideline #9 by including instructions ('Wybierz poprawne s≈Çowo:') within the 'question' field, which was forbidden. The context is also more generic than other candidates.                                                                                                                                                                                                                              |
|           4 | Mistral Large 3 | Fill Blank      |       9 |      1.68 | A very good task testing a fundamental A1 structure for self-introduction ('Mam na imiƒô... i jestem z...'). The sentence is natural and highly relevant. A minor point is deducted because an alternative answer ('pochodzƒô') is also grammatically possible, though less common at A1, creating a slight ambiguity.                                                                                                                                                                                                                                                      |
|           4 | Qwen 3 Max      | Multiple Choice |       4 |      4.47 | This candidate has multiple flaws. It violates guideline #9 by including an instruction ('Wpisz swoje imiƒô i nazwisko w formularzu:') in the 'question' field. It also fails to use the correct array format for the `correctAnswer` field. While the context of 'filling a form' is relevant, the task design is more about pragmatic comprehension than a specific grammar or vocabulary point, making it a less effective language task.                                                                                                                               |
|           4 | Qwen 3 Max      | Fill Blank      |      10 |      3.24 | An outstanding response that masterfully incorporates the 'postcard' theme from the level description. It tests a crucial vocabulary item ('karta pocztowa') and the appropriate grammatical case (accusative), making it highly relevant and perfectly targeted for an A1 learner. All instructions are followed flawlessly.                                                                                                                                                                                                                                             |
|           5 | GPT-5.2         | Multiple Choice |       9 |      1.62 | Excellent task that perfectly matches the A1 level and the specific context of 'filling in forms' from the proficiency description. The question is framed cleverly as a statement ('In the form I write: ...') to avoid giving a direct instruction, which follows the guidelines strictly. The options correctly test first-person singular verb conjugation. The only minor flaw is that the `correctAnswer` is a string instead of an array, which was specified in the prompt's example format.                                                                      |
|           5 | GPT-5.2         | Fill Blank      |      10 |      1.39 | This is an excellent task. It perfectly aligns with the A1 level description by using the context of a postcard. The vocabulary ('serdecznie') is appropriate, the sentence is natural, and the answer is unambiguous. It follows all instructions precisely.                                                                                                                                                                                                                                                                                                             |
|           5 | Gemini 3 Flash  | Multiple Choice |       9 |      1.24 | This is an excellent task, almost identical to Candidate 1. It perfectly aligns with the A1 level by testing first-person verb conjugation within the context of providing personal details, which is directly relevant to the 'filling in forms' or 'writing a postcard' skill. It avoids instructions and provides clear, unambiguous options. Like Candidate 1, its only minor imperfection is providing the `correctAnswer` as a string instead of an array.                                                                                                          |
|           5 | Gemini 3 Flash  | Fill Blank      |      10 |      1.23 | A classic and well-constructed A1 task. It tests the present tense conjugation of a core verb ('mieszkaƒá') within a common, everyday context. The sentence is natural, the level is appropriate, and the answer is unambiguous, adhering to all guidelines.                                                                                                                                                                                                                                                                                                               |
|           5 | Llama 4         | Multiple Choice |       8 |      0.62 | This is a very strong linguistic task. It correctly targets a common A1-level error in Polish (using 'to be' instead of 'to have' for age) and follows all technical guidelines, including the JSON format and avoiding instructions. The options are well-designed distractors. The only reason it doesn't score higher is that it uses a general 'daily life' context rather than referencing the specific 'form' or 'postcard' context mentioned in the proficiency description, which other candidates successfully incorporated.                                     |
|           5 | Llama 4         | Fill Blank      |       3 |      0.36 | The task is fundamentally flawed because it violates the key instruction that the answer must be deterministic and have only one correct option. The blank in 'Mieszkam w _____' could be filled with 'mie≈õcie' (city), but also with any city name in the locative case (e.g., 'Warszawie', 'Krakowie'), making the question highly ambiguous.                                                                                                                                                                                                                           |
|           5 | Mistral Large 3 | Multiple Choice |       6 |      2.66 | The task itself is a valid A1-level grammar question. However, it violates a key guideline by including an explicit instruction: 'Wybierz poprawnƒÖ formƒô czasownika:' ('Choose the correct verb form:'). The prompt explicitly stated 'Do not include any instructions for the task'. Additionally, while the context is level-appropriate, it does not specifically relate to the writing skill examples ('postcard', 'form') provided in the level description. On the positive side, the JSON format, including the `correctAnswer` as an array, is perfect.           |
|           5 | Mistral Large 3 | Fill Blank      |      10 |      1.52 | A perfect example of a foundational A1 task. It tests the verb 'byƒá' (to be) in a core context of personal introduction ('Jestem z Polski'). The task is clear, grammatically correct, and has a single, deterministic answer.                                                                                                                                                                                                                                                                                                                                            |
|           5 | Qwen 3 Max      | Multiple Choice |       4 |      3.9  | This candidate fails on several points. Firstly, it provides an instruction ('Wpisz swoje imiƒô i nazwisko w formularzu:') instead of a sentence completion task, violating a negative constraint. Secondly, the task tests reading comprehension of the instruction rather than a productive writing skill like grammar or vocabulary in context. Thirdly, the distractors are too dissimilar from the correct answer, making the task trivial. It doesn't effectively test a specific, meaningful skill aligned with the level.                                          |
|           5 | Qwen 3 Max      | Fill Blank      |      10 |      4.06 | This candidate also created an excellent task that directly references the level description's mention of writing a postcard. It correctly tests A1 vocabulary ('poczt√≥wka') and the necessary grammatical case (accusative), making it a well-designed and relevant question.                                                                                                                                                                                                                                                                                            |
|           6 | GPT-5.2         | Multiple Choice |       7 |     21.75 | The task is grammatically correct and appropriate for the A1 level, testing a common preposition of direction ('chodziƒá na'). However, it deviates from the specified JSON format by including an extra field ('question_en') and providing the 'correctAnswer' as a string instead of an array. The task itself is solid for A1 learners.                                                                                                                                                                                                                                |
|           6 | GPT-5.2         | Fill Blank      |      10 |      1.06 | The task is excellent. It perfectly aligns with the A1 level description by using vocabulary and a sentence structure ('Pozdrawiam z...') typical for writing a postcard. The question tests both vocabulary ('g√≥ry') and a key grammatical concept for this level (the genitive case after the preposition 'z'). The answer is unambiguous and the format is correct.                                                                                                                                                                                                    |
|           6 | Gemini 3 Flash  | Multiple Choice |       9 |      1.73 | This is an excellent A1-level task. It tests a fundamental skill (conjugation for 'nazywaƒá siƒô') in a very common and natural context (introductions). The question is clear, unambiguous, and perfectly suited for the level. The only flaw is a minor format deviation where 'correctAnswer' is a string instead of an array as specified in the prompt's example.                                                                                                                                                                                                      |
|           6 | Gemini 3 Flash  | Fill Blank      |      10 |      1.27 | This is another excellent example of a core A1 task. It's very similar to Candidate 2 but uses the phrase 'Nazywam siƒô...' instead of 'Mam na imiƒô...'. It correctly tests the verb 'byƒá' in the context of personal introductions and origin, which is fundamental for this level. The task is clear, accurate, and adheres to all guidelines.                                                                                                                                                                                                                           |
|           6 | Llama 4         | Multiple Choice |       7 |      2.54 | The task is well-constructed, testing the genitive case after a preposition of origin ('z Niemiec'), and it adheres perfectly to the JSON format. However, the sentence structure is too complex for the A1 level. A compound sentence with a relative clause ('...kt√≥rzy sƒÖ z...') is more characteristic of the A2 level, potentially overwhelming an A1 learner and testing reading comprehension more than the specific grammar point.                                                                                                                                |
|           6 | Llama 4         | Fill Blank      |       5 |      1.33 | While the topic (personal details) is A1 and the format is correct, the Polish sentence is grammatically incorrect and unnatural. The phrase 'Mam na nazwisko...' is not followed by both a first and last name. One would say 'Mam na nazwisko Nowak' or 'Nazywam siƒô Anna Nowak'. This inaccuracy makes it a poor and confusing task for a language learner.                                                                                                                                                                                                            |
|           6 | Mistral Large 3 | Multiple Choice |       6 |      2.35 | This candidate violates a key guideline by including an instruction ('Wybierz poprawnƒÖ formƒô czasownika:') within the 'question' field. While the JSON format is otherwise correct, and the task tests a core A1 skill (verb conjugation), the lack of an explicit subject pronoun ('ja', 'my') makes the question slightly ambiguous, although 'idƒô' is the most probable answer in a test context. The prompt required a deterministic answer.                                                                                                                          |
|           6 | Mistral Large 3 | Fill Blank      |      10 |      1.53 | This is a quintessential A1 task. It tests a fundamental concept: personal introductions and stating one's origin ('jestem z Polski'). The grammar is simple and correct, the vocabulary is core A1, and the context aligns with the 'filling in personal details' part of the proficiency description. The JSON format is valid and follows all instructions.                                                                                                                                                                                                            |
|           6 | Qwen 3 Max      | Multiple Choice |       5 |      4.35 | This task directly tests the ability to recognize personal details for a form, which aligns well with the proficiency description. However, it fails on several guidelines: the 'question' is an explicit instruction, not a sentence for completion; the 'correctAnswer' is a string instead of an array; and the distractors are too simple and unrelated to the correct answer, making it a test of basic vocabulary recognition rather than a nuanced language choice.                                                                                                |
|           6 | Qwen 3 Max      | Fill Blank      |      10 |      4.86 | An outstanding task that directly and creatively uses the example from the level description ('writing a postcard'). It tests a relevant vocabulary word ('poczt√≥wka') and the accusative case, which is a crucial grammatical point for A1/A2 learners. The use of the past tense ('wys≈Ça≈Çem') is appropriate and often introduced at this stage. The format is correct.                                                                                                                                                                                                 |
|           7 | GPT-5.2         | Multiple Choice |       8 |     15.35 | The task is a classic, effective A1 grammar question testing prepositions with cities. It is simple, clear, and adheres to most instructions. It loses points for a minor format deviation ('correctAnswer' is a string, not an array as in the prompt's example) and for being on the very basic end of the A1 spectrum, though perfectly level-appropriate.                                                                                                                                                                                                             |
|           7 | GPT-5.2         | Fill Blank      |       8 |      1.14 | The task is highly relevant to the A1 level description (writing a postcard). However, it violates the 'only one correct answer' rule, as 'znad morza' is an equally valid and common alternative to fill the blank, which could be constructed from two words instead of the single word 'nadmorza'.                                                                                                                                                                                                                                                                     |
|           7 | Gemini 3 Flash  | Multiple Choice |       8 |      1.56 | This is a linguistically sophisticated and well-designed task. It cleverly uses grammatical gender agreement ('Jaki' + masculine noun) to create a single correct answer among contextually plausible options. This tests a deeper understanding than simple vocabulary recall. Its main flaw is violating the 'single sentence' rule by using two sentences to provide context. Despite this, the quality and cleverness of the question design are very high.                                                                                                           |
|           7 | Gemini 3 Flash  | Fill Blank      |      10 |      1.6  | An excellent A1-level task that uses the common phrase 'Nazywam siƒô' for self-introduction. It correctly tests the verb 'byƒá' in a core context for beginners. The task is clear, accurate, and has a single correct answer, perfectly adhering to all guidelines.                                                                                                                                                                                                                                                                                                        |
|           7 | Llama 4         | Multiple Choice |       1 |      0.86 | This task is fundamentally flawed. It violates the core principle of having a single correct answer, as all four options are grammatically and semantically valid ways to complete the sentence. This makes the question non-deterministic and unusable. It also includes a forbidden instruction ('Uzupe≈Çnij zdanie:').                                                                                                                                                                                                                                                  |
|           7 | Llama 4         | Fill Blank      |      10 |      0.98 | A perfect A1-level task. It is concise, focuses on the fundamental skill of self-introduction, and tests the essential verb 'byƒá'. The answer is unambiguous, the sentence is natural, and all instructions, including the format and accurate English hint, are followed precisely.                                                                                                                                                                                                                                                                                      |
|           7 | Mistral Large 3 | Multiple Choice |       5 |      2.06 | The core task of conjugating a common verb is appropriate for A1. However, the candidate fails to follow a key negative constraint by including an instruction ('Wybierz poprawnƒÖ formƒô czasownika:') directly in the 'question' field, which was explicitly forbidden.                                                                                                                                                                                                                                                                                                   |
|           7 | Mistral Large 3 | Fill Blank      |      10 |      1.86 | An excellent A1-level task that tests a core skill (introducing oneself and stating origin) with the fundamental verb 'byƒá' (to be). The sentence is natural, and the answer is unambiguous. It perfectly follows the instructions, although the English hint '(am from)' is slightly redundant.                                                                                                                                                                                                                                                                          |
|           7 | Qwen 3 Max      | Multiple Choice |       6 |      4.4  | This candidate shows excellent understanding of the level description by creating a task directly related to filling out a form with personal details. The context is perfect. However, like Candidate 2, it violates the rule against including instructions in the question ('Wpisz swoje imiƒô i nazwisko w formularzu:'). The high relevance to the prompt's proficiency description gives it a slight edge over Candidate 2.                                                                                                                                          |
|           7 | Qwen 3 Max      | Fill Blank      |       9 |      4.43 | A very good and relevant task, directly referencing the context of sending a postcard. It correctly tests vocabulary and the accusative case. The use of the past tense and the sentence's overall complexity place it at the higher end of the A1 level, making it slightly more challenging than a typical introductory task.                                                                                                                                                                                                                                           |
|           8 | GPT-5.2         | Multiple Choice |       9 |     15.53 | Excellent task that perfectly matches the A1 level and the 'filling in a form' context. It tests a relevant grammar point (number declension) with good distractors. The only minor flaw is that the `correctAnswer` field is a string instead of an array of strings, which could be interpreted as a slight deviation from the ambiguous instruction format.                                                                                                                                                                                                            |
|           8 | GPT-5.2         | Fill Blank      |      10 |      1.2  | This candidate is excellent. It perfectly adheres to all instructions, including the JSON format. The task directly tests vocabulary relevant to the A1 level description ('fill in forms with personal details'). The sentence is natural, grammatically correct, and the answer is unambiguous. It's a high-quality, level-appropriate task.                                                                                                                                                                                                                            |
|           8 | Gemini 3 Flash  | Multiple Choice |       7 |      1.37 | The vocabulary task is perfectly suited for A1 and directly addresses the 'filling in a form' context specified in the prompt. The answer is clear and the distractors are relevant. However, it fails on two structural rules by including an instruction ('Proszƒô wype≈Çniƒá formularz.') and not being a single sentence, which were explicit negative constraints.                                                                                                                                                                                                      |
|           8 | Gemini 3 Flash  | Fill Blank      |       9 |      1.56 | An excellent candidate that follows all instructions. The task tests a core A1 verb ('mieszkaƒá' - to live) in the context of providing personal information, which is highly relevant for the level. The sentence is natural, grammatically correct, and the answer is deterministic. It is a well-constructed and appropriate task.                                                                                                                                                                                                                                      |
|           8 | Llama 4         | Multiple Choice |       3 |      1.27 | This task violates several key guidelines. It is not a 'single sentence' but a short paragraph. Most importantly, it fails the 'deterministic' rule, as there are at least two semantically plausible answers ('przyjaci√≥≈Çmi' and 'psem'), making it a poor multiple-choice question. The context is also not aligned with the 'filling in a form' skill.                                                                                                                                                                                                                 |
|           8 | Llama 4         | Fill Blank      |       1 |      0.79 | This candidate fails on multiple critical points. The generated sentence 'Mam na ______________ 'Cze≈õƒá, jak siƒô masz?'' is grammatically incorrect and nonsensical in Polish. It fails to include the required English translation of the missing word/phrase. Furthermore, one of the 'correctAnswer' options, 'imie', is misspelled (it should be 'imiƒô'). The output is unusable.                                                                                                                                                                                      |
|           8 | Mistral Large 3 | Multiple Choice |       6 |      2.3  | The task correctly tests a core A1 grammar point (verb conjugation) with good options. However, it explicitly violates the guideline 'Do not include any instructions for the task' by adding 'Wybierz poprawne s≈Çowo:'. The JSON format for the correct answer is an array, which is a better interpretation of the instructions than a string.                                                                                                                                                                                                                          |
|           8 | Mistral Large 3 | Fill Blank      |       9 |      1.69 | A very strong candidate. The task tests fundamental A1 grammar (the verb 'to be') in the context of personal introductions. The sentence is natural and correct, and it fully adheres to the format requirements. While not directly referencing postcards or forms, it aligns perfectly with the general A1 theme of sharing personal details.                                                                                                                                                                                                                           |
|           8 | Qwen 3 Max      | Multiple Choice |       2 |      3.71 | This candidate has critical flaws. It violates the 'exactly four options' rule by providing a duplicate option ('szed≈Çem'), invalidating the task format. The topic (past tense of verbs of motion) is arguably better suited for the A2 level than A1. Furthermore, the context does not relate to the specified writing skill of filling in forms.                                                                                                                                                                                                                      |
|           8 | Qwen 3 Max      | Fill Blank      |       5 |      3.39 | The concept for the task is perfect, as it directly relates to the level description ('write a short, simple postcard'). However, the execution is flawed. The provided 'correctAnswer' ('kartƒô') is incorrect. The correct word for 'postcard' is 'kartka pocztowa' or 'kartka', and its accusative form is 'kartkƒô'. 'Karta' means a different type of card (e.g., credit card). This grammatical error in the answer is a significant failure for a language task.                                                                                                     |
|           9 | GPT-5.2         | Multiple Choice |       9 |     12.73 | Excellent adherence to the instructions. The task correctly targets the A1 level by testing prepositions with cities ('w Krakowie'), a core A1 grammar point. It cleverly incorporates the 'filling a form' context by framing the sentence with 'W formularzu piszƒô:', which respects the 'single sentence' and 'no instructions' guidelines. The options are well-chosen distractors. The only minor imperfection is using a string for 'correctAnswer' when an array may have been intended by the ambiguous prompt, but this is a negligible issue.                   |
|           9 | GPT-5.2         | Fill Blank      |       9 |      1.08 | A great task that directly relates to the A1 skill of writing a postcard. It tests a vocabulary word ('pla≈ºa') and the genitive case after 'z'. While 'jestem z Polski' is core A1, applying the genitive rule to a new noun can be challenging for the earliest A1 learners, making it a high-A1 task. The format is perfect and the question is well-formed.                                                                                                                                                                                                            |
|           9 | Gemini 3 Flash  | Multiple Choice |       4 |      1.85 | The task is a decent A1-level vocabulary question related to personal details. However, it violates two key guidelines. It uses two sentences ('Proszƒô wype≈Çniƒá formularz. Moje ______ to Jan.') instead of the required one, and the first sentence is an explicit instruction, which breaks the 'no instructions' rule.                                                                                                                                                                                                                                                 |
|           9 | Gemini 3 Flash  | Fill Blank      |      10 |      1.47 | A perfect A1 task, functionally very similar to Candidate 2. It focuses on the core skill of introducing oneself and stating origin, testing the fundamental conjugation of 'byƒá' ('jestem'). The sentence is natural and the answer is unambiguous and essential for any A1 learner.                                                                                                                                                                                                                                                                                     |
|           9 | Llama 4         | Multiple Choice |       3 |      1.37 | This candidate fails on two major points. First, the level is incorrect. It tests the instrumental case ('jest studentkƒÖ'), which is an A2-level concept, not A1. An A1 learner would typically use the nominative case. Second, it violates the 'single sentence' rule by providing two sentences in the 'question' field.                                                                                                                                                                                                                                               |
|           9 | Llama 4         | Fill Blank      |       9 |      1.39 | A solid, well-leveled task. The context of stating a birth year aligns perfectly with the A1 skill of providing personal details. It tests the use of the preposition 'w' for dates, an essential concept. The task is slightly simpler than others, focusing on a single preposition, but it remains a very good question.                                                                                                                                                                                                                                               |
|           9 | Mistral Large 3 | Multiple Choice |       6 |      2.12 | The task itself is a very good A1-level question on present tense verb conjugation ('pijƒô'). The context of a daily routine is appropriate. However, it explicitly violates the instruction 'Do not include any instructions for the task' by adding 'Wybierz poprawnƒÖ formƒô czasownika:' to the question field. This is a significant deviation from the guidelines.                                                                                                                                                                                                     |
|           9 | Mistral Large 3 | Fill Blank      |      10 |      1.54 | A perfect A1 task. It targets the core skill of providing personal details by testing the first-person conjugation of 'byƒá', the most fundamental verb in Polish. The sentence is natural, common, and the answer 'jestem' is unambiguously correct and central to A1 proficiency.                                                                                                                                                                                                                                                                                        |
|           9 | Qwen 3 Max      | Multiple Choice |       4 |      5.02 | This candidate violates the 'no instructions' guideline by including the command 'Wpisz swoje imiƒô i nazwisko w formularzu:'. Furthermore, the task design is weak for a language test; it primarily tests the user's ability to understand the instruction and recognize a name, rather than testing a specific grammatical or vocabulary point within the sentence itself, as the blank represents the entire answer.                                                                                                                                                   |
|           9 | Qwen 3 Max      | Fill Blank      |      10 |      3.16 | An excellent and highly relevant task. The context of sending a postcard is taken directly from the A1 proficiency description. It effectively tests both A1 vocabulary ('poczt√≥wka') and a key grammatical concept, the accusative case, which is fundamental for forming simple sentences. The format and execution are flawless.                                                                                                                                                                                                                                       |
|          10 | GPT-5.2         | Multiple Choice |      10 |      9.7  | The candidate produced a perfectly valid JSON. The task is excellent for A1, testing a core grammatical concept (1st person verb conjugation) in a highly relevant context (personal information). It adheres to all instructions, including having a single, deterministic correct answer and avoiding instructions within the question.                                                                                                                                                                                                                                 |
|          10 | GPT-5.2         | Fill Blank      |       7 |      1.18 | The task is good and directly relates to the postcard-writing context in the prompt. However, it violates guideline #7 regarding a single correct answer. While 'przesy≈Çam' is a very good fit, the verb 'wysy≈Çam' is also a correct and common alternative in this context. A truly deterministic task would either need a context that excludes one option or would have to list both in the correctAnswer array.                                                                                                                                                       |
|          10 | Gemini 3 Flash  | Multiple Choice |      10 |      1.16 | This is an exemplary A1 task that perfectly adheres to all instructions. The JSON is valid. The question tests a fundamental grammatical point (preposition 'w' for location with cities) in a context directly aligned with the A1 skill of providing personal details. The task is clear, natural, and has only one correct answer among well-chosen distractors.                                                                                                                                                                                                       |
|          10 | Gemini 3 Flash  | Fill Blank      |      10 |      1.64 | This is a perfect example of a fundamental A1 task. It tests the core verb 'mieszkaƒá' (to live) in the context of providing personal information, which is central to the A1 level. The task is clear, the answer is unambiguous, and it fully adheres to all instructions.                                                                                                                                                                                                                                                                                               |
|          10 | Llama 4         | Multiple Choice |       2 |      2.05 | The JSON format is valid, but the task is fundamentally broken. It fails the core requirement of having a single correct answer. All four options are grammatically and semantically correct completions for the sentence 'gram tak≈ºe w _______' (I also play...). This makes it an invalid multiple-choice question.                                                                                                                                                                                                                                                     |
|          10 | Llama 4         | Fill Blank      |       7 |      0.52 | The sentence itself is correct and appropriate for the A1 level. However, the candidate creates ambiguity, which is explicitly forbidden by the instructions. The English clue '(am from)' translates more directly to 'jestem z'. While 'pochodzƒô z' (I come from/originate from) also fits the sentence, it doesn't match the clue as well as 'jestem z' does, making the task confusing for the learner.                                                                                                                                                               |
|          10 | Mistral Large 3 | Multiple Choice |       3 |      2.37 | While the JSON format is valid, the task itself is flawed. It violates the instruction to not include instructions in the question ('Wybierz poprawnƒÖ formƒô czasownika:'). More critically, the question is ambiguous; without an explicit subject, multiple options are grammatically correct depending on the implied pronoun (ja, ty, oni, my), violating the determinism requirement.                                                                                                                                                                                 |
|          10 | Mistral Large 3 | Fill Blank      |      10 |      1.62 | This is an excellent A1-level task. It tests a fundamental verb ('byƒá') in the context of a personal introduction, which aligns perfectly with the level description ('fill in forms with personal details'). The clue '(am from)' makes the answer 'jestem' completely unambiguous. The format is perfect.                                                                                                                                                                                                                                                               |
|          10 | Qwen 3 Max      | Multiple Choice |       8 |      4.18 | The candidate provided a valid JSON with a good A1-level vocabulary task. The question is clear and has a single logical answer. The context of 'writing a letter' is appropriate, although it is quite close to the 'writing a postcard' example mentioned in the prompt's proficiency description, which makes it slightly less creative. The use of the past tense is acceptable for the A1 level.                                                                                                                                                                     |
|          10 | Qwen 3 Max      | Fill Blank      |      10 |      4.52 | This is a flawless candidate. It tests a key vocabulary item ('poczt√≥wka') directly related to the prompt's context. Importantly, it also implicitly tests grammar, as the learner must provide the noun in the correct accusative case ('poczt√≥wkƒô'). The English clue makes the answer deterministic. It perfectly follows all guidelines.                                                                                                                                                                                                                              |
|          11 | GPT-5.2         | Multiple Choice |       9 |     15.13 | The task is excellent for the A1 level, testing the instrumental case for nationality, which aligns with providing personal details. It correctly follows most guidelines, including creating a clear, unambiguous question without instructions. The only minor flaw is that the 'correctAnswer' field is a string instead of an array, which was specified in the prompt's example format.                                                                                                                                                                              |
|          11 | GPT-5.2         | Fill Blank      |      10 |      1.1  | An excellent task that perfectly aligns with the A1 level description of 'writing a short, simple postcard'. The sentence is natural, and it correctly tests the use of the genitive case after the preposition 'z', a key grammatical point for this context. The format is valid and the answer is unambiguous.                                                                                                                                                                                                                                                         |
|          11 | Gemini 3 Flash  | Multiple Choice |       9 |      1.13 | This is a very strong candidate. The task is a classic and effective A1 exercise, testing the first-person singular conjugation of a common verb ('mieszkaƒá') in a personal introduction context. It adheres to almost all guidelines, presenting a clean question without instructions. Similar to Candidate 1, its only minor imperfection is the 'correctAnswer' format, which is a string instead of the requested array.                                                                                                                                             |
|          11 | Gemini 3 Flash  | Fill Blank      |      10 |      1.22 | An excellent A1-level task that aligns with the 'personal details' part of the proficiency description. The sentence is a very common and useful phrase for beginners. It effectively tests the conjugation of the high-frequency verb 'mieszkaƒá' (to live/reside) in a natural context. The format is valid and the answer is unambiguous.                                                                                                                                                                                                                               |
|          11 | Llama 4         | Multiple Choice |      10 |      1.84 | This candidate provides a perfect response. It adheres to all instructions meticulously: the JSON format is valid and correct, the question is a single sentence without instructions, and there are four clear options with one correct answer. The task itself is excellent for the A1 level, testing the distinction between a conjugated verb and a verbal noun ('bieganie') in the context of hobbies, which is a common and appropriate A1 topic.                                                                                                                   |
|          11 | Llama 4         | Fill Blank      |       1 |      1.16 | The task is fundamentally flawed. The resulting sentence, 'Mam na imiƒô 30 lat' ('My name is 30 years old'), is nonsensical as it incorrectly merges two distinct phrases ('Mam na imiƒô...' and 'Mam X lat'). This would severely confuse a learner. Additionally, the English cue '(imie)' is misspelled. The only positive aspect is the valid JSON structure.                                                                                                                                                                                                           |
|          11 | Mistral Large 3 | Multiple Choice |       6 |      2.35 | The task, which tests present tense verb conjugation, is linguistically appropriate for A1. However, it violates a key negative constraint by including an explicit instruction ('Wybierz poprawnƒÖ formƒô czasownika:') within the 'question' field, which the prompt strictly forbade. While the JSON format is correct, this failure to follow a critical instruction significantly lowers its quality.                                                                                                                                                                  |
|          11 | Mistral Large 3 | Fill Blank      |      10 |      1.65 | A perfect A1 task focused on providing personal details, as mentioned in the level description. It tests the first-person conjugation of 'byƒá' (to be), one of the most fundamental verbs for any beginner. The sentence is highly natural and common. The format is correct and the answer is clear.                                                                                                                                                                                                                                                                     |
|          11 | Qwen 3 Max      | Multiple Choice |       5 |      4.42 | While the task cleverly tests the practical skill of filling out a form, it violates two major guidelines. First, it includes an instruction ('Wpisz swoje imiƒô i nazwisko w formularzu:') in the 'question' field. Second, the task context ('fill in forms with personal details') is almost a direct copy of the example given in the proficiency description, which the prompt asked to avoid. The JSON format also has a minor error ('correctAnswer' as a string).                                                                                                  |
|          11 | Qwen 3 Max      | Fill Blank      |      10 |      3.63 | An outstanding task that directly engages with the 'postcard' context from the prompt's guidelines. It correctly tests a key vocabulary item ('poczt√≥wka') and its required grammatical form in the accusative case, which is a crucial concept for A1 learners constructing simple sentences. The format is perfect.                                                                                                                                                                                                                                                     |
|          12 | GPT-5.2         | Multiple Choice |       9 |     11.04 | A very strong candidate. The task is an excellent, classic A1 level question testing prepositions of place ('w' vs 'na'). It's clear, deterministic, and aligns perfectly with the proficiency level of providing personal details (where one lives). The only minor flaw is that the `correctAnswer` field is a string instead of an array, which was suggested in the prompt's example format.                                                                                                                                                                          |
|          12 | GPT-5.2         | Fill Blank      |       8 |      1.21 | The task is highly relevant to the A1 level description (writing a postcard). However, it violates the 'only one correct answer' rule, as 'pozdrawiamy' (we greet) would also be grammatically correct in a plural context, introducing slight ambiguity.                                                                                                                                                                                                                                                                                                                 |
|          12 | Gemini 3 Flash  | Multiple Choice |      10 |      1.27 | This is an outstanding candidate and the best of the set. The task perfectly targets the A1 level by combining personal introduction ('Mam na imiƒô Marek') with a core grammar point (1st person singular verb conjugation). It directly reflects the proficiency description of being able to fill in personal details. The task is unambiguous, well-contextualized, and follows all major guidelines. The minor format deviation in `correctAnswer` (string vs. array) is negligible given the superior quality of the linguistic task.                                |
|          12 | Gemini 3 Flash  | Fill Blank      |      10 |      1.12 | Excellent task. It aligns perfectly with the A1 level by testing a core verb ('mieszkam' - to live) in the context of providing personal details. The sentence is natural, grammatically correct, and the answer is unambiguous, following all guidelines.                                                                                                                                                                                                                                                                                                                |
|          12 | Llama 4         | Multiple Choice |       3 |      0.55 | This candidate fails on a critical requirement for a good multiple-choice question: determinism. The question asks for a preferred activity in a park, but multiple options are plausible. Both 'czytaƒá ksiƒÖ≈ºkƒô' (reading a book) and the marked answer 'jechaƒá na rowerze' (riding a bike) are very common and contextually appropriate. This ambiguity makes it a poorly designed test item.                                                                                                                                                                            |
|          12 | Llama 4         | Fill Blank      |      10 |      1.62 | Excellent task. It correctly tests the fundamental A1 verb 'jestem' in the context of providing personal details. The sentence is natural, the answer is unambiguous, and it fully adheres to all instructions.                                                                                                                                                                                                                                                                                                                                                           |
|          12 | Mistral Large 3 | Multiple Choice |       5 |      4.43 | The linguistic task itself, testing 1st person singular verb conjugation, is appropriate for A1. However, the candidate fails to follow a strict negative constraint: The 'question' field includes an instruction ('Wybierz poprawnƒÖ formƒô czasownika:'), which was explicitly forbidden by guideline #9. This is a significant deviation from the instructions.                                                                                                                                                                                                         |
|          12 | Mistral Large 3 | Fill Blank      |      10 |      1.45 | Excellent task. It's grammatically correct, natural, and perfectly aligned with the A1 level by testing a fundamental verb ('jestem') in the context of personal introductions, as mentioned in the proficiency description. The answer is unambiguous.                                                                                                                                                                                                                                                                                                                   |
|          12 | Qwen 3 Max      | Multiple Choice |       8 |      2.84 | A good task that tests verb tense recognition based on a time marker ('Wczoraj'). The level is high A1 or borderline A2, as past tense can be complex, but the choice is made simple and clear. The task adheres to all guidelines except for the minor format inconsistency of `correctAnswer` being a string rather than an array.                                                                                                                                                                                                                                      |
|          12 | Qwen 3 Max      | Fill Blank      |      10 |      4.13 | Excellent task. It directly tests vocabulary ('poczt√≥wkƒô') related to the A1 writing skill of 'writing a short, simple postcard'. The task correctly requires the accusative case, making it a good test of both vocabulary and basic grammar for the level. The answer is unambiguous.                                                                                                                                                                                                                                                                                   |
|          13 | GPT-5.2         | Multiple Choice |       9 |     24.49 | This is a high-quality task. The question is grammatically correct, level-appropriate for A1, and tests a fundamental concept (prepositions with cities). It successfully follows nearly all instructions, including the crucial one of not adding extra instructions to the question. The only minor deviation is that the `correctAnswer` field is a string instead of an array, which was a subtle point in the prompt.                                                                                                                                                |
|          13 | GPT-5.2         | Fill Blank      |       9 |      2.28 | The task is excellent and directly relates to the A1 level description of writing a postcard ('Pozdrawiam... z...'). It tests a key grammatical point (pronoun case). However, it loses one point for slight ambiguity. While 'Ciƒô' (informal you) is the most common and expected answer for an A1 learner, 'was' (formal/plural you) would also be grammatically correct, which slightly violates the strict 'only one correct answer' rule.                                                                                                                            |
|          13 | Gemini 3 Flash  | Multiple Choice |       9 |      1.26 | This is another high-quality task, very similar to Candidate 1. It correctly identifies a core A1 grammar point (prepositions) and presents it in a clear, simple sentence without any extraneous instructions. It fully meets the level and context requirements. Like Candidate 1, its only minor imperfection is providing the `correctAnswer` as a string rather than an array as suggested in the prompt's detailed description.                                                                                                                                     |
|          13 | Gemini 3 Flash  | Fill Blank      |      10 |      1.28 | This is an excellent, unambiguous A1 task. It combines two core A1 skills: stating one's name and stating where one lives. It correctly tests the conjugation of the essential verb 'mieszkaƒá' (to live). The task is perfectly aligned with the level's focus on personal details and follows all instructions flawlessly.                                                                                                                                                                                                                                               |
|          13 | Llama 4         | Multiple Choice |      10 |      0.48 | This is an excellent response that adheres to all instructions perfectly. The task tests a core A1 grammar point (verb 'mieƒá' for age) in a natural context. It correctly omits any instructions from the question, provides four clear options, and uses the specified JSON format, including the `correctAnswer` as an array. While the question consists of two short sentences, they form a single cohesive context for the blank, which is a perfectly acceptable and common format that fully respects the spirit of the instruction.                               |
|          13 | Llama 4         | Fill Blank      |      10 |      1.36 | This is an exemplary A1 task. It tests one of the most fundamental phrases a learner acquires ('Mam na imiƒô...'). The task is perfectly deterministic with only one correct answer ('imiƒô') and directly corresponds to the level description's mention of filling in forms with personal details. The format is correct and the task is clear.                                                                                                                                                                                                                           |
|          13 | Mistral Large 3 | Multiple Choice |       6 |      2.27 | The core task (verb conjugation) is appropriate for A1. However, the candidate failed to follow a strict guideline by including an instruction in the target language ('Wybierz poprawnƒÖ formƒô czasownika:') within the 'question' field. The prompt explicitly stated 'Do not include any instructions for the task'. This violation significantly lowers the score, despite the otherwise decent content and correct JSON format.                                                                                                                                       |
|          13 | Mistral Large 3 | Fill Blank      |      10 |      1.45 | This is a perfect A1 task. The sentence 'Mam na imiƒô Anna i ____ z Polski' is a fundamental introductory phrase. The answer 'jestem' is unambiguous and tests the core verb 'to be'. It aligns perfectly with the A1 skill of providing personal details, as mentioned in the level description.                                                                                                                                                                                                                                                                          |
|          13 | Qwen 3 Max      | Multiple Choice |       7 |      5.21 | This candidate shows excellent conceptual understanding by creating a task that directly relates to the 'fill in forms' part of the A1 proficiency description. The task is clever and highly relevant. However, like Candidate 2, it violates the strict rule against including instructions ('Wpisz swoje imiƒô i nazwisko w formularzu:'). Because the task's concept is so well-aligned with the prompt's core requirement, it scores slightly higher than Candidate 2, but the rule violation is still a major flaw.                                                  |
|          13 | Qwen 3 Max      | Fill Blank      |       7 |      3.31 | The task is relevant to the postcard theme in the level description. However, it fails on the strict guideline to 'avoid ambiguity' and have 'only one correct answer'. Besides the correct answer 'kartƒô pocztowƒÖ', the synonym 'poczt√≥wkƒô' is also a perfectly valid and common word that fits the blank, creating two possible correct answers.                                                                                                                                                                                                                        |
|          14 | GPT-5.2         | Multiple Choice |      10 |     19.1  | This is an excellent task that perfectly aligns with all instructions. It directly tests a skill mentioned in the A1 proficiency description ('fill in forms'). The question tests a fundamental grammar point (nominative case) in a clear, unambiguous context. The vocabulary is appropriate for A1, and the distractors are well-chosen grammatical variations of the same root word. The JSON is valid and follows the specified structure.                                                                                                                          |
|          14 | GPT-5.2         | Fill Blank      |       8 |      1.29 | This is a solid A1 task testing a core verb ('mieszkaƒá') and personal information. However, the sentence structure itself is slightly ambiguous, as another common verb like 'pracujƒô' (I work) could also fit the blank. The task's unambiguity relies entirely on the English hint '(live)' rather than a tightly constrained sentence context.                                                                                                                                                                                                                         |
|          14 | Gemini 3 Flash  | Multiple Choice |       7 |      1.55 | The task has excellent context and vocabulary directly related to the A1 skill of filling in forms. However, it explicitly violates the guideline that 'The task must consist of a single sentence' by using two sentences. The first sentence also acts as a soft instruction ('Proszƒô wype≈Çniƒá formularz.'), which is borderline. Additionally, the 'correctAnswer' field uses a string instead of an array, a minor format deviation from the prompt's example.                                                                                                        |
|          14 | Gemini 3 Flash  | Fill Blank      |       9 |      1    | An excellent task testing the most fundamental Polish verb, 'byƒá' (to be), in a personal information context. It aligns perfectly with the A1 level. It loses one point because the sentence could plausibly be completed with 'pochodzƒô' (I come from), making it reliant on the English hint '(am)' for disambiguation.                                                                                                                                                                                                                                                 |
|          14 | Llama 4         | Multiple Choice |       9 |      2.03 | This is a very well-designed task. It tests vocabulary in a clear context, and all options are grammatically parallel (all are nouns in the locative case), which effectively isolates the vocabulary knowledge being tested. The JSON format is perfect, including the use of an array for the 'correctAnswer'. The only minor drawback is that the context (student life), while valid for A1, is less directly related to the specific skill description ('filling forms') than other candidates, but it fully adheres to the prompt's guidelines.                     |
|          14 | Llama 4         | Fill Blank      |      10 |      1.22 | This is an exemplary task. It tests a fundamental, high-frequency idiom ('mieƒá na imiƒô') that is essential for A1 learners. The key strength is its perfect lack of ambiguity; 'imiƒô' is the only word that can grammatically and idiomatically complete the sentence, making the English hint a confirmation rather than a necessary clue. It perfectly follows all instructions.                                                                                                                                                                                        |
|          14 | Mistral Large 3 | Multiple Choice |       6 |      2.23 | The candidate fails to follow a key negative constraint by including an explicit instruction ('Wybierz poprawne s≈Çowo:') in the 'question' field, which was forbidden. While the grammar point (gender agreement) is appropriate for A1, the task's relevance to the specified writing skill ('filling forms' or 'writing postcards') is low. The JSON format is correct.                                                                                                                                                                                                 |
|          14 | Mistral Large 3 | Fill Blank      |       8 |      1.58 | This is a good A1-level question, very similar to Candidate 1. It correctly tests a fundamental verb in the context of a personal introduction. The score is slightly reduced because, like Candidate 1, the sentence allows for other logical answers (e.g., 'pracujƒô' - I work), making it fully dependent on the English hint for its single correct answer.                                                                                                                                                                                                           |
|          14 | Qwen 3 Max      | Multiple Choice |       7 |      3.17 | The task context (filling a form) is perfectly aligned with the prompt. However, the task design is flawed from a pedagogical standpoint. The correct option is in the locative case ('formularzu'), while the distractors are in the nominative case. This conflates a vocabulary test with a grammar test, which can be confusing for an A1 learner. A better design would have all options in the same grammatical case. The 'correctAnswer' field uses a string instead of an array, a minor deviation from the prompt's example.                                     |
|          14 | Qwen 3 Max      | Fill Blank      |       7 |      3.7  | While the task cleverly uses the 'postcard' theme from the level description, it tests grammar (past tense, accusative case) and vocabulary ('nadmorskiego kurortu') that are generally considered high-A1 or even A2. The core of A1 focuses on the present tense and more basic vocabulary. The sentence is also not inherently unambiguous without the hint.                                                                                                                                                                                                           |
|          15 | GPT-5.2         | Multiple Choice |       9 |     20.76 | A very strong task that correctly tests A1 grammar (genitive case) within the specified context of filling out a form. It follows almost all guidelines, with the only minor issue being the `correctAnswer` field not being an array, which is understandable given the ambiguous instruction. The task is clear, level-appropriate, and directly relevant to the prompt's writing skill requirement.                                                                                                                                                                    |
|          15 | GPT-5.2         | Fill Blank      |       9 |      2.07 | The task is excellent for the A1 level, testing the core verb 'mieszkaƒá' (to live) in a personal information context. It's grammatically sound, natural, and has a single, unambiguous answer. It perfectly aligns with the required proficiency level and follows all formatting rules.                                                                                                                                                                                                                                                                                  |
|          15 | Gemini 3 Flash  | Multiple Choice |      10 |      1.56 | An excellent and creative interpretation of the prompt. The task perfectly simulates the A1 writing skill of filling in a form by testing relevant vocabulary ('nazwisko'). The two-sentence structure effectively sets the context without being a distracting meta-instruction. It is highly natural, deterministic, and precisely aligned with both the CEFR level and the specific guidelines. This is a model answer.                                                                                                                                                |
|          15 | Gemini 3 Flash  | Fill Blank      |       9 |      1.28 | A very strong candidate that tests the essential A1 fixed phrase 'mieƒá na imiƒô' (to be named). This is a crucial piece of vocabulary for introductions. The answer is deterministic and the context is highly relevant. It's an effective way to check for knowledge of key lexical chunks.                                                                                                                                                                                                                                                                               |
|          15 | Llama 4         | Multiple Choice |       2 |      1.42 | This candidate has numerous errors. It violates the JSON format by using the key 'correct' instead of 'correctAnswer'. It includes explicit instructions in the question string and uses a format with the infinitive in parentheses, which was not requested. Furthermore, it completely disregards the required context of forms or postcards. The task is fundamentally flawed in its execution.                                                                                                                                                                       |
|          15 | Llama 4         | Fill Blank      |      10 |      1.61 | This is a perfect A1 task. It tests the most fundamental Polish verb, 'byƒá' (to be), in its first-person form 'jestem'. The context of stating one's origin is a cornerstone of A1 curriculum. The task adheres to all instructions flawlessly and represents an ideal fill-in-the-blank question for this level.                                                                                                                                                                                                                                                         |
|          15 | Mistral Large 3 | Multiple Choice |       3 |      2.3  | This candidate fails on several critical points. Most importantly, the question is ambiguous and allows for multiple correct answers ('idƒô', 'idziemy') as no subject is provided, violating the determinism rule. It also incorrectly includes instructions ('Wybierz poprawnƒÖ formƒô czasownika:') within the question string and fails to adhere to the specified context of filling a form or writing a postcard.                                                                                                                                                      |
|          15 | Mistral Large 3 | Fill Blank      |       3 |      1.66 | This candidate fails on a critical instruction: providing a task with a deterministic answer. The question 'mam na imiƒô ____ (name)' can be completed with any name, making it an open-ended prompt rather than a language knowledge test. This violates guideline #7 ('the missing word/phrase must have only one correct answer') and results in a poor assessment item.                                                                                                                                                                                                |
|          15 | Qwen 3 Max      | Multiple Choice |       6 |      5.77 | A solid, level-appropriate grammar task testing the past tense. The answer is deterministic given the options. However, the candidate completely ignored the crucial instruction to create a task related to the specified writing skills (filling forms, writing postcards), making it only partially compliant with the prompt.                                                                                                                                                                                                                                         |
|          15 | Qwen 3 Max      | Fill Blank      |      10 |      3.21 | An outstanding candidate. It cleverly and directly incorporates the A1 level description ('write a simple postcard') into the task. The question tests both relevant vocabulary ('poczt√≥wka') and a key A1 grammatical concept (the accusative case), making it a well-rounded and level-appropriate question with a unique, unambiguous answer.                                                                                                                                                                                                                          |

### üåê Language: POLISH | Level: B2
|   iteration | model           | task_type       |   score |   latency | reason                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|------------:|:----------------|:----------------|--------:|----------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|           1 | GPT-5.2         | Multiple Choice |      10 |     23.15 | The candidate perfectly adheres to all instructions. The generated JSON is valid and uses the correct schema. The task tests the use of a relative pronoun with a preposition ('w kt√≥rym'), a grammatical point highly appropriate for the B2 level. The context is realistic, and the options provide clear, grammatically distinct distractors, ensuring a single correct answer. It successfully avoids including instructions in the question field.                                                                                  |
|           1 | GPT-5.2         | Fill Blank      |       8 |      1.27 | The task is well-suited for the B2 level, using relevant professional vocabulary ('raport', 'strategia', 'ryzyko') and a correct grammatical structure. The sentence is natural and the format is correct. However, it violates the 'only one correct answer' guideline. While 'oceniƒá' (to assess) is a very good fit, the verb 'oszacowaƒá' (to estimate) is an equally valid and common alternative in this context, making the answer not strictly deterministic.                                                                      |
|           1 | Gemini 3 Flash  | Multiple Choice |       6 |      1.62 | The candidate follows all formatting and structural instructions perfectly, resulting in a valid and correctly structured JSON. However, the linguistic task itself is not appropriate for the B2 level. It tests basic subject-verb agreement ('autor podtrzymuje'), which is an A2/B1 skill. Despite the B2-level vocabulary in the sentence, the core challenge is far too simple for the target proficiency, making the task ineffective as a B2 assessment.                                                                          |
|           1 | Gemini 3 Flash  | Fill Blank      |       9 |      1.49 | This is a high-quality task that may even touch C1 level. It uses advanced vocabulary ('pomimo licznych przeszk√≥d', 'zarzƒÖd', 'kompromis') and complex grammar ('pomimo' + genitive, dative subject with 'uda≈Ço siƒô'). The collocation 'wypracowaƒá kompromis' is excellent. The only minor flaw is that 'osiƒÖgnƒÖƒá kompromis' (to reach a compromise) is an equally perfect and common alternative, meaning the task is not strictly deterministic as per the instructions. Otherwise, it is an exemplary task.                            |
|           1 | Llama 4         | Multiple Choice |       2 |      1.41 | This candidate fails significantly on formatting requirements. The JSON schema is incorrect, using 'correct' with an index instead of 'correctAnswer' with the word, and adding an extraneous 'format' field. It also violates the instruction to omit instructions from the question by including 'Wybierz odpowiedniƒÖ formƒô czasownika w zdaniu:'. While the grammatical task (conditional mood) is level-appropriate, the failure to follow fundamental output instructions is a major flaw.                                           |
|           1 | Llama 4         | Fill Blank      |       1 |      1.02 | This candidate fails on all criteria. The JSON format is incorrect, nested within an extra layer. It fails to include the required English translation of the missing word. The task itself is illogical, as one cannot 'read' ('czytaƒá') movies. The provided answers are also nonsensical ('czytaƒá ksiƒÖ≈ºki' would result in a repetition). Finally, the vocabulary and sentence structure are at an A1/A2 level, far below the requested B2 proficiency.                                                                                |
|           1 | Mistral Large 3 | Multiple Choice |       3 |      3.13 | The candidate fails on several key guidelines. It includes instructions ('Kt√≥re s≈Çowo najlepiej pasuje do zdania:') within the 'question' field, violating a specific rule. More importantly, the task is not deterministic; multiple options ('fili≈ºance', 'kubku', 'szklance') are plausible for drinking tea, making the question ambiguous and based on preference rather than a clear linguistic rule. The level is closer to B1 than B2.                                                                                            |
|           1 | Mistral Large 3 | Fill Blank      |       3 |      2.34 | This task is fundamentally flawed because the missing verb's form depends on a subject that is not provided in the sentence. While the candidate provided 'zdecydowali≈õmy' (we decided), other forms like 'zdecydowa≈Çem siƒô' (I, male, decided), 'zdecydowa≈Ça≈õ siƒô' (you, female, decided), or 'zdecydowali siƒô' (they decided) are equally possible. This violates the 'only one correct answer' and 'avoid ambiguity' rules. The difficulty level is closer to B1 than B2.                                                              |
|           1 | Qwen 3 Max      | Multiple Choice |      10 |      5.75 | This is an excellent response that meets all criteria. The JSON is perfectly formatted. The task targets B2-level vocabulary ('bagatelizowa≈Ç') within a context that requires nuanced understanding. The contrast in the sentence ('zamiast je powa≈ºnie rozwa≈ºyƒá') makes the correct answer clear and deterministic, while the distractors are plausible but incorrect. It correctly omits any instructions from the question.                                                                                                            |
|           1 | Qwen 3 Max      | Fill Blank      |       9 |      5.77 | An excellent task that aligns perfectly with the B2 level proficiency description, testing a strong vocabulary collocation ('wyraziƒá opiniƒô' - to express an opinion) within a relevant context (writing an email about a project). The sentence is grammatically correct and natural. The answer 'wyraziƒá' is the most common and fitting choice. While another verb like 'przedstawiƒá' (to present) could also fit, 'wyraziƒá' is the strongest choice, making the ambiguity minimal.                                                    |
|           2 | GPT-5.2         | Multiple Choice |       8 |     16.32 | The candidate produced a valid JSON and followed most instructions. The task, which tests the subjunctive mood in a passive voice construction ('aby... zosta≈Çy wprowadzone'), is grammatically correct and perfectly aligned with the B2 level. The context is appropriate. The only minor flaw is that the prompt requested the 'correctAnswer' in an array, and a string was provided, but this is a negligible deviation given the prompt's own ambiguity. The question does not contain any extra instructions, which is good.       |
|           2 | GPT-5.2         | Fill Blank      |       6 |      1.49 | The task tests an excellent B2-level grammar point (past unreal conditional) with a natural sentence. However, it fails to follow the core 'fill-in-the-blank' format instruction. Instead of leaving a blank within the sentence, it presents a complete sentence and then separately shows the phrase that was supposed to be in the blank, which is a major structural error.                                                                                                                                                          |
|           2 | Gemini 3 Flash  | Multiple Choice |      10 |      1.54 | This is an outstanding candidate that perfectly meets all requirements. The JSON is well-formatted and adheres to the instructions, including the crucial rule of not adding extra text to the question. The task itself is an excellent B2-level vocabulary question, requiring the user to distinguish between semantically similar verbs in a formal, complex sentence. The vocabulary and context ('autor raportu', 's≈Çuszno≈õƒá strategii') align perfectly with the B2 proficiency description of writing reports and giving reasons. |
|           2 | Gemini 3 Flash  | Fill Blank      |       8 |      1.41 | A very strong B2-level task that appropriately tests grammar ('uda≈Ço siƒô + infinitive') and vocabulary (collocation). The context is natural and the sentence uses a B2-level structure ('Mimo...'). The score is slightly reduced because it is not fully deterministic; it provides 'osiƒÖgnƒÖƒá' as the sole answer, while 'zrealizowaƒá' is another equally valid and common alternative that should have been included in the answer array.                                                                                              |
|           2 | Llama 4         | Multiple Choice |       5 |      1.16 | The linguistic content of the task (testing conditional mood) is appropriate for the B2 level and the context fits the prompt. However, the candidate failed to adhere to several key formatting guidelines. The JSON schema is incorrect, using 'correct: 0' instead of 'correctAnswer: "napisa≈Çbym"'. It also incorrectly includes instructions within the 'question' field ('Wybierz odpowiedniƒÖ formƒô...') and provides the base verb in parentheses, which also counts as an instruction.                                            |
|           2 | Llama 4         | Fill Blank      |       9 |      2.21 | An excellent task that aligns perfectly with the B2 proficiency description (writing an essay). The context is relevant, and the vocabulary is appropriate. Although it violates the conflicting guideline for a single deterministic answer, it correctly handles the linguistic reality by providing an array of valid synonyms, making it a high-quality, natural language question.                                                                                                                                                   |
|           2 | Mistral Large 3 | Multiple Choice |       2 |      3.42 | This candidate fails on several critical points. Firstly, it violates the rule to not include instructions in the question field ('Wybierz odpowiedniƒÖ formƒô czasownika...'). Secondly, and more importantly, the task is grammatically flawed. For the sentence 'Gdyby≈õ _______ wcze≈õniej...', the correct verb form would be 'przyjecha≈Ç', which is not provided as an option. The provided 'correctAnswer' ('przyjecha≈Çby≈õ') is incorrect in this specific grammatical context, making the entire task invalid.                        |
|           2 | Mistral Large 3 | Fill Blank      |      10 |      2.48 | This is an exemplary B2-level task. It tests relevant vocabulary ('zaimprowizowaƒá') in a natural and specific business context. The sentence structure is appropriate for the level, the answer is deterministic, and all formatting and content instructions have been followed perfectly.                                                                                                                                                                                                                                               |
|           2 | Qwen 3 Max      | Multiple Choice |       6 |      5.33 | The candidate followed the formatting instructions perfectly, providing a clean and valid JSON. The sentence is grammatically correct. However, the difficulty of the task is below the requested B2 level. It tests basic gender agreement for past tense verbs ('drzewo' -> 'rozpali≈Ço siƒô'), which is typically a B1 or even A2 concept. Furthermore, two of the distractors rely on a simple spelling error (missing diacritic), which weakens the quality of the question for a B2 assessment.                                       |
|           2 | Qwen 3 Max      | Fill Blank      |       7 |      4.19 | The task is grammatically correct and follows the required format. However, the linguistic concept being tested (past imperfective aspect of the common verb 'czytaƒá') is more characteristic of a B1 level. The task lacks the complexity and nuance expected for a B2 learner.                                                                                                                                                                                                                                                          |
|           3 | GPT-5.2         | Multiple Choice |       8 |      1.99 | The task is excellent, testing B2-level vocabulary (`zweryfikowaƒá`) in a highly relevant professional context (writing a report), which aligns perfectly with the prompt's proficiency description. The distractors are well-chosen. The only flaw is that the `correctAnswer` field is a string instead of an array, which deviates from the specified JSON format.                                                                                                                                                                      |
|           3 | GPT-5.2         | Fill Blank      |      10 |     17.7  | Excellent. The task tests a key B2-level fixed phrase ('biorƒÖc pod uwagƒô') within a formal context appropriate for the level. The use of a participial clause is a good indicator of B2+ proficiency. The answer is unambiguous, and all formatting instructions were followed perfectly.                                                                                                                                                                                                                                                 |
|           3 | Gemini 3 Flash  | Multiple Choice |       8 |      1.36 | An excellent, high-quality task that tests knowledge of advanced collocations (`przemawiaƒá za czym≈õ`) in a formal context that is perfectly aligned with the B2 writing skills description. The distractors are very effective. Its only flaw is the formatting of the `correctAnswer` as a string instead of an array, which deviates from the strict guideline.                                                                                                                                                                         |
|           3 | Gemini 3 Flash  | Fill Blank      |      10 |      1.27 | Excellent. This is a perfect B2-level task. It tests both advanced grammar (the impersonal structure 'uda≈Ço siƒô' with a dative subject) and formal vocabulary/collocations ('osiƒÖgnƒÖƒá porozumienie'). The provided English hint '(reach)' makes the answer 'osiƒÖgnƒÖƒá' uniquely correct over other synonyms. All instructions were followed precisely.                                                                                                                                                                                     |
|           3 | Llama 4         | Multiple Choice |       3 |      3.39 | This candidate fails to produce a valid language task. The question is a test of real-world logic, not a linguistic skill. The answer is not deterministic, as multiple options are logically plausible, violating a core guideline. Although the JSON format is correct, the content of the task is fundamentally flawed.                                                                                                                                                                                                                |
|           3 | Llama 4         | Fill Blank      |       1 |      0.98 | Very poor. This candidate fails on multiple critical requirements. The JSON format is incorrect and does not match the specified schema. The task level is A1/A2, far below the requested B2. The sentence construction is logically flawed, and it omits the required English translation of the missing word.                                                                                                                                                                                                                           |
|           3 | Mistral Large 3 | Multiple Choice |       5 |      3.45 | While the task tests a valid B2 grammar point (conditional mood) and uses the correct JSON format, it violates a key guideline by including instructions ('Wybierz odpowiedniƒÖ formƒô czasownika...') within the 'question' field. The prompt explicitly forbids including instructions. The context is also less sophisticated than ideal for the specified level.                                                                                                                                                                        |
|           3 | Mistral Large 3 | Fill Blank      |       9 |      2.17 | Very good. The task uses appropriate B2-level business vocabulary and context. The sentence is natural and grammatically correct. The only minor flaw is that a very common synonym ('zaprezentowa≈Ç') could also fit, which slightly reduces the determinism requested by the prompt, though 'przedstawi≈Ç' is an excellent choice.                                                                                                                                                                                                        |
|           3 | Qwen 3 Max      | Multiple Choice |       7 |      5.3  | A solid task that correctly tests knowledge of parts of speech in an appropriate B2 context (job interview). The answer is deterministic and the sentence is natural. It loses points because the difficulty is on the lower end of B2, and it uses a string for `correctAnswer` instead of an array, failing to strictly follow the specified format.                                                                                                                                                                                    |
|           3 | Qwen 3 Max      | Fill Blank      |       4 |      4.07 | Poor. Although the task is grammatically correct and follows the JSON format, it completely misses the target proficiency level. The vocabulary, grammar (present tense of a common verb), and context (daily routine) are characteristic of an A2 or low B1 level, not B2.                                                                                                                                                                                                                                                               |
|           4 | GPT-5.2         | Multiple Choice |       9 |     15.78 | A very well-constructed, level-appropriate task that correctly tests the use of contrasting conjunctions in a formal writing context (a report). It adheres to all major instructions, including the 'no instructions' and 'single sentence' rules. The task is deterministic and the vocabulary is suitable for the B2 level.                                                                                                                                                                                                            |
|           4 | GPT-5.2         | Fill Blank      |      10 |     16.67 | Excellent candidate. The task correctly tests a key B2 grammar point: the use of a relative pronoun ('kt√≥ry') in the genitive case ('kt√≥rego') required by the negated impersonal construction 'nie da siƒô'. The answer is deterministic, the sentence is natural and complex, and the context of a discussion is appropriate for the level. It follows all instructions perfectly.                                                                                                                                                       |
|           4 | Gemini 3 Flash  | Multiple Choice |       6 |      1.93 | The linguistic quality of this task is excellent; it tests a sophisticated conjunction ('niemniej jednak') in a perfect B2 essay-writing context. However, the score is significantly reduced because it completely ignores the strict guideline to not include any instructions in the 'question' field. The inclusion of the preamble makes the format incorrect despite the high quality of the core language test.                                                                                                                    |
|           4 | Gemini 3 Flash  | Fill Blank      |       8 |      1.23 | This candidate presents an excellent B2-level task, testing advanced vocabulary and collocation ('wypracowaƒá porozumienie') in a formal context. The sentence structure is also suitably complex. However, like Candidate 2, it fails on the determinism rule by providing only one possible answer. The verb 'osiƒÖgnƒÖƒá' (to reach/achieve) is an equally valid and common alternative that should have been included in the 'correctAnswer' array.                                                                                       |
|           4 | Llama 4         | Multiple Choice |       2 |      1.83 | This task is fundamentally flawed because it is not deterministic. All four options are grammatically and semantically plausible; a report on a trip could focus on any of the topics listed. This violates the crucial guideline to have only one clear, correct answer, making the question a test of subjective preference rather than language skill.                                                                                                                                                                                 |
|           4 | Llama 4         | Fill Blank      |       8 |      1.41 | This is a solid candidate that correctly follows all instructions. It tests a relevant B1/B2 business vocabulary collocation ('rozszerzyƒá dzia≈Çalno≈õƒá') and implicitly requires correct past tense conjugation. The answer is deterministic, and the context is appropriate. While not as grammatically challenging as Candidate 1, it's a well-constructed and suitable task.                                                                                                                                                            |
|           4 | Mistral Large 3 | Multiple Choice |       4 |      3.62 | The candidate fails on two key points. Firstly, it violates the explicit instruction not to include instructions in the 'question' field ('Kt√≥re s≈Çowo najlepiej pasuje...'). Secondly, the grammatical point tested (aspect and the use of '≈ºeby' + infinitive) is more appropriate for a B1 level than the specified B2 writing proficiency, which focuses on more complex text construction.                                                                                                                                           |
|           4 | Mistral Large 3 | Fill Blank      |       7 |      1.74 | A good task that tests the preposition 'mimo' with the genitive case, which is appropriate for the B1/B2 level. However, it fails to be fully deterministic as instructed. The word 'pomimo' is an equally correct and common answer that should have been included in the 'correctAnswer' array. This oversight violates the guideline regarding multiple correct answers.                                                                                                                                                               |
|           4 | Qwen 3 Max      | Multiple Choice |      10 |      8.06 | This is an excellent and challenging B2/C1 level vocabulary task. It tests the nuanced difference between abstract nouns in a professional context, which is highly relevant to the B2 writing description. It follows all structural guidelines correctly. The options are well-designed to test collocation and precise word choice, making it a high-quality, deterministic question.                                                                                                                                                  |
|           4 | Qwen 3 Max      | Fill Blank      |       5 |      6.11 | While the format is correct and the sentence is grammatically sound, the task completely misses the specified B2 proficiency level. Conjugating a regular verb in the past tense ('pracowali≈õmy') is a fundamental A2/B1 skill. A B2 learner would find this task trivial, so it fails to test a key skill for the target level.                                                                                                                                                                                                          |
|           5 | GPT-5.2         | Multiple Choice |       7 |     16.94 | The task is linguistically sound and level-appropriate, testing the use of conjunctions at a B2 level. However, it fails to follow the output format instructions strictly. It includes an extra, non-requested field 'englishTranslation', which also violates the guideline 'Do not translate any parts of the sentence in English'. The value for 'correctAnswer' is a string, while the instructions hinted at an array format.                                                                                                       |
|           5 | GPT-5.2         | Fill Blank      |       9 |      1.44 | Excellent B2 level task. The vocabulary ('raport', 'kierownictwo', 'strategia') and the context of presenting arguments in a report align perfectly with the user's proficiency description. The use of 'aby' + infinitive is appropriate. 'Przekonaƒá' is the most suitable verb, making the answer deterministic in this formal context.                                                                                                                                                                                                 |
|           5 | Gemini 3 Flash  | Multiple Choice |      10 |      1.48 | An exemplary response that follows all instructions perfectly. The task is a well-designed vocabulary question testing nuanced word choice ('zwiƒôz≈Çy') in a formal context, which is highly appropriate for the B2 level. The question is a single, unadorned sentence, the options are excellent distractors, and the JSON format is correct. It effectively tests a skill needed for clear and detailed writing.                                                                                                                        |
|           5 | Gemini 3 Flash  | Fill Blank      |      10 |      1.08 | This is an exemplary B2-level task. It uses advanced vocabulary ('liczne trudno≈õci', 'zamierzony cel') and structures ('Pomimo' + genitive, 'zdo≈Çaƒá' + infinitive) relevant to formal and professional contexts. The collocation 'osiƒÖgnƒÖƒá cel' (to achieve a goal) is very strong, making 'osiƒÖgnƒÖƒá' the single best choice and fulfilling all instructions perfectly.                                                                                                                                                                   |
|           5 | Llama 4         | Multiple Choice |       4 |      1.22 | While the linguistic task itself (testing the conditional mood) is appropriate for the B2 level, the candidate failed to follow multiple critical formatting instructions. It included instructions in the 'question' field, used an incorrect key ('correct' instead of 'correctAnswer'), provided the answer as an index instead of the string, and included a non-requested 'translation' field. These are significant deviations from the prompt's requirements.                                                                      |
|           5 | Llama 4         | Fill Blank      |       5 |      1.31 | The task fails the 'only one correct answer' guideline, as 'podr√≥≈ºowa≈Ça' is a valid and common alternative to 'je≈∫dzi≈Ça'. While testing the imperfective aspect for past repeated actions is a key B1/B2 skill, the ambiguity makes it a weak question for this format.                                                                                                                                                                                                                                                                   |
|           5 | Mistral Large 3 | Multiple Choice |       6 |      4.99 | This candidate failed on two key instructions. First, the 'question' field includes instructions ('Kt√≥re s≈Çowo poprawnie uzupe≈Çnia zdanie:'), which was explicitly forbidden. Second, the task itself, testing the collocation 'i≈õƒá na spacer', is more appropriate for a B1 level rather than B2, as it's a very common phrase. The distractors are plausible but the core task lacks the complexity expected at the B2 level.                                                                                                           |
|           5 | Mistral Large 3 | Fill Blank      |       4 |      2.1  | This task violates the strict guideline of having only one correct answer. Both 'pojechaƒá' (to go by vehicle) and 'p√≥j≈õƒá' (to go on foot) are equally valid and common answers depending on the nature of the trip, creating ambiguity. The vocabulary and grammar are more suited for a B1 level than a B2 level.                                                                                                                                                                                                                        |
|           5 | Qwen 3 Max      | Multiple Choice |      10 |      6.52 | This is an excellent response that perfectly adheres to all instructions. The question is a single sentence without any added instructions. The task tests the subjunctive mood ('aby≈õmy zako≈Ñczyli'), a key grammatical point for the B2 level. The context is relevant, and the distractors are well-chosen to test common learner errors. The JSON format is correct.                                                                                                                                                                  |
|           5 | Qwen 3 Max      | Fill Blank      |       8 |      5.7  | A solid B2-level task testing the common and important collocation 'zrobiƒá wra≈ºenie na kim≈õ' (to make an impression on someone). The answer 'zrobi≈Ço' is uniquely correct due to the fixed phrase and grammatical agreement. The context is relevant, though slightly less complex than other top candidates.                                                                                                                                                                                                                             |
|           6 | GPT-5.2         | Multiple Choice |       7 |     21.08 | The candidate created a valid JSON with a good B2-level vocabulary question. However, it violates a key guideline by providing English translations for the options. Guideline 7 states, 'Do not translate any parts of the sentence in English,' and Guideline 3 suggests translating only 'necessary parts,' which would not include the options themselves. This significantly lowers the task's difficulty, as the user can solve it by understanding English rather than knowing the Polish vocabulary.                              |
|           6 | GPT-5.2         | Fill Blank      |       9 |      1.48 | Excellent candidate. The task is perfectly aligned with the B2 level, using relevant vocabulary ('podkre≈õli≈Çem', 'znaczƒÖco', 'efektywno≈õƒá') within a professional context (writing a report) that matches the proficiency description. The answer is deterministic and the sentence is grammatically sound and natural. It correctly tests the collocation 'wp≈ÇynƒÖƒá na'.                                                                                                                                                                  |
|           6 | Gemini 3 Flash  | Multiple Choice |      10 |      1.54 | This candidate produced a high-quality task that perfectly reflects the B2 level requirements. The context (writing a report on environmental issues) and the grammar point (verb form in a relative clause) are ideal. The question is clear, the options are effective distractors, and it follows all major guidelines. The use of a string for `correctAnswer` instead of an array is a minuscule deviation from the prompt's example but is acceptable given the overall excellence and adherence to all other rules.                |
|           6 | Gemini 3 Flash  | Fill Blank      |       6 |      1.23 | The task features excellent B2-level vocabulary and a relevant context (negotiations). However, it fails on the critical guideline of having only one correct answer. In Polish, one can 'osiƒÖgnƒÖƒá porozumienie' (achieve an agreement), 'zawrzeƒá porozumienie' (conclude an agreement), or 'doj≈õƒá do porozumienia' (arrive at an agreement). All are common and correct, making the question ambiguous for a fill-in-the-blank format.                                                                                                   |
|           6 | Llama 4         | Multiple Choice |      10 |      2.36 | An outstanding submission that perfectly meets all requirements. The task is challenging and perfectly aligned with the B2 level, testing grammatical agreement within a complex sentence structure. The context of writing a report directly mirrors the proficiency description. The JSON is perfectly formatted, and the task is linguistically accurate and natural. It's a high-quality, well-designed question.                                                                                                                     |
|           6 | Llama 4         | Fill Blank      |      10 |      2.05 | This is an outstanding candidate that perfectly captures the essence of the B2 level. The context of writing an essay and presenting arguments directly mirrors the user's proficiency description. The vocabulary ('esej', 'argumenty za i przeciw') and complex sentence structure are highly appropriate. The answer is deterministic and all guidelines are followed flawlessly.                                                                                                                                                      |
|           6 | Mistral Large 3 | Multiple Choice |       7 |      2.98 | The task tests a relevant B2 grammar point (conditionals) and the JSON format is valid. However, it explicitly violates Guideline 9 ('Do not include any instructions for the task') by adding 'Wybierz odpowiedniƒÖ formƒô czasownika, aby poprawnie uzupe≈Çniƒá zdanie:' to the question field. The core task is good, but the inclusion of instructions is a direct failure to follow the prompt.                                                                                                                                          |
|           6 | Mistral Large 3 | Fill Blank      |       9 |      2.37 | A very strong candidate. The task effectively tests B2-level vocabulary ('zaimprowizowaƒá') in a relatable business context. The sentence is natural and grammatically correct. It fully adheres to all instructions, including the requirement for a single, unambiguous answer.                                                                                                                                                                                                                                                          |
|           6 | Qwen 3 Max      | Multiple Choice |      10 |      5.75 | This is an excellent response. It adheres to all instructions perfectly. The JSON is valid, the task tests a crucial B2 concept (verb aspect) in a relevant context (formal reporting), and the vocabulary is level-appropriate. The options are well-chosen distractors, and the answer is deterministic. It fully aligns with the specified CEFR level description without any violations.                                                                                                                                              |
|           6 | Qwen 3 Max      | Fill Blank      |       3 |      4.08 | This task is well below the target B2 level; the grammar and vocabulary are more suited for an A2 or B1 learner. Crucially, it violates the guideline to avoid ambiguity. The correct answer depends on the speaker's gender ('nie poszed≈Çem' for male, 'nie posz≈Çam' for female), but only the male form is provided, making the task flawed.                                                                                                                                                                                            |
|           7 | GPT-5.2         | Multiple Choice |       7 |      9.27 | The task is at an appropriate B2 level, testing knowledge of verb aspect and form. However, it directly violates Guideline 7 by including an English translation ('(English: to reconcile/make up)') within the question string, which was explicitly forbidden.                                                                                                                                                                                                                                                                          |
|           7 | GPT-5.2         | Fill Blank      |       9 |      1.37 | Excellent adherence to all instructions. The task tests the comparative form of adverbs ('bardziej op≈Çacalne'), a key B2 grammar point. The business context is appropriate for the level. Crucially, it has only one correct answer, making it a well-designed, deterministic task.                                                                                                                                                                                                                                                      |
|           7 | Gemini 3 Flash  | Multiple Choice |       5 |      1.8  | The task's context, vocabulary, and alignment with the B2 level description are outstanding. However, it fails on a critical requirement for a multiple-choice question, as stated in Guideline 8. Both 'nalega' and 'k≈Çadzie nacisk' are correct options in the given sentence, making the answer non-deterministic. This ambiguity makes the task invalid for assessment.                                                                                                                                                               |
|           7 | Gemini 3 Flash  | Fill Blank      |       5 |      1.04 | The sentence context and vocabulary are appropriate for the B2 level. However, like Candidate 4, it critically fails the 'only one correct answer' rule. The collocation 'osiƒÖgnƒÖƒá porozumienie' is correct, but so are 'zawrzeƒá porozumienie' (to conclude an agreement) and 'wypracowaƒá porozumienie' (to work out an agreement), which are common and equally valid alternatives.                                                                                                                                                      |
|           7 | Llama 4         | Multiple Choice |       9 |      1.86 | This candidate successfully followed all instructions, including negative constraints. The JSON is well-formatted, the task is grammatically correct, and the answer is deterministic. It correctly tests the genitive case with a common prepositional phrase. While the difficulty could be considered borderline B1/B2, it is a high-quality submission that meets all prompt requirements.                                                                                                                                            |
|           7 | Llama 4         | Fill Blank      |       5 |      0.61 | While the sentence quality, formal register, and topic (writing an essay) are perfectly aligned with the B2 level description, the task fails the critical 'only one correct answer' guideline. Several verbs like 'przeanalizowaƒá' (to analyze) or 'przedstawiƒá' (to present) are equally valid alternatives to 'om√≥wiƒá', making the question ambiguous.                                                                                                                                                                                 |
|           7 | Mistral Large 3 | Multiple Choice |       8 |      3.04 | This is an excellent B2-level task focusing on the past conditional mood, a key grammatical structure. The distractors are well-designed. The score is reduced because it violates Guideline 9 by including instructions ('Wybierz odpowiedniƒÖ formƒô czasownika, aby poprawnie uzupe≈Çniƒá zdanie:') in the question field.                                                                                                                                                                                                                 |
|           7 | Mistral Large 3 | Fill Blank      |       6 |      2.3  | The topic (work-life balance) and vocabulary are suitable for B2. However, the task violates the 'only one correct answer' rule, as 'pogodzenie' (reconciliation) could also fit. Additionally, the chosen answer 'zr√≥wnowa≈ºenie' is grammatically correct but sounds slightly less natural than the alternative noun 'r√≥wnowaga' (which would require changing the adjective).                                                                                                                                                           |
|           7 | Qwen 3 Max      | Multiple Choice |       6 |      6.92 | The task features excellent B2-level vocabulary and a complex sentence structure. However, it is seriously flawed by the inclusion of a duplicate option ('u≈ÇatwiƒÖ'). This violates the instruction to provide four distinct options and compromises the integrity of the question.                                                                                                                                                                                                                                                       |
|           7 | Qwen 3 Max      | Fill Blank      |       4 |      3.83 | The task fails on two key criteria. Firstly, the level is closer to B1 than B2, testing basic past tense conjugation which should already be mastered. Secondly, it is not deterministic; 'zasiedzia≈Çam siƒô' (I stayed too long) is another valid and contextually appropriate answer besides 'zosta≈Çam'.                                                                                                                                                                                                                                 |
|           8 | GPT-5.2         | Multiple Choice |       8 |     21.16 | The task is well-designed for the B2 level, testing genitive case agreement in a relevant professional context. The grammar is accurate and the distractors are plausible. However, it partially violates the instructions by including a full English translation of the sentence within the 'question' field, which was explicitly forbidden ('Do not translate any parts of the sentence in English'), even though the prompt was contradictory on this point.                                                                         |
|           8 | GPT-5.2         | Fill Blank      |       9 |      9    | Excellent task. The JSON format is perfect. The sentence 'Wniosek o urlop ____ wczoraj w dziale kadr' tests the passive voice ('zosta≈Ç z≈Ço≈ºony'), a key B2 grammar point. The vocabulary ('wniosek o urlop', 'dzia≈Ç kadr') is appropriate for the level and relates to a formal/work context. The answer is highly deterministic, as 'sk≈Çadaƒá wniosek' is a strong collocation, making other alternatives unlikely. It fully meets the prompt's requirements.                                                                             |
|           8 | Gemini 3 Flash  | Multiple Choice |       9 |      1.5  | An excellent B2-level vocabulary task that tests collocations in a formal context, perfectly matching the proficiency description. The sentence is complex and natural, the distractors are well-chosen to test nuanced meaning, and the JSON format is correct. The task is challenging and well-constructed, fully meeting the user's requirements.                                                                                                                                                                                     |
|           8 | Gemini 3 Flash  | Fill Blank      |       7 |      1.14 | The task is excellent in terms of level and complexity. The sentence structure ('Mimo...') and vocabulary ('przeszk√≥d', 'przekonaƒá', 'argument√≥w') are very well-suited for B2 and align with the writing skill description. The format is also correct. However, it fails the critical 'only one correct answer' guideline. The phrase 'przekonaƒá do swoich racji' is a highly idiomatic and valid alternative to 'przekonaƒá do swoich argument√≥w', as are other words like 'poglƒÖd√≥w' or 'tez'.                                         |
|           8 | Llama 4         | Multiple Choice |       3 |      3.47 | This candidate fails on the most critical requirement for a multiple-choice question: having only one correct answer. Three of the four options are grammatically correct and semantically plausible answers, making the task highly ambiguous and violating guideline #8. The tested grammar point (verb patterns with 'lubiƒá') is also arguably closer to a B1 level.                                                                                                                                                                   |
|           8 | Llama 4         | Fill Blank      |       1 |      1.09 | This candidate fails on almost every criterion. The JSON format is incorrect, wrapping the intended JSON inside another object and including unrequested fields. It completely omits the required 'correctAnswer' field and the English translation of the missing word. The task itself, 'M√≥j ulubiony ____ to pi≈Çka no≈ºna i koszyk√≥wka', is at an A1/A2 level, not the requested B2.                                                                                                                                                    |
|           8 | Mistral Large 3 | Multiple Choice |       6 |      3.24 | The linguistic task itself, testing the conditional mood with aspect distinction, is excellent for the B2 level. However, the output fails on a key formatting instruction by including explicit instructions ('Wybierz poprawnƒÖ formƒô czasownika, aby uzupe≈Çniƒá zdanie:') in the 'question' field, which was strictly forbidden by guideline #9.                                                                                                                                                                                         |
|           8 | Mistral Large 3 | Fill Blank      |       7 |      1.77 | A good B2-level task that follows the specified JSON format. The sentence tests the perfective aspect in a professional context. However, it violates the strict guideline of having only one correct answer. Both 'poinformowa≈Ç' and its close synonym 'powiadomi≈Ç' are equally valid and natural in this context, which introduces ambiguity.                                                                                                                                                                                           |
|           8 | Qwen 3 Max      | Multiple Choice |      10 |      6.52 | This is an exemplary response that strictly adheres to all instructions. The JSON format is perfect. The task is highly appropriate for the B2 level, testing adjective agreement in a complex sentence with a relevant professional context ('job interview'). The vocabulary is well-chosen, the sentence is natural, and the distractors are grammatically distinct and create a clear, deterministic choice.                                                                                                                          |
|           8 | Qwen 3 Max      | Fill Blank      |       6 |      5.4  | The task is grammatically correct and the JSON format is valid. However, its level is closer to B1 than B2 due to the simple context and vocabulary ('kolega', 'plany na wakacje'). More importantly, it fails the uniqueness requirement, as multiple verbs like 'porozmawiaƒá', 'pogadaƒá', and 'om√≥wiƒá' could correctly fill the blank.                                                                                                                                                                                                  |
|           9 | GPT-5.2         | Multiple Choice |       5 |     14.13 | The candidate failed to follow a key negative constraint by including an English translation/hint in the question: `(missing word meaning: ‚Äûafter‚Äù)`. Additionally, the linguistic task itself, which tests basic prepositions of time, is well below the target B2 level and is more appropriate for an A2 or B1 learner.                                                                                                                                                                                                                |
|           9 | GPT-5.2         | Fill Blank      |       9 |      1.29 | Excellent task. The context (writing a report) and vocabulary ('uzasadniƒá' - to justify) are perfectly aligned with the B2 level descriptor. The complex sentence structure adds appropriate difficulty, and the answer is deterministic given the English hint.                                                                                                                                                                                                                                                                          |
|           9 | Gemini 3 Flash  | Multiple Choice |       6 |      1.34 | The candidate followed all formatting and explicit instructions correctly. However, the task's difficulty does not meet the B2 standard. While the sentence structure is complex, the question itself tests basic past tense verb conjugation for a 3rd person subject ('autor' -> 'zignorowa≈Ç'). This is an A2/B1 level skill, and the distractors are too grammatically distant to pose a challenge for a B2 learner.                                                                                                                   |
|           9 | Gemini 3 Flash  | Fill Blank      |      10 |      1.53 | An exceptional task that perfectly matches the B2 level. It tests a key vocabulary item ('przekonaƒá') within a grammatically complex and contextually appropriate sentence ('Pomimo..., uda≈Ço siƒô...'). It directly relates to the B2 skill of presenting arguments and convincing others, as described in the prompt.                                                                                                                                                                                                                    |
|           9 | Llama 4         | Multiple Choice |       4 |      2.27 | The task violates a fundamental principle of good multiple-choice question design, as stated in instruction #8 and #9: the answer must be deterministic and not ambiguous. The options 'w czasie', 'w trakcie', and arguably 'w ciƒÖgu' are near-synonyms, and more than one can be considered correct in this context, even if one is slightly more idiomatic. This ambiguity makes the question flawed.                                                                                                                                  |
|           9 | Llama 4         | Fill Blank      |       6 |      0.42 | While the sentence context (writing an essay) is appropriate for B2, the task itself is too simple. It tests basic subject-verb agreement ('zmiany... majƒÖ'), a skill mastered at A2/B1 levels, not a key skill for B2. The gap does not provide sufficient challenge.                                                                                                                                                                                                                                                                    |
|           9 | Mistral Large 3 | Multiple Choice |       7 |      2.84 | The task itself is excellent, testing the conditional mood ('tryb przypuszczajƒÖcy'), which is a perfect grammar point for the B2 level. The distractors are well-chosen. However, the candidate failed to follow the explicit instruction #9: 'Do not include any instructions for the task.' The question was prepended with 'Wybierz odpowiedniƒÖ formƒô czasownika, aby uzupe≈Çniƒá zdanie:', which is a direct violation.                                                                                                                 |
|           9 | Mistral Large 3 | Fill Blank      |       8 |      6.27 | A very good B2-level task with a relevant professional context. However, it violates the instruction about deterministic answers, as 'zaprezentowaƒá' is an equally valid synonym for 'przedstawiƒá' in this context and was not included in the 'correctAnswer' array.                                                                                                                                                                                                                                                                     |
|           9 | Qwen 3 Max      | Multiple Choice |      10 |      6.05 | This is an exemplary response. It adheres to all instructions, including the negative constraints. The task is linguistically sound and perfectly targets the B2 level by testing the subtle but crucial distinction between perfective and imperfective aspects within a complex sentence. The professional context and well-designed distractors make it a high-quality assessment item.                                                                                                                                                |
|           9 | Qwen 3 Max      | Fill Blank      |       8 |      5.9  | A solid B1/B2 task. It correctly tests a useful collocation ('z≈Ço≈ºyƒá zg≈Çoszenie') and commendably includes both gendered forms in the answer. However, the core grammatical point (simple past tense) is slightly below the target complexity for a strong B2 task.                                                                                                                                                                                                                                                                       |
|          10 | GPT-5.2         | Multiple Choice |       7 |     14.51 | The linguistic quality of the task is very high, testing a key B2 grammar point (subjunctive mood after 'aby'). The options are well-chosen distractors. However, the candidate failed to follow a strict negative constraint (guideline #7) by including an English translation of the sentence in the 'question' field. The 'correctAnswer' field is also a string instead of an array, which is a minor format deviation.                                                                                                              |
|          10 | GPT-5.2         | Fill Blank      |       9 |      1.27 | Excellent. The task directly reflects the B2 writing skill description ('report', 'significance'). The tested vocabulary ('znaczenie') and the collocation ('mieƒá znaczenie') are natural and level-appropriate. The task is highly deterministic, as 'znaczenie' is by far the most common and expected word in this context, strictly following the guidelines.                                                                                                                                                                         |
|          10 | Gemini 3 Flash  | Multiple Choice |      10 |      1.73 | An excellent, well-constructed task. The context (sustainable development) and vocabulary are perfectly aligned with the B2 level. It tests a core grammatical concept (conjunctions of purpose) within a complex sentence, requiring logical understanding. The candidate successfully followed all guidelines, creating a clear, deterministic, and level-appropriate question. The minor format deviation in 'correctAnswer' is overlooked due to prompt ambiguity.                                                                    |
|          10 | Gemini 3 Flash  | Fill Blank      |       5 |      1.65 | Fair. The sentence itself is excellent in terms of complexity and vocabulary for a B2 level. However, it completely disregards the strict instruction for determinism. Multiple verbs such as 'przedstawiƒá', 'wyraziƒá', and 'uzasadniƒá' are all perfectly correct and natural fits, making the task highly ambiguous.                                                                                                                                                                                                                     |
|          10 | Llama 4         | Multiple Choice |       3 |      3.11 | This candidate is fundamentally flawed. Firstly, the task has at least two grammatically and idiomatically correct answers ('piesze wycieczki' and 'chodziƒá na piesze wycieczki'), which violates the core principle of a multiple-choice question. Secondly, the grammatical point being tested (lubiƒá + noun/infinitive) is more appropriate for A2/B1 level, not the requested B2 level.                                                                                                                                               |
|          10 | Llama 4         | Fill Blank      |       7 |      2.02 | Good. The task tests relevant B2 vocabulary ('obciƒÖ≈ºenie' - workload) in a suitable context. The phrasing 'obciƒÖ≈ºenie pracy' is slightly unnatural but understandable ('obciƒÖ≈ºenie pracƒÖ' is more common). While 'obciƒÖ≈ºenie' is the best fit for 'workload', the synonym 'nat≈Çok' is also a plausible answer, making it not perfectly deterministic.                                                                                                                                                                                     |
|          10 | Mistral Large 3 | Multiple Choice |       8 |      2.85 | The task is linguistically solid, testing a nuanced distinction between verbs of motion which is appropriate for the B2 level. The JSON format is correct. The main issue is the violation of guideline #9, as it includes explicit instructions ('Wybierz odpowiedni wyraz, aby poprawnie uzupe≈Çniƒá zdanie:') within the 'question' field, which was forbidden.                                                                                                                                                                          |
|          10 | Mistral Large 3 | Fill Blank      |       4 |      1.65 | Poor. The task's complexity is more suitable for a B1 level, testing a basic verb pattern. It critically fails the determinism rule, as 'p√≥j≈õƒá' (to go on foot) or 'wybraƒá siƒô' (to set out) are equally valid answers to 'pojechaƒá' (to go by vehicle), making the provided single answer incomplete and the task ambiguous.                                                                                                                                                                                                             |
|          10 | Qwen 3 Max      | Multiple Choice |      10 |      5.71 | This is an excellent candidate. It provides a high-quality, nuanced vocabulary task that is perfectly suited for the B2 level, pushing towards C1. The context is formal and the sentence structure is complex. It adheres to all instructions, including the negative constraints. The only minor deviation is the 'correctAnswer' format (string vs. array), which is excusable given the ambiguity in the prompt's example.                                                                                                            |
|          10 | Qwen 3 Max      | Fill Blank      |       6 |      3.81 | Adequate. The context of clarifying one's position in an email is appropriate for B2. However, the task is not deterministic. Besides 'wyja≈õniƒá' (clarify), other verbs like 'przedstawiƒá' (present) or 'uzasadniƒá' (justify) would also fit the blank perfectly, violating a key instruction.                                                                                                                                                                                                                                            |
|          11 | GPT-5.2         | Multiple Choice |       7 |     14.94 | The task uses a relevant B2-level context (professional communication). However, the vocabulary choice is closer to a strong B1 level, as the correct answer is strongly implied by the context ('za op√≥≈∫nienie'). The JSON output also includes an extra 'translation' key not specified in the required schema, and the 'correctAnswer' value is a string instead of an array.                                                                                                                                                          |
|          11 | GPT-5.2         | Fill Blank      |       6 |      1.16 | The task has a good B2-level context (writing a report) and vocabulary. However, it critically fails the guideline to have only one correct answer. The verb 'oceni≈Çem' is the first-person masculine singular form, but without a specified subject, other forms like 'oceni≈Çam' (feminine), 'ocenili≈õmy' (plural), or 'oceniono' (impersonal) are equally valid. This ambiguity makes the task flawed.                                                                                                                                  |
|          11 | Gemini 3 Flash  | Multiple Choice |      10 |      1.7  | This is an exemplary response that perfectly matches the B2 level and all instructions. The context (writing a formal report) is directly aligned with the CEFR description provided. The task tests nuanced, level-appropriate vocabulary by providing well-chosen, similar-sounding distractors, requiring a precise understanding of word choice. The task is well-designed and highly relevant.                                                                                                                                       |
|          11 | Gemini 3 Flash  | Fill Blank      |      10 |      1.41 | An outstanding task that perfectly targets the B2 level. It uses advanced vocabulary ('oskar≈ºony', 'stanowczo', 'dowody') in a formal context. Crucially, it tests collocation ('wyprzeƒá siƒô winy'), which ensures there is only one correct answer ('zaprzeczyƒá' would require a different grammatical structure). It adheres to all instructions flawlessly.                                                                                                                                                                            |
|          11 | Llama 4         | Multiple Choice |       2 |      0.65 | This candidate fundamentally misunderstands the request. It provides a general knowledge/trivia question rather than a language learning task that tests grammar or vocabulary. Furthermore, the question is flawed as it has more than one potentially correct answer (both Krak√≥w and Toru≈Ñ fit the description), violating the 'deterministic' and 'only one correct answer' rules.                                                                                                                                                    |
|          11 | Llama 4         | Fill Blank      |       6 |      1.1  | The vocabulary ('prze≈ºyƒá' in the sense of 'undergo') and context are appropriate for B2. However, the task fails the 'only one correct answer' rule. The verb 'przesz≈Ça' (went through) is an equally correct and natural-sounding alternative to 'prze≈ºy≈Ça' in this context. There is also a minor formatting error in the question ('___' instead of '____' and no space before the parenthesis).                                                                                                                                       |
|          11 | Mistral Large 3 | Multiple Choice |       5 |      3.02 | The task correctly identifies a key grammar point for the B1/B2 level (verb aspect). However, it explicitly violates a strict guideline by including instructions ('Wybierz odpowiedni wyraz, aby poprawnie uzupe≈Çniƒá zdanie:') in the 'question' field, which the prompt forbade.                                                                                                                                                                                                                                                        |
|          11 | Mistral Large 3 | Fill Blank      |      10 |      2.09 | This is an excellent task that fully meets all requirements. The vocabulary ('zakupy online', 'sklepy stacjonarne') and the topic are highly relevant for a B2 level. The sentence is natural, and 'zakupy online' is the most direct and common answer, making it deterministic as requested. The format is perfect.                                                                                                                                                                                                                     |
|          11 | Qwen 3 Max      | Multiple Choice |       9 |      7.21 | An excellent task. It uses a complex sentence with perfect B2-level vocabulary and context. While the core grammar point (adjective agreement) is foundational, its application within this complex structure makes it a valid check for a B2 learner. It adheres to all instructions very well, with only a minor format deviation (correctAnswer as a string, not an array).                                                                                                                                                            |
|          11 | Qwen 3 Max      | Fill Blank      |       7 |      3.97 | The task is cleverly constructed to have a single correct answer by providing context ('chcia≈Çem') that determines the grammatical person, gender, and number. However, the overall difficulty is too low for the B2 level. The vocabulary ('p√≥j≈õƒá do teatru') and grammar (simple past tense) are typically mastered at the A2 or B1 level.                                                                                                                                                                                              |
|          12 | GPT-5.2         | Multiple Choice |       6 |     23.52 | The task itself, testing the collocation `odnie≈õƒá sukces`, is appropriate for the B2 level. However, the output has significant flaws. It violates guideline #7 ('Do not translate any parts of the sentence in English') by including `(English: I succeeded)`. This hint makes the task much easier and goes against the principles of a language test. It also violates guideline #9 ('Do not include any instructions'). Lastly, the `correctAnswer` field is a string, not an array as specified in the instructions.                |
|          12 | GPT-5.2         | Fill Blank      |       9 |      1.35 | Excellent candidate. The sentence structure is complex and the vocabulary ('wyniki bada≈Ñ', 'kryteria oceny') is appropriate for the B2 level, aligning well with the 'writing a report' context from the proficiency description. The answer 'zale≈ºƒÖ' is the most natural and common choice, making the task highly deterministic and well-designed. It correctly tests the conjugation of a key verb in a formal context.                                                                                                                |
|          12 | Gemini 3 Flash  | Multiple Choice |       9 |      1.6  | This is the best candidate. The task is excellent, testing B2-level vocabulary (phrasal verbs like `opowiedzieƒá siƒô za`) within a formal context that aligns perfectly with the level description's focus on writing reports and arguing a point of view. It strictly adheres to the crucial guidelines of having no instructions and no English translations. The only minor deviation from the instructions is that `correctAnswer` is a string rather than an array.                                                                   |
|          12 | Gemini 3 Flash  | Fill Blank      |      10 |      1.25 | This is a perfect response that adheres to all instructions. The task tests a crucial B2-level collocation ('wziƒÖƒá pod uwagƒô'). The complex sentence structure and formal vocabulary are ideal for the level. Most importantly, the answer is completely deterministic; within the phrase '____ pod uwagƒô', 'wziƒÖ≈Ç' is the only grammatically correct option for the subject and tense. It's an unambiguous, high-quality task.                                                                                                           |
|          12 | Llama 4         | Multiple Choice |       3 |      1.13 | While the linguistic concept (impersonal subjunctive `aby by≈Ço`) and context (cover letter) are perfectly suited for B2, the execution is critically flawed. It violates guideline #9 by including instructions. It completely fails to follow the specified JSON schema, using `"correct": 1` instead of a `"correctAnswer"` field. Most importantly, the designated correct answer (index 1, 'by≈Ç') is grammatically incorrect; the right answer is 'by≈Ço' (index 0).                                                                   |
|          12 | Llama 4         | Fill Blank      |       4 |      0.43 | This task is weak because it violates two guidelines. Firstly, it is not deterministic; 'przeprowadzi≈Ça siƒô' is an equally correct, and arguably more common, answer for moving house. This also means it fails the guideline to 'choose the word/phrase that is most likely to be used'. The task is ambiguous and the chosen answer is not the most idiomatic one.                                                                                                                                                                      |
|          12 | Mistral Large 3 | Multiple Choice |       7 |      3.22 | This candidate correctly follows the specified JSON schema, notably providing the `correctAnswer` in an array format as requested. The task, which tests verb aspect and reflexive pronoun usage, is grammatically sound. However, it violates guideline #9 ('Do not include any instructions') by prepending 'Kt√≥re s≈Çowo najlepiej uzupe≈Çnia zdanie:' to the question. The linguistic difficulty is also borderline B1/B2, arguably a bit simple for the target level.                                                                  |
|          12 | Mistral Large 3 | Fill Blank      |       5 |      1.95 | The candidate fails a critical guideline: avoiding ambiguity. While the sentence is grammatically correct and the B2-level business context is appropriate, the blank can be filled by at least one other equally valid and common word: 'zaprezentowa≈Ç'. The instruction to ensure 'only one correct answer' was not followed.                                                                                                                                                                                                           |
|          12 | Qwen 3 Max      | Multiple Choice |       8 |      5.46 | This output demonstrates excellent adherence to the negative constraints, correctly omitting any instructions or English translations, resulting in a clean task format. The main weakness is that the level is closer to B1 than B2; choosing the correct conjunction for an indirect question is a core intermediate skill. The JSON format is nearly perfect, with the minor exception of `correctAnswer` being a string instead of an array.                                                                                          |
|          12 | Qwen 3 Max      | Fill Blank      |       5 |      3.67 | This candidate also violates the 'only one correct answer' rule. The sentence is well-formed and suitable for the level, but other verbs like 'opisa≈Çem' (I described) or 'przedstawi≈Çem' (I presented) fit the blank perfectly, making the task ambiguous. This is a significant flaw based on the provided instructions.                                                                                                                                                                                                                |
|          13 | GPT-5.2         | Multiple Choice |       8 |      2.21 | The task is well-formed and adheres to all instructions, including the provision of an English translation. It correctly tests the use of logical connectors, a skill relevant to B2-level writing. While the grammatical point is solid, it might be considered on the lower end of the B2 spectrum, but the professional context (writing a report) aligns with the level's requirements.                                                                                                                                               |
|          13 | GPT-5.2         | Fill Blank      |      10 |     33.21 | An excellent B2-level task. It tests knowledge of a key phrasal verb ('wywiƒÖzaƒá siƒô z'), which is crucial for formal and professional communication. The grammatical context, using the 'uda≈Ço siƒô + infinitive' structure, is also perfectly suited for the B2 level. The task is unambiguous and adheres to all formatting guidelines.                                                                                                                                                                                                  |
|          13 | Gemini 3 Flash  | Multiple Choice |       9 |      1.46 | This is an outstanding linguistic task that tests a complex B2/C1 grammar point (contemporary adverbial participles) essential for producing sophisticated written text. The context and distractors are perfectly designed. Despite its high quality, it is not a perfect 10 as it omits the English translation requested in the instructions.                                                                                                                                                                                          |
|          13 | Gemini 3 Flash  | Fill Blank      |      10 |      1.51 | An outstanding task that perfectly targets the B2 level. It tests the impersonal 'uda≈Ço siƒô' construction, a crucial and often challenging grammatical point for learners. The vocabulary is appropriate for formal contexts, and the sentence is natural and unambiguous. The candidate followed all instructions flawlessly.                                                                                                                                                                                                            |
|          13 | Llama 4         | Multiple Choice |       7 |      1.95 | This is an excellent task that directly targets the B2 writing skill description by testing nuanced vocabulary choice in the context of writing a letter. The answer is determined by logical coherence. The candidate loses points for failing to provide the required English translation of the sentence.                                                                                                                                                                                                                              |
|          13 | Llama 4         | Fill Blank      |       6 |      0.4  | The content of the task is excellent and perfectly aligned with the B2 level, referencing essay writing as described in the prompt. However, it fails to follow a key guideline by omitting the required English translation of the missing phrase in parentheses. This is a significant deviation from the instructions.                                                                                                                                                                                                                 |
|          13 | Mistral Large 3 | Multiple Choice |       6 |      3.79 | The linguistic task, focusing on verb aspect and reflexivity, is appropriate for the B2 level. However, the output violates two explicit guidelines: it includes instructions ('Kt√≥re s≈Çowo najlepiej pasuje do zdania:') within the 'question' field, and it completely omits the required English translation of the sentence.                                                                                                                                                                                                          |
|          13 | Mistral Large 3 | Fill Blank      |       7 |      1.83 | The task is functional and the format is correct. However, the verb being tested ('zdecydowaƒá siƒô') and its simple past tense conjugation are more characteristic of a B1 level. While the sentence is grammatically acceptable, a stronger B2 task would target more complex vocabulary or grammatical structures.                                                                                                                                                                                                                       |
|          13 | Qwen 3 Max      | Multiple Choice |       7 |      5.31 | A strong B2-level task that effectively tests verb aspect within a complex sentence, a key skill for advanced writing. The formal context of a press conference is also very appropriate. The score is reduced because it fails to follow the instruction to provide an English translation of the sentence.                                                                                                                                                                                                                              |
|          13 | Qwen 3 Max      | Fill Blank      |       9 |      4.11 | A very strong task that directly reflects the B2 writing proficiency description (explaining one's position). It effectively tests the use of 'aby' + infinitive to express purpose. The only flaw is a minor but common grammatical error in the provided sentence ('d≈Çugiego e-maila' should be 'd≈Çugi e-mail' in the accusative case), which slightly detracts from its perfection.                                                                                                                                                    |
|          14 | GPT-5.2         | Multiple Choice |       7 |      2.29 | The task is a good B2-level vocabulary question testing nuance. However, it violates two explicit guidelines by including an English translation and instructions ('(EN: Choose the best word to complete the sentence.)') within the 'question' field. The prompt stated 'Do not translate any parts of the sentence in English' and 'Do not include any instructions for the task'.                                                                                                                                                     |
|          14 | GPT-5.2         | Fill Blank      |       8 |      7.93 | The task correctly targets a key B2 grammar point: the past conditional tense ('tryb przypuszczajƒÖcy z≈Ço≈ºony'). The sentence is natural and the context is appropriate. However, it slightly violates the 'only one correct answer' rule, as other verbs like 'uko≈Ñczy≈Çbym' (would have completed) or 'napisa≈Çbym' (would have written) could also fit the context, even if 'sko≈Ñczy≈Çbym' is the most direct translation of the hint.                                                                                                     |
|          14 | Gemini 3 Flash  | Multiple Choice |      10 |      1.49 | This candidate provides a perfect B2-level task. It follows all guidelines precisely. The sentence is complex, uses formal vocabulary appropriate for B2 ('zr√≥wnowa≈ºony rozw√≥j', 'zamierzony cel'), and tests the correct verb form (infinitive with correct aspect) in a dependent clause. This accurately reflects the ability to construct and understand detailed, formal text.                                                                                                                                                       |
|          14 | Gemini 3 Flash  | Fill Blank      |       9 |      1.66 | A very strong B2-level task focusing on vocabulary and collocation ('osiƒÖgnƒÖƒá porozumienie'). The context is appropriate for the level. The answer is the most natural and expected choice, strongly guided by the English hint 'to reach', making it effectively deterministic and a good test of a learner's lexical knowledge.                                                                                                                                                                                                         |
|          14 | Llama 4         | Multiple Choice |       5 |      1.57 | While the format is correct and it follows the negative constraints, the task itself is not at a B2 level. Testing the basic past tense aspect distinction ('zrobi≈Çem' vs 'robi≈Çem') for a simple completed action is a core B1 skill. The task does not meet the required proficiency level.                                                                                                                                                                                                                                             |
|          14 | Llama 4         | Fill Blank      |       2 |      1.12 | This candidate fails on multiple critical guidelines. The question is highly ambiguous, allowing for numerous correct answers (e.g., 'tygodnia', 'dw√≥ch tygodni'), which violates the determinism rule. It also fails to include the mandatory English translation of the missing word. Furthermore, the sentence's logical construction is slightly awkward, and the tested concept (genitive case after 'od') is more typical of the B1 level.                                                                                          |
|          14 | Mistral Large 3 | Multiple Choice |       6 |      3.32 | The task tests the difference between perfective and imperfective verbs, which is more characteristic of a B1 level than B2. A B2 task should test more complex structures or vocabulary. Additionally, it violates the guideline 'Do not include any instructions for the task' by adding 'Kt√≥re s≈Çowo najlepiej uzupe≈Çnia zdanie:' to the question.                                                                                                                                                                                     |
|          14 | Mistral Large 3 | Fill Blank      |      10 |      2.08 | This is an excellent B2-level task. It tests relevant vocabulary ('zaimprowizowaƒá') within a realistic business context. The task is well-formed, follows all instructions, and the answer is unambiguous and deterministic, testing the infinitive form after a modal verb.                                                                                                                                                                                                                                                              |
|          14 | Qwen 3 Max      | Multiple Choice |      10 |      6.09 | This is an excellent B2-level task. It strictly adheres to all instructions, including the negative constraints (no instructions, no translations). The question tests a subtle but important grammatical distinction between an adjective, participles, and an adverb, using level-appropriate vocabulary ('pogardliwy') in a realistic context. The distractors are very well-chosen.                                                                                                                                                   |
|          14 | Qwen 3 Max      | Fill Blank      |      10 |      3.82 | A perfect B2-level grammar task. It precisely tests the use of relative pronouns in a complex sentence and the required case declension ('kt√≥rego' in the accusative). The sentence is natural, the context is clear, and the answer is unequivocally the only correct one. It fully adheres to all guidelines.                                                                                                                                                                                                                           |
|          15 | GPT-5.2         | Multiple Choice |       8 |      6.3  | The task is excellent, testing B2-level vocabulary ('podkre≈õliƒá') in a highly relevant professional context (writing a report). The options are well-differentiated. However, it fails to strictly adhere to the output format by providing the `correctAnswer` as a string instead of an array containing a string, as specified in the instructions.                                                                                                                                                                                    |
|          15 | GPT-5.2         | Fill Blank      |       9 |      1.92 | Excellent task. The context of writing a report is perfectly aligned with the B2 level description. The vocabulary 'poczyniƒá postƒôpy' is a sophisticated and natural collocation. While 'zrobi≈Ç' could be a possible alternative, 'poczyni≈Ç' is stylistically superior and more likely in this formal context, thus adhering well to the guideline of choosing the 'most likely' word.                                                                                                                                                    |
|          15 | Gemini 3 Flash  | Multiple Choice |       8 |      1.28 | An excellent task with a context that is perfectly aligned with the B2 writing description (writing an essay). It tests knowledge of academic collocations ('przytacza argumenty'). The score is brought down by the failure to adhere to the specified JSON format for the `correctAnswer` field, which should have been an array.                                                                                                                                                                                                       |
|          15 | Gemini 3 Flash  | Fill Blank      |       7 |      1.52 | A strong task with a relevant B2-level topic (discussing pros and cons) and appropriate vocabulary. Its main weakness is the ambiguity of the answer. 'ZwracajƒÖ uwagƒô' (draw attention) is an equally valid and common alternative to 'wskazujƒÖ' (point out), which violates the strict instruction for a single deterministic answer.                                                                                                                                                                                                    |
|          15 | Llama 4         | Multiple Choice |      10 |      0.68 | This candidate is flawless. It perfectly adheres to all instructions, including the specific JSON format for the `correctAnswer` field. The task tests appropriate B2 vocabulary ('udoskonaliƒá') in a context (hobbies/interests) that is both relevant to the proficiency description and explicitly allowed by the prompt's examples. The question is natural and the answer is unambiguous.                                                                                                                                            |
|          15 | Llama 4         | Fill Blank      |       6 |      0.48 | The task's concept is excellent, with a context (writing an essay) and vocabulary ('argumentowaƒá', 'znaczƒÖcy wp≈Çyw') that perfectly match the B2 level. However, it contains a critical grammatical error ('turysty' instead of 'turystyka') that makes the sentence incorrect, significantly lowering its quality.                                                                                                                                                                                                                       |
|          15 | Mistral Large 3 | Multiple Choice |       5 |      3.63 | This candidate violates two major guidelines. First, it includes instructions ('Kt√≥re s≈Çowo najlepiej pasuje do zdania:') within the 'question' field, which was explicitly forbidden. Second, the options 'zanurzeniu' and 'zanurzaniu' are too similar and both grammatically plausible, violating the 'deterministic' answer requirement.                                                                                                                                                                                              |
|          15 | Mistral Large 3 | Fill Blank      |       4 |      4.74 | The task is significantly flawed due to ambiguity. Both 'pojechaƒá' (go by vehicle) and 'p√≥j≈õƒá' (go on foot) are equally valid and common answers, which violates the 'one correct answer' rule. Additionally, the grammatical structure and vocabulary are more typical of a B1 level than B2.                                                                                                                                                                                                                                            |
|          15 | Qwen 3 Max      | Multiple Choice |       8 |      5.73 | A very strong task testing a key B2 grammar point (subjunctive mood after 'aby') in a relevant professional context. The question is clear and the distractors are well-designed. The score is reduced because it fails to follow the strict formatting guideline for the `correctAnswer` field, providing a string instead of an array.                                                                                                                                                                                                  |
|          15 | Qwen 3 Max      | Fill Blank      |       3 |      4.04 | This task is not suitable for the B2 level; the grammar (simple past tense) and vocabulary are elementary (A2/B1). Furthermore, it fails to provide all correct answers. Besides 'poszed≈Çem/posz≈Çam' (went on foot), 'pojecha≈Çem/pojecha≈Çam' (went by vehicle) are also correct, making the provided answer array incomplete and the question ambiguous.                                                                                                                                                                                  |

### üåê Language: RUSSIAN | Level: A1
|   iteration | model           | task_type       |   score |   latency | reason                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
|------------:|:----------------|:----------------|--------:|----------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|           1 | GPT-5.2         | Multiple Choice |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|           1 | GPT-5.2         | Fill Blank      |       0 |      1.96 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           1 | Gemini 3 Flash  | Multiple Choice |       8 |      1.22 | A very strong task that tests the prepositional case in a clear context relevant to the A1 level (stating where one lives). The task is slightly better than Candidate 2's due to the added context. However, like Candidate 2, it failed to adhere to the JSON format, providing 'correctAnswer' as a string instead of the requested array.                                                                                                                                                                                         |
|           1 | Gemini 3 Flash  | Fill Blank      |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|           1 | Llama 4         | Multiple Choice |       7 |      1.05 | The task is a suitable A1 vocabulary question. However, it violates two explicit instructions: 'The task must consist of a single sentence' and 'Do not include any instructions for the task'. The candidate included the instruction '–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—Å–∫:' within the 'question' string.                                                                                                                                                                                                                                             |
|           1 | Llama 4         | Fill Blank      |       0 |      2.85 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           1 | Mistral Large 3 | Multiple Choice |      10 |      1.96 | The candidate perfectly followed all instructions. The task is a classic A1 grammar question (verb conjugation in the present tense) set in a simple, everyday context. The JSON format is valid, and the 'correctAnswer' field correctly uses an array as specified. The distractors are logical and test common beginner mistakes.                                                                                                                                                                                                  |
|           1 | Mistral Large 3 | Fill Blank      |       0 |      1.12 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           1 | Qwen 3 Max      | Multiple Choice |       8 |      6.79 | The task is excellent and perfectly aligned with the A1 level, testing the prepositional case for a location, which relates to filling in personal details. However, it failed to follow a specific formatting instruction: the 'correctAnswer' field should have been an array of strings (["–ú–æ—Å–∫–≤–µ"]) but was provided as a single string.                                                                                                                                                                                          |
|           1 | Qwen 3 Max      | Fill Blank      |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|           2 | GPT-5.2         | Multiple Choice |       9 |      1.49 | Excellent task that perfectly aligns with the A1 level description of 'filling in forms'. It tests a fundamental A1 grammar point (1st person verb conjugation). The only minor issue is that `correctAnswer` is a string instead of an array as suggested by the prompt's example format description.                                                                                                                                                                                                                                |
|           2 | GPT-5.2         | Fill Blank      |       0 |      1.91 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           2 | Gemini 3 Flash  | Multiple Choice |      10 |      1.17 | This is an outstanding A1 task. It tests a crucial and often difficult grammar point for writing (prepositional case for location) in a very simple, clear, and common context. The distractors are perfectly chosen, representing common case errors. It fully adheres to the spirit of the prompt, creating a task directly relevant to writing personal details.                                                                                                                                                                   |
|           2 | Gemini 3 Flash  | Fill Blank      |       0 |      1.1  | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           2 | Llama 4         | Multiple Choice |       3 |      1.05 | Fails on multiple guidelines. The JSON format is incorrect, using a different key (`correct`) and an index for the answer instead of the specified `correctAnswer` field and value. It includes instructions within the question, violating a specific guideline. The context is also too close to the example provided in the prompt.                                                                                                                                                                                                |
|           2 | Llama 4         | Fill Blank      |       0 |      0.87 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           2 | Mistral Large 3 | Multiple Choice |       8 |      2.32 | A good A1 task testing verb conjugation in a daily routine context. It correctly follows the specified JSON format for `correctAnswer` by using an array. However, it slightly deviates from the 'single sentence' guideline by including a second sentence in the question.                                                                                                                                                                                                                                                          |
|           2 | Mistral Large 3 | Fill Blank      |       0 |      1.38 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           2 | Qwen 3 Max      | Multiple Choice |       9 |      4.56 | An excellent A1 task that creatively uses the 'writing a letter' context, which is a great parallel to the 'postcard' example without copying it. It tests a core grammar point effectively. Like Candidate 1, it has a minor format deviation, providing `correctAnswer` as a string instead of an array.                                                                                                                                                                                                                            |
|           2 | Qwen 3 Max      | Fill Blank      |       0 |      3.17 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|           3 | GPT-5.2         | Multiple Choice |       9 |      7.09 | The task is excellent and perfectly aligns with the A1 level and the 'filling in forms' context from the prompt. It tests a fundamental grammar point (prepositional case of location) with clear, unambiguous options. The only minor flaw is that the `correctAnswer` is a string instead of an array of strings, which deviates from the specified JSON format example.                                                                                                                                                            |
|           3 | GPT-5.2         | Fill Blank      |      10 |      1.98 | This is an excellent task that perfectly adheres to all instructions. It directly relates to the A1 level description of writing a short postcard for greetings. The task tests both vocabulary ('–¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è') and a key A1 grammar point (the Instrumental case after the preposition '—Å'). The sentence is natural, the answer is unambiguous, and the format is correct. It is a model example of a well-designed, level-appropriate task.                                                                                      |
|           3 | Gemini 3 Flash  | Multiple Choice |       7 |      1.41 | The task correctly targets an A1 grammar point (prepositional case) and has a relevant context. However, the phrasing '–≤ –≥–æ—Ä–æ–¥–µ ______' is slightly ambiguous, as the appositive construction '–≤ –≥–æ—Ä–æ–¥–µ –ú–æ—Å–∫–≤–∞' (nominative case) is also possible in some contexts, which could confuse learners. The task is less direct than Candidate 1's. It also uses a string for the answer instead of an array.                                                                                                                              |
|           3 | Gemini 3 Flash  | Fill Blank      |       9 |      1.69 | This is a very strong candidate. The task is simple, clear, and perfectly appropriate for the A1 level, testing the fundamental introductory phrase '–ú–µ–Ω—è –∑–æ–≤—É—Ç...'. It aligns well with the 'filling in forms with personal details' part of the level description. The answer is completely unambiguous and all formatting instructions are followed correctly. While slightly more basic than Candidate 1's task, it is an excellent and highly effective question for a beginner.                                                 |
|           3 | Llama 4         | Multiple Choice |       5 |      2.41 | While the JSON format is correct, the task is not suitable for the A1 level. The use of a complex sentence with a subordinate clause ('...–≥–¥–µ –µ—Å—Ç—å...') and the grammar point itself (accusative animate plural) are characteristic of the A2 level or higher. It fails the core requirement of matching the specified proficiency level.                                                                                                                                                                                             |
|           3 | Llama 4         | Fill Blank      |       3 |      0.66 | The candidate fails on several key guidelines. Most importantly, it demonstrates a critical lack of accuracy by providing a grammatically incorrect word ('–∂–∏–≤—É') as a correct answer; '–Ø –∂–∏–≤—É –∏–∑ –ú–æ—Å–∫–≤—ã' is wrong. Furthermore, the task is ambiguous, as other words like '–ø—Ä–∏–µ—Ö–∞–ª–∞' (arrived) could also fit, violating the 'only one correct answer' rule. The English hint '(am)' is also vague and unhelpful for eliciting the correct word '—Ä–æ–¥–æ–º'. The JSON itself is valid, but the linguistic content is deeply flawed.     |
|           3 | Mistral Large 3 | Multiple Choice |       6 |      2.01 | The task uses appropriate A1 vocabulary and has a correct JSON format (using an array for the answer). However, it fails to follow a strict guideline by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ:') in the question. Additionally, its context is more generic and less specifically tied to the 'writing' skill description compared to other candidates.                                                                                                                                                                 |
|           3 | Mistral Large 3 | Fill Blank      |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|           3 | Qwen 3 Max      | Multiple Choice |       9 |      3.59 | This is an outstanding task that creatively and accurately targets the 'writing a short, simple postcard' skill described in the prompt. It tests A1-level adjective-noun agreement in a very natural context, and the options are perfectly chosen. Like Candidate 1, its only minor imperfection is the `correctAnswer` format being a string instead of an array.                                                                                                                                                                  |
|           3 | Qwen 3 Max      | Fill Blank      |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|           4 | GPT-5.2         | Multiple Choice |       9 |     15.16 | Excellent adherence to the prompt's core requirement. The context '–í –∞–Ω–∫–µ—Ç–µ:' (In the form:) directly targets the specified A1 writing skill of filling in forms. The task itself, choosing the correct preposition of place ('–≤'), is a fundamental A1 concept. The only flaw is that `correctAnswer` is a string instead of an array of strings as specified in the prompt's example, which is a minor formatting deviation.                                                                                                        |
|           4 | GPT-5.2         | Fill Blank      |       9 |      1.04 | The task is excellent and highly relevant to the A1 level, directly referencing the 'postcard' example. It correctly tests the first-person singular conjugation of a key verb ('–ø–∏—à—É'). The format is perfect. A point is deducted because '–î–æ—Ä–æ–≥–∞—è –ê–Ω–Ω–∞,' is a salutation, not part of the sentence, which slightly bends the 'create one sentence' rule, even though it makes the context more naturalistic.                                                                                                                       |
|           4 | Gemini 3 Flash  | Multiple Choice |       8 |      1.44 | A very good task that is highly relevant to the prompt. The context '–ú–µ–Ω—è –∑–æ–≤—É—Ç –ò–≤–∞–Ω. –Ø –∂–∏–≤—É –≤ –≥–æ—Ä–æ–¥–µ...' perfectly simulates providing personal information for a form. It tests the prepositional case, a core A1 skill. Like Candidates 1 and 3, its only weakness is a minor formatting error where `correctAnswer` is a string instead of the requested array.                                                                                                                                                                   |
|           4 | Gemini 3 Flash  | Fill Blank      |      10 |      1.77 | An exemplary response that follows all guidelines perfectly. The task tests the fundamental A1 phrase for introducing oneself ('–ú–µ–Ω—è –∑–æ–≤—É—Ç'), which directly relates to the 'fill in forms with personal details' skill. The question is simple, unambiguous, level-appropriate, and correctly formatted. It is a classic and effective A1 language task.                                                                                                                                                                             |
|           4 | Llama 4         | Multiple Choice |       9 |      2.58 | This submission perfectly adheres to all instructions, including the JSON structure with `correctAnswer` as an array. The task tests the prepositional case, which is appropriate for A1. The context of where one lives is relevant to personal details. The sentence is slightly more complex than other candidates, but it remains well within the A1 level. Its strict adherence to all rules makes it an excellent response.                                                                                                     |
|           4 | Llama 4         | Fill Blank      |       4 |      0.33 | The task has significant flaws. The English translation for the missing word, '(am)', is inaccurate for the correct answer '—Ä–æ–¥–æ–º' (which means 'originally from' or 'by birth from'). This is highly misleading for a learner. Additionally, the word '—Ä–æ–¥–æ–º' is arguably A2 level, making the task potentially too difficult and not focused on core A1 skills. A simpler construction like '–Ø –∏–∑ –ú–æ—Å–∫–≤—ã' would be more appropriate.                                                                                                |
|           4 | Mistral Large 3 | Multiple Choice |       5 |      1.88 | Fails to follow two strict guidelines. It includes instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ:') within the 'question' field, which was explicitly forbidden. Furthermore, while the task is appropriate for A1 level, its context (daily routine) does not align with the specified writing skill of 'filling in forms with personal details'. The JSON format is correct, but the content misses the mark.                                                                                                                            |
|           4 | Mistral Large 3 | Fill Blank      |       2 |      2.17 | This candidate fails on several core requirements. Firstly, the JSON format is incorrect as it includes an extra 'translation' field. More importantly, the task design is fundamentally flawed. It asks for a personal name, which is not a deterministic vocabulary or grammar test item, violating the guideline that the answer must have 'only one correct answer' or be a 'deterministic' set. It's a prompt for personal information, not a language assessment task.                                                          |
|           4 | Qwen 3 Max      | Multiple Choice |       8 |      4.56 | This is a strong candidate. The task correctly tests a crucial A1 grammar point (the prepositional case of a noun after '–≤'). The context '–Ø –∂–∏–≤—É –≤...' is highly relevant to providing personal details for a form. The distractors are well-chosen case variations. It loses points for not formatting the `correctAnswer` as an array, a minor deviation from the instructions.                                                                                                                                                    |
|           4 | Qwen 3 Max      | Fill Blank      |      10 |      3.32 | This is a perfect response that adheres to all instructions. The task tests both a key A1 vocabulary word ('–æ—Ç–∫—Ä—ã—Ç–∫–∞' - postcard) and a fundamental grammatical concept (the accusative case). It is unambiguous, correctly formatted, and directly relevant to the proficiency description provided in the prompt.                                                                                                                                                                                                                   |
|           5 | GPT-5.2         | Multiple Choice |       8 |     29.18 | The task tests a relevant A1 grammar point (prepositions of direction). However, it violates guideline #9 by including the instructional phrase '–ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ:' ('What is correct:') in the question string. The format for 'correctAnswer' is a string, while the prompt ambiguously suggested an array.                                                                                                                                                                                                                            |
|           5 | GPT-5.2         | Fill Blank      |       9 |      1.22 | The task is excellent and perfectly aligned with the A1 level and the 'postcard writing' context given in the prompt. It correctly tests the first-person present tense conjugation of the common verb '–ø–∏—Å–∞—Ç—å' (to write). The JSON is valid and all instructions were followed. It's a high-quality, relevant exercise.                                                                                                                                                                                                             |
|           5 | Gemini 3 Flash  | Multiple Choice |       9 |      1.37 | This is a very strong and well-designed task. It tests a specific, important, and challenging A1 grammar point (prepositional case of a proper noun) that directly relates to the skill of filling in personal details. The options are excellent distractors. The only minor issue is that the 'correctAnswer' is a string instead of an array as suggested by the prompt.                                                                                                                                                           |
|           5 | Gemini 3 Flash  | Fill Blank      |       8 |      1.18 | This is a very good task that tests a foundational A1 phrase for introductions ('–ú–µ–Ω—è –∑–æ–≤—É—Ç'). It is extremely relevant for a beginner, unambiguous, and grammatically perfect. The task adheres to all guidelines. While it represents the simpler end of the A1 spectrum, its correctness and relevance make it a strong and useful item.                                                                                                                                                                                           |
|           5 | Llama 4         | Multiple Choice |       2 |      0.51 | This task is fundamentally flawed as a language assessment. It does not test a language skill but rather a cultural stereotype or logical assumption (that a person from Russia must have a Russian city as their favorite). All options are grammatically correct, making the question non-deterministic and unfair. It completely fails the guideline that the answer must not allow for multiple interpretations.                                                                                                                  |
|           5 | Llama 4         | Fill Blank      |       8 |      1.15 | A solid and well-constructed task. It correctly tests a core A1 grammar concept: the prepositional case for location ('–≤ –≥–æ—Ä–æ–¥–µ'). The context of providing personal information is relevant to the level. The task is clear, accurate, and follows all formatting rules. While not as creative as other candidates in using the 'postcard' theme, it is a very effective and standard A1 exercise.                                                                                                                                   |
|           5 | Mistral Large 3 | Multiple Choice |      10 |      2.05 | This is an excellent task that perfectly adheres to all instructions. It tests a fundamental A1 grammar point (present tense verb conjugation) in a common daily life context. The distractors are well-chosen, and the JSON format, including the array for 'correctAnswer', is correct.                                                                                                                                                                                                                                             |
|           5 | Mistral Large 3 | Fill Blank      |       1 |      1.34 | The generated task is grammatically incorrect. The sentence '—è ____ –∏–∑ –†–æ—Å—Å–∏–∏' cannot be completed with the provided correct answer '–∂–∏–≤—É'. The correct phrasing for 'I live in Russia' is '—è –∂–∏–≤—É –≤ –†–æ—Å—Å–∏–∏', and for 'I am from Russia' is '—è –∏–∑ –†–æ—Å—Å–∏–∏'. This fundamental error makes the task unsolvable and confusing for a learner.                                                                                                                                                                                              |
|           5 | Qwen 3 Max      | Multiple Choice |       4 |      4.58 | The task is grammatically correct, but it violates the core requirement of being deterministic with a single correct answer. All four options ('postcard', 'book', 'letter', 'package') are grammatically and semantically plausible items to send for a birthday. The question does not test a specific language skill but rather relies on guessing the intended answer, which was likely inspired too closely by the prompt's example.                                                                                             |
|           5 | Qwen 3 Max      | Fill Blank      |      10 |      4.07 | This is a perfect response. The task cleverly uses the 'postcard' theme from the proficiency description. It tests both A1 vocabulary ('–æ—Ç–∫—Ä—ã—Ç–∫–∞' - postcard) and a crucial A1 grammar point (the accusative case). The question is natural, unambiguous, and perfectly suited for the target level. All formatting and content guidelines were strictly followed.                                                                                                                                                                    |
|           6 | GPT-5.2         | Multiple Choice |      10 |     19.41 | The task perfectly aligns with the A1 level description of 'filling in forms' by using the context '–í –∞–Ω–∫–µ—Ç–µ' (In the form). It tests a fundamental A1 grammar point: gender agreement of possessive pronouns ('–∏–º—è' is neuter). The options are clear and well-chosen distractors. The format is valid and all instructions were followed.                                                                                                                                                                                           |
|           6 | GPT-5.2         | Fill Blank      |      10 |      1.08 | The candidate produced a perfectly formatted JSON. The task is excellent for the A1 level, directly referencing the 'writing a postcard' skill mentioned in the prompt. It tests a high-frequency verb ('–ø–∏—Å–∞—Ç—å') in the correct 1st person singular present tense form ('–ø–∏—à—É'), which is a core A1 grammar point. The sentence is natural, and the answer is deterministic, fulfilling all guidelines.                                                                                                                              |
|           6 | Gemini 3 Flash  | Multiple Choice |      10 |      1.17 | An outstanding task that aligns perfectly with providing personal details for a form or postcard. It tests the prepositional case with '–≤' to indicate location ('–Ø –∂–∏–≤—É –≤ –ú–æ—Å–∫–≤–µ'), which is a crucial and fundamental concept for A1 learners. The options correctly test different cases of the same noun, making it an effective grammar check.                                                                                                                                                                                   |
|           6 | Gemini 3 Flash  | Fill Blank      |       9 |      1.67 | The candidate followed all formatting instructions correctly. The task is highly appropriate for the A1 level, testing the crucial fixed expression '–ú–µ–Ω—è –∑–æ–≤—É—Ç' (My name is). This is one of the first phrases learners acquire and is directly related to providing personal details. The sentence is natural, and the answer is deterministic. A very strong and fundamental A1 task.                                                                                                                                              |
|           6 | Llama 4         | Multiple Choice |       9 |      1.48 | A strong task that fits the 'filling in forms with personal details' context by asking for age. It correctly tests the use of cardinal numbers, an A1 topic. The JSON format is correct. The task is well-designed, although the case-based distractors might be slightly challenging for the very beginning of A1, but the correct answer is the most basic form.                                                                                                                                                                    |
|           6 | Llama 4         | Fill Blank      |       9 |      1.28 | The output is a valid JSON and follows the specified format. The task is very good for the A1 level, testing the essential preposition '–∏–∑' to indicate origin. This aligns with the 'personal details' aspect of the proficiency description. The sentence is natural and the answer is deterministic. It's a solid A1 task, though slightly less complex than tasks testing verb conjugations or noun cases.                                                                                                                        |
|           6 | Mistral Large 3 | Multiple Choice |       8 |      2.15 | A good A1-level task testing present tense verb conjugation, a core skill. However, the daily routine context ('I drink coffee every morning') is less directly tied to the specified writing skills ('filling in forms' or 'writing a postcard') compared to other candidates, making it less tailored to the prompt's specific context.                                                                                                                                                                                             |
|           6 | Mistral Large 3 | Fill Blank      |       3 |      2.15 | The JSON format is incorrect as it includes an extra, unrequested 'translation' field. More importantly, the task design is fundamentally flawed. By asking for a 'name' and providing a non-exhaustive list of examples as 'correctAnswer', it violates the crucial guideline that the answer must be deterministic. The task becomes a guessing game, not a valid language assessment.                                                                                                                                              |
|           6 | Qwen 3 Max      | Multiple Choice |      10 |      3.38 | Excellent task that directly reflects the 'writing a short, simple postcard' skill from the level description by framing the question as 'I am writing a letter to a friend...'. It tests adjective-noun gender agreement ('–ø–æ–≥–æ–¥–∞' is feminine), a key A1 concept. The options are perfect distractors and it fully meets all prompt requirements.                                                                                                                                                                                   |
|           6 | Qwen 3 Max      | Fill Blank      |      10 |      3.04 | This candidate provides a perfect response. The JSON is well-formatted. The task cleverly combines vocabulary and grammar relevant to the A1 level and the specific skill of 'writing a postcard'. It tests the noun '–æ—Ç–∫—Ä—ã—Ç–∫–∞' (postcard) in the required accusative case ('–æ—Ç–∫—Ä—ã—Ç–∫—É'), a key grammatical concept for beginners. The context is natural and the answer is unambiguous.                                                                                                                                               |
|           7 | GPT-5.2         | Multiple Choice |       8 |     22.62 | The task directly addresses the 'filling in forms' context, which is excellent. However, the question tests world knowledge (knowing Moscow is in Russia) rather than a specific grammatical or vocabulary point in the way a language task typically would. The JSON is valid but includes an extra 'translation' field not specified in the final structure, likely an attempt to resolve contradictory instructions in the prompt. The 'correctAnswer' format as a string is an acceptable interpretation of the ambiguous prompt. |
|           7 | GPT-5.2         | Fill Blank      |       9 |      1.48 | This is a very strong candidate that aligns perfectly with the A1 level description of 'sending holiday greetings' on a postcard. It tests a common and useful set phrase ('—Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è') and the instrumental case. The task is clear and natural. It loses one point because the alternative (though dated/poetic) spelling '—Ä–æ–∂–¥–µ–Ω—å—è' is also technically possible, which slightly goes against the 'only one correct answer' guideline, although '—Ä–æ–∂–¥–µ–Ω–∏—è' is the standard and expected answer at this level.                |
|           7 | Gemini 3 Flash  | Multiple Choice |      10 |      1.22 | This is a perfect response, functionally identical to Candidate 3. It creates a flawless A1 grammar task testing the prepositional case, a skill directly applicable to writing one's personal details. The task is clear, level-appropriate, and adheres to all constraints of the prompt, resulting in a high-quality educational item.                                                                                                                                                                                             |
|           7 | Gemini 3 Flash  | Fill Blank      |      10 |      1.14 | A perfect candidate. This task tests one of the most fundamental phrases an A1 learner acquires: introducing oneself. '–ú–µ–Ω—è –∑–æ–≤—É—Ç...' is a core vocabulary and grammar point. The task is simple, clear, unambiguous, and perfectly aligned with the 'personal details' competency for the A1 level. All guidelines, including JSON format and content, are met flawlessly.                                                                                                                                                           |
|           7 | Llama 4         | Multiple Choice |      10 |      1.27 | This is another excellent response. It correctly identifies a core A1 grammar point (genitive case after '–∏–∑') needed to provide personal information. The context is perfectly aligned with the proficiency description, the task is well-formed, and it follows all instructions, including the JSON structure and using an array for 'correctAnswer' as suggested in the prompt example.                                                                                                                                           |
|           7 | Llama 4         | Fill Blank      |       9 |      1.74 | A very good candidate that tests a fundamental A1 structure for stating one's origin. The sentence is correct and relevant to the 'personal details' aspect of the proficiency level. The only minor flaw is the English prompt '(am from)' for a blank that requires only the preposition '–∏–∑' (from). The verb 'am' is omitted in Russian, so the prompt is a slight over-translation for the single-word answer, which could be minimally confusing.                                                                               |
|           7 | Mistral Large 3 | Multiple Choice |       4 |      2.01 | While this is a valid and well-constructed A1 vocabulary task, it completely fails to adhere to the central requirement of the prompt: creating a task related to the writing skill of 'filling in forms with personal details'. The context of drinking coffee is unrelated to the specified proficiency description.                                                                                                                                                                                                                |
|           7 | Mistral Large 3 | Fill Blank      |       1 |      1.13 | This candidate is a complete failure. The question '–ú–µ–Ω—è –∑–æ–≤—É—Ç ____ –ò–≤–∞–Ω' is grammatically and logically incoherent, as it provides a name ('–ò–≤–∞–Ω') and then asks for another name to be inserted. The provided 'correctAnswer' ('–ê–Ω–¥—Ä–µ–π') is completely arbitrary and makes the sentence nonsensical. The task does not test any linguistic skill and would only confuse a learner.                                                                                                                                                  |
|           7 | Qwen 3 Max      | Multiple Choice |      10 |      4.38 | This is an outstanding response. It perfectly targets the underlying grammatical knowledge (prepositional case after '–≤') required for the A1 writing skill of providing personal details like an address. The task is clear, the options are excellent distractors, and it adheres flawlessly to all formatting and content instructions.                                                                                                                                                                                            |
|           7 | Qwen 3 Max      | Fill Blank      |      10 |      3.03 | An excellent candidate that perfectly fulfills all instructions. The task is directly inspired by the level description ('write a short, simple postcard') without copying it. It tests a core A1 grammar point (accusative case for a feminine noun) within a natural, unambiguous, and level-appropriate context. The formatting and content are flawless.                                                                                                                                                                          |
|           8 | GPT-5.2         | Multiple Choice |      10 |     11.6  | The candidate perfectly aligns with the prompt's requirements. The task, choosing the correct preposition for a city, is a fundamental A1 skill. Crucially, the context '–í –∞–Ω–∫–µ—Ç–µ:' ('In the form:') directly targets the specified proficiency description 'fill in forms with personal details', showing a superior understanding of the instructions. The task is accurate, level-appropriate, and unambiguous.                                                                                                                    |
|           8 | GPT-5.2         | Fill Blank      |      10 |      1.59 | Excellent task that directly aligns with the A1 level description of 'writing a short, simple postcard, for example sending holiday greetings.' It tests the essential fixed phrase '—Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è' and the associated instrumental case, which is appropriate for the level. The task is deterministic and follows all instructions perfectly.                                                                                                                                                                                     |
|           8 | Gemini 3 Flash  | Multiple Choice |       9 |      1.85 | The task is a fundamental A1 grammar exercise (verb conjugation) set in the context of providing personal information ('My name is... I live...'). This aligns well with the 'fill in forms' aspect of the proficiency description. The task is accurate, clear, and perfectly level-appropriate. It's a very solid and effective task, only slightly less creative in its contextual framing than the top-scoring candidates.                                                                                                        |
|           8 | Gemini 3 Flash  | Fill Blank      |       9 |      0.97 | A very good task that tests the essential A1 phrase '–ú–µ–Ω—è –∑–æ–≤—É—Ç...' (My name is...). It correctly creates a deterministic question for this structure, unlike Candidate 2. The task is clear, accurate, and relevant to the 'personal details' aspect of the A1 level. It is a textbook example of a good A1 vocabulary/grammar question.                                                                                                                                                                                             |
|           8 | Llama 4         | Multiple Choice |       9 |      0.42 | This is a strong A1 grammar task testing the dative plural case for days of the week, a useful structure for writing about routines in a letter or postcard. The task is accurate and the distractors are well-designed (other case forms). While the grammar point might be considered high-A1, it is still appropriate. The connection to the writing skill is good, though not as explicit as in candidates 1 and 3.                                                                                                               |
|           8 | Llama 4         | Fill Blank      |       8 |      0.42 | A solid A1 task testing a fundamental structure for stating one's origin ('—è –∏–∑...'). The topic of personal details is relevant. However, the English cue '(am from)' is slightly imprecise as it might lead learners to look for a verb, while the correct answer is a preposition ('–∏–∑'). A cue of just '(from)' would have been clearer.                                                                                                                                                                                           |
|           8 | Mistral Large 3 | Multiple Choice |       9 |      1.74 | The task is a valid A1 vocabulary question about daily routines, which is relevant context for writing a simple postcard or message. The format is correct, and the options are well-chosen. It is slightly less targeted to the specific writing skills mentioned in the prompt (form-filling or postcard writing) compared to other candidates, although it's still a very good and appropriate task.                                                                                                                               |
|           8 | Mistral Large 3 | Fill Blank      |       3 |      1.42 | This candidate fundamentally misunderstands the nature of a deterministic fill-in-the-blank task. Guideline #7 ('only one correct answer') and #9 ('The answer should be deterministic') are violated. While the topic is A1, allowing any name as an answer makes it an invalid assessment of linguistic knowledge rather than a test of a specific word or grammar point.                                                                                                                                                           |
|           8 | Qwen 3 Max      | Multiple Choice |      10 |      4.07 | The candidate provided an excellent interpretation of the prompt. The contextual framing '–Ø –ø–∏—à—É –ø–∏—Å—å–º–æ –¥—Ä—É–≥—É –∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å:' ('I'm writing a letter to a friend and I want to say:') brilliantly connects the grammar task (verb conjugation) directly to the act of writing, which perfectly matches the proficiency description. The task is clear, accurate, and highly relevant.                                                                                                                                                |
|           8 | Qwen 3 Max      | Fill Blank      |      10 |      2.8  | Perfect execution. The task is directly inspired by the A1 skill description ('I can write a short, simple postcard'). It correctly tests both A1 vocabulary ('–æ—Ç–∫—Ä—ã—Ç–∫–∞') and a core A1 grammar point (the accusative case for a direct object). The task is unambiguous, deterministic, and adheres to all guidelines.                                                                                                                                                                                                               |
|           9 | GPT-5.2         | Multiple Choice |       8 |     16.98 | The task is excellent and tests a core A1 grammar point (prepositional case) relevant to the specified writing skill. However, the JSON format is incorrect as it includes an extra `translation` field not requested in the final schema and provides the `correctAnswer` as a string instead of an array of strings.                                                                                                                                                                                                                |
|           9 | GPT-5.2         | Fill Blank      |       8 |      1.34 | The task is well-formed, grammatically correct, and appropriate for the A1 level. It tests verbs of motion ('–µ–¥—É'), a key A1 topic, within a natural context of telling someone about travel plans, which fits the 'postcard' theme. The only minor issue is that the perfective future '–ø–æ–µ–¥—É' could also be a valid answer for a planned weekend trip, making the answer not strictly unique. However, the English hint '(am going)' strongly favors the provided answer '–µ–¥—É'.                                                     |
|           9 | Gemini 3 Flash  | Multiple Choice |       9 |      1.03 | This is an excellent task that perfectly tests A1 verb conjugation in a context directly related to providing personal details. The task is clear and the distractors are well-chosen. Its only minor flaw is providing `correctAnswer` as a string instead of an array of strings.                                                                                                                                                                                                                                                   |
|           9 | Gemini 3 Flash  | Fill Blank      |      10 |      1.36 | This is a flawless execution of the instructions. The task tests one of the most fundamental phrases for an A1 learner ('–ú–µ–Ω—è –∑–æ–≤—É—Ç...'). It is completely unambiguous, with '–∑–æ–≤—É—Ç' being the only possible correct answer. The task directly relates to the 'fill in forms with personal details' aspect of the A1 level description. All formatting and content requirements from the prompt were met perfectly.                                                                                                                   |
|           9 | Llama 4         | Multiple Choice |       1 |      1.16 | The output fails on multiple critical instructions. It includes instructions and English words within the 'question' field, uses an incorrect JSON schema (`'correct': 2` instead of `correctAnswer`), and presents a confusing, multi-part question that is unnatural and poorly constructed.                                                                                                                                                                                                                                        |
|           9 | Llama 4         | Fill Blank      |       2 |      0.49 | The candidate failed on two major points. First, it did not follow the instruction to include the English translation of the missing word in the question. Second, the provided answer '–Ω–∞—á–∏–Ω–∞—é' creates a grammatically incorrect sentence: '–Ø –æ–±—ã—á–Ω–æ –Ω–∞—á–∏–Ω–∞—é –Ω–∞ —Ä–∞–±–æ—Ç—É' is wrong. The correct construction would be '–Ω–∞—á–∏–Ω–∞—é —Ä–∞–±–æ—Ç–∞—Ç—å' or '–Ω–∞—á–∏–Ω–∞—é —Ä–∞–±–æ—Ç—É'. The blank itself is ambiguous and could be filled with '—Ö–æ–∂—É' or '–µ–¥—É', but the provided answer is incorrect.                                                           |
|           9 | Mistral Large 3 | Multiple Choice |      10 |      2.04 | The candidate provides a solid A1 vocabulary task in a common daily routine context. It flawlessly adheres to all instructions, including the JSON structure with `correctAnswer` as an array. The task is clear, accurate, and perfectly level-appropriate.                                                                                                                                                                                                                                                                          |
|           9 | Mistral Large 3 | Fill Blank      |       2 |      1.37 | This task is fundamentally flawed. The resulting sentence '–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–Ω–∞, –∏ —è –∂–∏–≤—É –∏–∑ –†–æ—Å—Å–∏–∏' is grammatically incorrect. The verb '–∂–∏–≤—É' (I live) requires the preposition '–≤' (in), not '–∏–∑' (from). To express 'I am from Russia,' no verb is used in the present tense ('–Ø –∏–∑ –†–æ—Å—Å–∏–∏'). Therefore, the blank cannot be filled with the provided answer, or any single verb, to create a correct sentence. This task would confuse a learner.                                                                                    |
|           9 | Qwen 3 Max      | Multiple Choice |       9 |      3.39 | This is a very strong candidate. The task is highly relevant as it cleverly adapts the 'postcard/letter' context from the proficiency description without copying it. The vocabulary is appropriate for A1. The only minor flaw is that `correctAnswer` is a string, not an array of strings as specified in the instructions.                                                                                                                                                                                                        |
|           9 | Qwen 3 Max      | Fill Blank      |       9 |      2.81 | This is an excellent task that directly aligns with the 'writing a postcard' context from the proficiency description. It tests a very common set phrase ('–°—á–∞—Å—Ç–ª–∏–≤–æ–≥–æ –ù–æ–≤–æ–≥–æ –≥–æ–¥–∞!') and the use of the genitive case in greetings, which is a useful chunk of language for an A1 learner. The use of the English hint '(New Year)' successfully removes ambiguity. The sentence structure '...–∏ –≥–æ–≤–æ—Ä—é' is slightly unnatural but grammatically acceptable.                                                                         |
|          10 | GPT-5.2         | Multiple Choice |       6 |     18.72 | The candidate fails to follow several strict guidelines. It includes instructions within the 'question' field ('–ö–∞–∫–æ–µ —Å–ª–æ–≤–æ –ø–æ–¥—Ö–æ–¥–∏—Ç') and also translates them ('Which word fits'), directly violating guidelines #9 ('Do not include any instructions') and #7 ('Do not translate any parts of the sentence'). While the linguistic task itself (prepositions of motion) is appropriate for A1, these formatting errors are significant.                                                                                            |
|          10 | GPT-5.2         | Fill Blank      |       8 |      1.71 | A very good candidate that directly addresses the prompt's context of 'sending holiday greetings.' The task is level-appropriate (A1) and tests a common phrase. The grammar is correct ('—Å—á–∞—Å—Ç–ª–∏–≤—ã—Ö' is the correct genitive plural form). The only minor weakness is that other adjectives like '–≤–µ—Å—ë–ª—ã—Ö' (merry) or '—Ö–æ—Ä–æ—à–∏—Ö' (good) could also fit, slightly violating the 'only one correct answer' rule. However, the English cue 'happy' strongly points to the intended answer.                                               |
|          10 | Gemini 3 Flash  | Multiple Choice |      10 |      1.52 | This is an excellent and well-constructed task. It adheres to all guidelines, including the negative constraints. The task of choosing the correct case for a city name directly corresponds to the A1 writing skill 'fill in forms with personal details'. It tests a fundamental A1 grammar point (prepositional case of location) using a simple, clear, and highly relevant sentence structure.                                                                                                                                   |
|          10 | Gemini 3 Flash  | Fill Blank      |      10 |      1.13 | An excellent and perfectly executed task. It tests a fundamental A1 vocabulary/grammar chunk ('–ú–µ–Ω—è –∑–æ–≤—É—Ç'). The task is simple, clear, and absolutely essential for the level, aligning with the 'fill in forms with personal details' skill. It fully complies with the 'only one correct answer' guideline, as '–∑–æ–≤—É—Ç' is the only word that fits. The format is correct and the task is highly effective.                                                                                                                         |
|          10 | Llama 4         | Multiple Choice |       8 |      0.56 | The candidate correctly identifies a core A1 grammar point (instrumental case with '—Å') and follows the negative constraints about instructions and translations. However, the sentence structure ('–Ø –∂–∏–≤—É –≤ –≥–æ—Ä–æ–¥–µ, –≥–¥–µ –µ—Å—Ç—å –±–æ–ª—å—à–æ–π –ø–∞—Ä–∫...') is a complex sentence with a subordinate clause, which is too advanced for the A1 level. The complexity of the sentence distracts from the core task and does not align with the A1 proficiency of understanding 'very simple sentences'.                                             |
|          10 | Llama 4         | Fill Blank      |       3 |      0.85 | This candidate's output is grammatically flawed. It provides two 'correct' answers, but one of them is incorrect in the given context: '–Ø –∂–∏–≤—É –∏–∑ –ú–æ—Å–∫–≤—ã' is wrong; it should be '–Ø –∂–∏–≤—É –≤ –ú–æ—Å–∫–≤–µ'. This violates the accuracy requirement. Furthermore, it violates the 'only one correct answer' rule. The English cue '(am)' is also poorly chosen and misleading for a Russian sentence that omits the verb 'to be' in this context.                                                                                              |
|          10 | Mistral Large 3 | Multiple Choice |       7 |      2.15 | The candidate provides an excellent A1-level grammar task (verb conjugation). However, it violates guideline #9 by including the instruction '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ:' (Choose the correct word) in the 'question' field. It is better than Candidate 1 as it does not add a translation, but it still fails a key negative constraint.                                                                                                                                                                                            |
|          10 | Mistral Large 3 | Fill Blank      |       3 |      1.44 | This candidate fails a critical guideline. The instruction was to create a task with 'only one correct answer' to be deterministic. Instead, it creates an open-ended prompt where any name would be correct. The `correctAnswer` array lists examples, not the exhaustive or single correct answer. While the sentence '–ú–µ–Ω—è –∑–æ–≤—É—Ç ____.' is a staple for A1 learners, the task design fundamentally misunderstands the instructions.                                                                                                |
|          10 | Qwen 3 Max      | Multiple Choice |      10 |      3.17 | This is an outstanding response. It perfectly adheres to all instructions. The question is framed as a thought process while writing a letter ('–Ø –ø–∏—à—É –ø–∏—Å—å–º–æ... –∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å...'), which cleverly provides context without being a direct instruction, and directly relates to the 'writing a postcard' skill in the level description. The grammar point (adjective-noun agreement) is perfectly suited for A1. The task is natural, clear, and well-designed.                                                                    |
|          10 | Qwen 3 Max      | Fill Blank      |      10 |      4.68 | This is an outstanding response that perfectly adheres to all instructions. It creates a task directly inspired by the level description ('write a short, simple postcard'). It tests both vocabulary ('–æ—Ç–∫—Ä—ã—Ç–∫—É' - postcard) and a core A1 grammar concept (the accusative case after the verb '–ø–∏—à—É'). The English cue makes the task completely unambiguous, fulfilling the 'only one correct answer' requirement. The JSON format is perfect.                                                                                     |
|          11 | GPT-5.2         | Multiple Choice |       8 |     12.74 | The task is excellent for A1, testing a core grammatical concept (prepositional case for location) with clear options. It perfectly aligns with the level description. It loses points for a minor formatting error: including an unrequested 'translation' field in the JSON output, which deviates from the specified structure in the instructions.                                                                                                                                                                                |
|          11 | GPT-5.2         | Fill Blank      |       9 |      2.42 | Excellent task that aligns perfectly with the A1 level description of writing a postcard. It tests the set phrase '—Å –¥–Ω—ë–º —Ä–æ–∂–¥–µ–Ω–∏—è' and the instrumental case, making it a good grammar and vocabulary question. The hint '(birthday)' makes the answer highly deterministic. The format is valid.                                                                                                                                                                                                                                    |
|          11 | Gemini 3 Flash  | Multiple Choice |       3 |      1.03 | This candidate has several major flaws. It violates the 'single sentence' rule by providing two. More critically, it tests a complex and ambiguous grammar point (declension of an appositive city name) where multiple answers could be considered correct, violating the 'deterministic' answer requirement. This makes the task unsuitable for an A1 learner.                                                                                                                                                                      |
|          11 | Gemini 3 Flash  | Fill Blank      |      10 |      0.98 | This is a perfect A1 task. It tests the fundamental and fixed expression '–ú–µ–Ω—è –∑–æ–≤—É—Ç...'. The question is completely deterministic, as only the verb '–∑–æ–≤—É—Ç' can correctly complete the sentence. It perfectly follows all guidelines regarding level, format, and task design.                                                                                                                                                                                                                                                       |
|          11 | Llama 4         | Multiple Choice |       5 |      0.5  | The task tests a valid A1 grammar point (verb + infinitive). However, the sentence structure ('–Ø –∂–∏–≤—É –≤ –≥–æ—Ä–æ–¥–µ, –≥–¥–µ –µ—Å—Ç—å...') is too complex for the A1 level, featuring a relative clause that is more typical of A2. This significant level mismatch makes the task less suitable for the target learner, despite the good distractors.                                                                                                                                                                                             |
|          11 | Llama 4         | Fill Blank      |       6 |      0.93 | While the sentence is grammatically correct and level-appropriate, it is not deterministic. The blank for '____ (city)' could be correctly filled with '–≥–æ—Ä–æ–¥–µ' (in a city) or the name of a specific city in the prepositional case (e.g., '–ú–æ—Å–∫–≤–µ'). This ambiguity violates the instruction to have only one correct answer.                                                                                                                                                                                                       |
|          11 | Mistral Large 3 | Multiple Choice |       6 |      1.94 | The task tests relevant A1 vocabulary in a clear context (daily routines). However, it scores lower because it explicitly violates a key guideline by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ:') within the 'question' field, whereas the prompt strictly forbade including any instructions.                                                                                                                                                                                                                              |
|          11 | Mistral Large 3 | Fill Blank      |       4 |      1.56 | The task is not deterministic as instructed. The blank can be filled with any name, making it an open-ended question rather than a targeted language test. It fails the 'only one correct answer' guideline, as it doesn't test a specific vocabulary word or grammatical structure that has a unique solution.                                                                                                                                                                                                                       |
|          11 | Qwen 3 Max      | Multiple Choice |       9 |      3.2  | A very strong candidate. The task correctly tests adjective-noun agreement in the prepositional case, which is appropriate for a high A1 level and aligns well with the 'postcard' writing context. It follows all formatting and content guidelines precisely. The prompt sentence is slightly unnatural but grammatically defensible for a test item.                                                                                                                                                                               |
|          11 | Qwen 3 Max      | Fill Blank      |       2 |      2.23 | The task is fundamentally flawed due to a completely incorrect English hint. The blank requires the noun '–ø–∏—Å—å–º–æ' (letter), but the hint provided is '(to)', which is a preposition represented by the dative case on another word in the sentence. This makes the question nonsensical and unsolvable.                                                                                                                                                                                                                               |
|          12 | GPT-5.2         | Multiple Choice |      10 |     14.04 | This is an excellent task that perfectly adheres to all instructions. It correctly interprets the A1 proficiency level, focusing on vocabulary needed for filling in forms ('–∞–Ω–∫–µ—Ç–∞', '–≤–æ–∑—Ä–∞—Å—Ç'). The question is a single, clear sentence without instructions. The options are relevant and create a logical vocabulary puzzle appropriate for the level. The context is natural and the answer is unambiguous.                                                                                                                     |
|          12 | GPT-5.2         | Fill Blank      |       8 |      1.54 | The task is very good and directly relates to the A1 level description of writing a postcard. The phrase '–≤ –æ—Ç–ø—É—Å–∫–µ' is appropriate. However, it loses points because another answer, '–æ—Ç–¥—ã—Ö–∞—é' (I am relaxing/vacationing), would also be a natural and correct fit in this context, which slightly violates the guideline for the answer to be deterministic with only one correct option.                                                                                                                                          |
|          12 | Gemini 3 Flash  | Multiple Choice |       5 |      1.39 | The candidate violates the 'single sentence' rule by providing two sentences in the 'question' field. The context ('–ú–µ–Ω—è –∑–æ–≤—É—Ç –ò–≤–∞–Ω... –ö–∞–∫ ___ —Ñ–∞–º–∏–ª–∏—è?') is slightly unnatural, as one sentence doesn't logically connect to the next without more information. However, the task itself is a good A1-level question testing possessive pronouns and gender agreement, and the distractors are well-chosen.                                                                                                                          |
|          12 | Gemini 3 Flash  | Fill Blank      |       9 |      1.04 | A very strong and well-constructed task. It tests a core A1 introductory phrase ('–ú–µ–Ω—è –∑–æ–≤—É—Ç...'), is grammatically correct, and has only one possible answer, making it perfectly deterministic. It aligns well with the 'personal details' aspect of the A1 level. It is a simple, effective, and flawless execution of the prompt's requirements.                                                                                                                                                                                  |
|          12 | Llama 4         | Multiple Choice |       3 |      0.43 | This candidate completely disregards the 'single sentence' guideline (Guideline 1), providing a three-sentence paragraph as the question. The complexity of the context paragraph, including a relative clause ('–≥–¥–µ –µ—Å—Ç—å...'), is more appropriate for A2 than A1, potentially overwhelming the learner. While the specific grammar point (pronoun in the instrumental case) can be an A1 topic, the overall task complexity is far too high for the target level.                                                                   |
|          12 | Llama 4         | Fill Blank      |       1 |      0.9  | This candidate is fundamentally flawed and demonstrates a critical lack of knowledge of Russian grammar. In modern Russian, the present tense of the verb 'to be' is omitted in such sentences ('–Ø –∏–∑ –ú–æ—Å–∫–≤—ã'). The suggested answers, '–µ—Å–º—å' and '–µ—Å—Ç—å', are archaic or used in completely different contexts. This task would teach incorrect Russian and be actively harmful to a learner.                                                                                                                                         |
|          12 | Mistral Large 3 | Multiple Choice |       4 |      1.8  | This candidate fails on several key guidelines. The 'question' field violates the instructions by including an explicit question ('–ö–∞–∫–æ–π –ø—Ä–µ–¥–ª–æ–≥ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ?') instead of just the task sentence. This breaks Guideline 1 ('single sentence') and Guideline 9 ('Do not include any instructions'). While the grammar point (prepositions of motion) is A1, the format is incorrect.                                                                                                                              |
|          12 | Mistral Large 3 | Fill Blank      |       3 |      3.81 | While the sentence '–ú–µ–Ω—è –∑–æ–≤—É—Ç...' is fundamental for A1 level, this is not a good test item. The blank can be filled with any name, making the answer completely non-deterministic. It fails to test the learner's knowledge of a specific vocabulary word or grammar rule, which is the purpose of a fill-in-the-blank task. It violates guideline #7.                                                                                                                                                                              |
|          12 | Qwen 3 Max      | Multiple Choice |       7 |      3.52 | A good attempt that creates a task highly relevant to the 'writing a postcard/letter' part of the level description. The grammar point (nominative case after '–Ω—Ä–∞–≤–∏—Ç—Å—è') is appropriate for A1. However, it violates the 'single sentence' and 'no instructions' guidelines by including a long introductory clause ('–Ø –ø–∏—à—É –ø–∏—Å—å–º–æ –¥—Ä—É–≥—É –∏ —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å: ...') which functions as context-setting and instruction, making the question field unnecessarily complex.                                                                 |
|          12 | Qwen 3 Max      | Fill Blank      |      10 |      2.6  | This is an excellent task that perfectly adheres to all instructions. It directly references the 'postcard' context from the level description. It tests a key vocabulary word ('–æ—Ç–∫—Ä—ã—Ç–∫–∞') and a crucial A1/A2 grammar point (the accusative case '–æ—Ç–∫—Ä—ã—Ç–∫—É'). The answer is deterministic and unambiguous. This is a model example of a well-designed task for the specified level.                                                                                                                                                 |
|          13 | GPT-5.2         | Multiple Choice |       9 |     19.04 | The candidate produced a high-quality task that perfectly aligns with the A1 level and the specific writing context ('fill in forms'). The Russian sentence '–í –∞–Ω–∫–µ—Ç–µ —è –ø–∏—à—É: ¬´–ú–Ω–µ ___ –ª–µ—Ç¬ª' directly uses the context of a form ('–∞–Ω–∫–µ—Ç–µ'). The grammar point (nominative case for age) is fundamental for A1. The distractors are well-chosen case variations. The output follows all formatting and structural rules.                                                                                                              |
|          13 | GPT-5.2         | Fill Blank      |      10 |      1.62 | The task is perfectly suited for the A1 level, testing the essential verb '–∂–∏—Ç—å' (to live) in the first-person singular form ('–∂–∏–≤—É'). The sentence is natural, and the task is unambiguous, directly addressing the 'personal details' aspect of the proficiency description. It follows all instructions flawlessly.                                                                                                                                                                                                                |
|          13 | Gemini 3 Flash  | Multiple Choice |       7 |      1.34 | The task content is excellent for the A1 level, testing the crucial prepositional case for location ('–≤ –ú–æ—Å–∫–≤–µ'). It aligns well with the context of providing personal information. However, it violates guideline #1 ('The task must consist of a single sentence') by presenting the context in two separate sentences.                                                                                                                                                                                                            |
|          13 | Gemini 3 Flash  | Fill Blank      |      10 |      1.81 | The task tests the fundamental A1 introductory phrase '–ú–µ–Ω—è –∑–æ–≤—É—Ç' (My name is). This is one of the first and most important structures a learner encounters. The question is clear, deterministic, and directly relates to providing personal details, aligning perfectly with the level description and all instructions.                                                                                                                                                                                                           |
|          13 | Llama 4         | Multiple Choice |       7 |      1.9  | The task tests a relevant grammar point (instrumental case with '—Ä—è–¥–æ–º —Å') and the options are well-constructed. However, it violates guideline #1 ('The task must consist of a single sentence'), as the question contains two sentences. Additionally, the complexity of the sentence structure and the grammar point is at the higher end of the A1 level, bordering on A2.                                                                                                                                                        |
|          13 | Llama 4         | Fill Blank      |       6 |      1.36 | While the sentence is grammatically correct and the JSON format is valid, the choice of the missing word '—Ä–æ–¥–æ–º' (originally from) is questionable for the A1 level. The standard A1 construction is simply '–Ø –∏–∑ –ú–æ—Å–∫–≤—ã.' The word '—Ä–æ–¥–æ–º' introduces a nuance that is typically taught at the A2 level. The task is therefore slightly too advanced and not focused on the most foundational vocabulary for A1.                                                                                                                     |
|          13 | Mistral Large 3 | Multiple Choice |       6 |      2.05 | While the linguistic content of the task (verb conjugation) is appropriate for A1, the candidate failed to follow a strict negative constraint. The question includes the instruction '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ:' which was explicitly forbidden by guideline #9 ('Do not include any instructions for the task'). This is a significant deviation from the prompt.                                                                                                                                                                  |
|          13 | Mistral Large 3 | Fill Blank      |       2 |      1.33 | The candidate fails on multiple critical points. The proposed sentence '–ú–µ–Ω—è –∑–æ–≤—É—Ç –ê–Ω–Ω–∞ –ò–≤–∞–Ω–æ–≤' is grammatically incorrect, as it pairs a feminine first name with a masculine surname. Furthermore, the task is not deterministic as instructed; any masculine name could fit the blank, making it a prompt for information rather than a test of a specific word or grammatical form. It fundamentally misunderstands the nature of a fill-in-the-blank language test.                                                              |
|          13 | Qwen 3 Max      | Multiple Choice |       9 |      3.28 | This is an excellent, standard A1 task that follows all instructions perfectly. It tests a core A1 grammar point (verb conjugation for 'to live') within a relevant context (stating personal information). The sentence is simple, clear, and the options are appropriate. It fully complies with the structural and content requirements of the prompt.                                                                                                                                                                             |
|          13 | Qwen 3 Max      | Fill Blank      |      10 |      2.97 | This is an outstanding task. It directly and cleverly incorporates the A1 proficiency description ('write a ... postcard') into the question. It tests both a key vocabulary word ('–æ—Ç–∫—Ä—ã—Ç–∫–∞') and a fundamental A1 grammar concept ‚Äì the accusative case for inanimate feminine nouns. The task is relevant, unambiguous, and perfectly pitched for the level.                                                                                                                                                                       |
|          14 | GPT-5.2         | Multiple Choice |       0 |     35.87 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          14 | GPT-5.2         | Fill Blank      |      10 |      1.57 | The candidate provides a high-quality task that perfectly aligns with the A1 level and the postcard-writing context mentioned in the instructions. The JSON format is correct, and the task tests a fundamental verb conjugation ('–ø–∏—à—É'), which is a key A1 skill. The answer is unambiguous and the sentence is natural.                                                                                                                                                                                                            |
|          14 | Gemini 3 Flash  | Multiple Choice |       0 |      1.06 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          14 | Gemini 3 Flash  | Fill Blank      |      10 |      1.25 | An excellent submission that correctly follows all guidelines. The task tests the crucial A1 introductory phrase '–ú–µ–Ω—è –∑–æ–≤—É—Ç...' (My name is...). The format is valid, the question is clear, and the answer ('–∑–æ–≤—É—Ç') is unambiguous. It directly relates to the 'fill in forms with personal details' aspect of the A1 level description, making it highly relevant and effective.                                                                                                                                                  |
|          14 | Llama 4         | Multiple Choice |       0 |      0.87 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          14 | Llama 4         | Fill Blank      |       4 |      0.52 | This candidate's output has several significant flaws. It fails to include the mandatory English translation of the missing word in the 'question' string. The JSON format is incorrect, as 'correctAnswer' is a string instead of the required array. Critically, the task is ambiguous; while '–µ–¥—É' (I go by vehicle) is a correct answer, '–ª–µ—á—É' (I fly) is also a valid alternative, violating the instruction for a deterministic answer.                                                                                        |
|          14 | Mistral Large 3 | Multiple Choice |       0 |      1.91 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          14 | Mistral Large 3 | Fill Blank      |       3 |      1.99 | The candidate fails to follow several key instructions. The JSON format is incorrect due to an extra 'translation' field. More importantly, it misinterprets the nature of a fill-in-the-blank task by providing a blank for a proper noun ('name'), leading to an infinite number of possible answers. This violates the 'only one correct answer' guideline and creates a personalization prompt rather than a deterministic linguistic test.                                                                                       |
|          14 | Qwen 3 Max      | Multiple Choice |       0 |      3.84 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          14 | Qwen 3 Max      | Fill Blank      |      10 |      2.66 | This is an outstanding response that perfectly adheres to all instructions. The task is excellently designed for the A1 level, as it cleverly tests both a key vocabulary word ('–æ—Ç–∫—Ä—ã—Ç–∫–∞' - postcard) from the provided context and a fundamental grammatical concept (the accusative case, '–æ—Ç–∫—Ä—ã—Ç–∫—É'). The JSON is valid, and the answer is unambiguous.                                                                                                                                                                           |
|          15 | GPT-5.2         | Multiple Choice |       0 |     15.19 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          15 | GPT-5.2         | Fill Blank      |       3 |      1.77 | The task is fundamentally flawed. The provided sentence is '–Ø ____ –≤ –°–æ—á–∏...' (I ____ in Sochi...). The correct answer is given as '—è' (I), which would result in the grammatically incorrect sentence '–Ø —è –≤ –°–æ—á–∏...'. The task is unsolvable as presented, demonstrating a poor understanding of basic Russian grammar. While the context (postcard) is appropriate for A1, the execution is incorrect.                                                                                                                             |
|          15 | Gemini 3 Flash  | Multiple Choice |       0 |      1.53 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          15 | Gemini 3 Flash  | Fill Blank      |      10 |      1.11 | This is a perfect execution of the instructions. The task '–ú–µ–Ω—è ____ –ò–≤–∞–Ω' (My name is Ivan) tests one of the most fundamental phrases for an A1 learner. The answer '–∑–æ–≤—É—Ç' is unambiguous and deterministic, with no other common words fitting the context. The task is highly relevant, accurate, and perfectly calibrated to the specified proficiency level.                                                                                                                                                                    |
|          15 | Llama 4         | Multiple Choice |       0 |      1.42 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          15 | Llama 4         | Fill Blank      |       2 |      0.56 | This candidate's output contains a major grammatical error. It provides two 'correct' answers, '–∂–∏–≤—É' and '—Ä–æ–¥–æ–º', for the sentence '—è ____ –∏–∑ –ú–æ—Å–∫–≤—ã'. The phrase '—è –∂–∏–≤—É –∏–∑ –ú–æ—Å–∫–≤—ã' is grammatically incorrect. '–ñ–∏–≤—É' (I live) requires '–≤', not '–∏–∑'. This indicates a failure to understand Russian prepositions and cases. Furthermore, '—Ä–æ–¥–æ–º' is arguably an A2-level word, making the task's difficulty questionable for A1.                                                                                                 |
|          15 | Mistral Large 3 | Multiple Choice |       0 |      1.98 | Judge failed                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|          15 | Mistral Large 3 | Fill Blank      |       8 |      1.54 | This is a good task testing a key A1 grammar point (prepositional case). The sentence '–Ø –∂–∏–≤—É –≤ ____ (city)' is grammatically correct with the answer '–≥–æ—Ä–æ–¥–µ'. However, the phrasing 'I live in a city' is slightly unnatural for an introduction. A better task design would provide the nominative case to be conjugated (e.g., '...–≤ ____ (–≥–æ—Ä–æ–¥)') to make the grammar objective clearer and less ambiguous.                                                                                                                     |
|          15 | Qwen 3 Max      | Multiple Choice |       0 |      0    | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|          15 | Qwen 3 Max      | Fill Blank      |       9 |      3.2  | Excellent candidate. The task directly uses the 'postcard' theme from the proficiency description, testing relevant vocabulary ('–æ—Ç–∫—Ä—ã—Ç–∫–∞') and a core grammatical concept (accusative case). The sentence is natural and perfectly suited for the A1 level. The only minor weakness is that another word, '–ø–∏—Å—å–º–æ' (letter), could also fit the blank, slightly violating the 'only one correct answer' rule, though the hint strongly guides the user.                                                                              |

### üåê Language: RUSSIAN | Level: B2
|   iteration | model           | task_type       |   score |   latency | reason                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|------------:|:----------------|:----------------|--------:|----------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|           1 | GPT-5.2         | Multiple Choice |       7 |     11.51 | The task is good and appropriate for the B2 level, testing logical conjunctions in a complex sentence. However, it violates a guideline by translating the options into English within the options list. The original instruction was 'translate the necessary parts to English', which is ambiguous, but this implementation is clunky. The JSON format for `correctAnswer` is a string, not an array as specified in the instructions' example.                                                                                                                            |
|           1 | GPT-5.2         | Fill Blank      |       8 |      1.34 | The task is highly relevant to the B2 level, using a complex sentence structure within a context ('report') that directly matches the proficiency description. However, it fails on the 'only one correct answer' rule. The conjunction '–ø–æ –∫–æ—Ç–æ—Ä—ã–º' is an equally valid and common alternative to '–ø–æ—á–µ–º—É' in this context, but it was not included in the 'correctAnswer' array.                                                                                                                                                                                           |
|           1 | Gemini 3 Flash  | Multiple Choice |       9 |      1.97 | This is a high-quality task that tests sophisticated B2/C1 skills: collocations and the use of adverbial participles in a formal context. The distractors are cleverly designed by mixing parts of correct collocations. It perfectly aligns with the 'writing a report' skill. A point is deducted for not following the specified format for `correctAnswer` (it's a string instead of an array).                                                                                                                                                                          |
|           1 | Gemini 3 Flash  | Fill Blank      |       8 |      1.54 | The task uses advanced vocabulary ('–≤—ã—Å–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –≤ –ø–æ–ª—å–∑—É', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∏—Å–∫–∏') and a grammatical structure ('–Ω–µ–≤–∑–∏—Ä–∞—è –Ω–∞') that are very appropriate for the B2/C1 level. The context is also excellent. However, it violates the determinism rule by providing only '–Ω–µ–≤–∑–∏—Ä–∞—è' as the correct answer, when '–Ω–µ—Å–º–æ—Ç—Ä—è' is an equally correct and even more common synonym that should have been included.                                                                                                                                                                  |
|           1 | Llama 4         | Multiple Choice |      10 |      1.97 | An excellent submission that perfectly adheres to all instructions. The task tests the passive voice combined with verbal aspect, a complex grammar point entirely appropriate for the B2 level. The context is clear, the distractors are plausible grammatical alternatives, and the JSON format is exactly as requested, including the `correctAnswer` as an array.                                                                                                                                                                                                       |
|           1 | Llama 4         | Fill Blank      |      10 |      1.76 | This is an excellent B2-level task. It correctly tests a specific and challenging grammatical construction ('–Ω–∞—Ö–æ–¥–∏—Ç—å —á—Ç–æ-—Ç–æ + instrumental case') that distinguishes intermediate from upper-intermediate learners. The sentence is natural, the answer is unique and unambiguous, and the context of expressing an opinion aligns well with B2 skills. It perfectly follows all instructions.                                                                                                                                                                              |
|           1 | Mistral Large 3 | Multiple Choice |       4 |      2.63 | This candidate fails on a key instruction by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') inside the 'question' field, which was explicitly forbidden. Furthermore, the task itself, while testing verbs of motion, is more suited for a B1 level rather than B2. A B2 learner should find this task relatively simple.                                                                                                                                                                                                                                         |
|           1 | Mistral Large 3 | Fill Blank      |       7 |      1.51 | The task is grammatically correct and the JSON format is valid. The use of '–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞...' and testing verb aspect ('–ø–æ–π—Ç–∏') is appropriate. However, the core grammatical point (choosing a perfective infinitive after '—Ä–µ—à–∏–ª–∏') is typically mastered at the B1 level. The task lacks the complexity expected for a solid B2 assessment.                                                                                                                                                                                                                                 |
|           1 | Qwen 3 Max      | Multiple Choice |       6 |      4.74 | The task concept, testing nuanced vocabulary (paronyms), is excellent for the B2 level. However, the execution is flawed because one of the distractors, '–ø–æ—Å–µ–ª–æ–≤–∞—Ç—å—Å—è', is a non-existent word. A well-designed task should use plausible but incorrect distractors, not invented words, which makes the choice artificially easy for the learner.                                                                                                                                                                                                                          |
|           1 | Qwen 3 Max      | Fill Blank      |       3 |      3.39 | The task attempts to use a B2-level context (writing a letter) and structure ('—á—Ç–æ–±—ã' + infinitive), but contains a significant grammatical error. The verb '–æ–±—ä—è—Å–Ω–∏—Ç—å' does not collocate with the preposition '–æ' ('about'). The correct structure would be '–æ–±—ä—è—Å–Ω–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å' (accusative). This fundamental error makes the task unsuitable for language learning.                                                                                                                                                                                                     |
|           2 | GPT-5.2         | Multiple Choice |       9 |     12.89 | A very good task that correctly follows all instructions. It tests a B2-level grammar point (dative case governed by the preposition '–±–ª–∞–≥–æ–¥–∞—Ä—è' and adjective agreement) within a relevant context (work/conference). The distractors are well-chosen, especially '–∏—Å–∫—Ä–µ–Ω–Ω–æ–π', which tests a finer orthographic point.                                                                                                                                                                                                                                                      |
|           2 | GPT-5.2         | Fill Blank      |       9 |      1.84 | The task is excellent and well-aligned with the B2 level, testing complex sentence structure and formal vocabulary ('–≤ –æ—Ç—á—ë—Ç–µ', '–∏–∑–ª–æ–∂–∏–ª –ø—Ä–∏—á–∏–Ω—ã'). The JSON is valid. It's scored slightly below perfect because another answer, '–ø–æ –∫–æ—Ç–æ—Ä—ã–º', is also grammatically correct and natural in this context, which slightly undermines the 'only one correct answer' guideline. However, '–ø–æ—á–µ–º—É' is the most direct translation of the English cue '(why)'.                                                                                                                   |
|           2 | Gemini 3 Flash  | Multiple Choice |      10 |      1.43 | This is an outstanding vocabulary task that fits the B2/C1 borderline. The sentence structure is complex and the context (writing a formal report) directly relates to the CEFR description for B2 writing. It tests knowledge of formal vocabulary and collocations ('–∏–∑–ª–∞–≥–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã') by providing semantically related but contextually incorrect distractors. It fully adheres to all instructions.                                                                                                                                                                  |
|           2 | Gemini 3 Flash  | Fill Blank      |      10 |      1.19 | This is an outstanding task that perfectly meets all requirements. The JSON is valid. The sentence uses advanced, formal vocabulary ('–º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏,' '–ø—Ä–∏–π—Ç–∏ –∫ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å—É,' '–¥–æ—Å—Ç–∏—á—å —Ä–µ—à–µ–Ω–∏—è') and a complex structure, making it ideal for the B2 level. The context aligns perfectly with the proficiency description of analyzing and reporting on events. The answer is unambiguous and the most appropriate choice.                                                                                                                                            |
|           2 | Llama 4         | Multiple Choice |       9 |      1.03 | A solid task that tests the aspectual pair '–Ω–∞—á–∞–ª'/'–Ω–∞—á–∏–Ω–∞–ª', which is a common point of difficulty for B1/B2 learners. The context is appropriate and the sentence is natural. It follows all instructions correctly. The task is slightly less complex in sentence structure compared to other high-scoring candidates but is still a very effective B2-level question.                                                                                                                                                                                                    |
|           2 | Llama 4         | Fill Blank      |       7 |      2.09 | The task is well-formed with valid JSON and a grammatically correct sentence. It correctly tests the use of the imperfective infinitive after the verb '–Ω–∞—á–∞—Ç—å'. However, the level feels closer to B1 than a solid B2. While it involves a complex sentence, the context and vocabulary are quite general and don't fully capture the B2 proficiency of writing essays or reports on a wide range of subjects.                                                                                                                                                              |
|           2 | Mistral Large 3 | Multiple Choice |       6 |      2.37 | The linguistic task itself, testing verb aspect and verbs of motion, is appropriate for the B1/B2 level. However, the candidate failed to follow a strict guideline: 'Do not include any instructions for the task'. The question begins with '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:', which is an explicit instruction.                                                                                                                                                                                                                                 |
|           2 | Mistral Large 3 | Fill Blank      |       8 |      1.6  | The task is grammatically correct and the JSON format is valid. The use of '–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞...' and testing verb aspect after '—Ä–µ—à–∏—Ç—å' is appropriate for an intermediate level. However, the overall complexity and vocabulary feel more aligned with a B1 level rather than the specified B2 level, which emphasizes writing reports and complex arguments.                                                                                                                                                                                                                    |
|           2 | Qwen 3 Max      | Multiple Choice |      10 |      4.77 | An excellent task that perfectly meets all requirements. It tests a crucial B2 skill: the use of verb aspect and tense in complex sentences with subordinate clauses. The context is natural and aligns with the level description. The distinction between '—Ä–µ—à–∏–ª' (perfective) and '—Ä–µ—à–∞–ª' (imperfective) is a key challenge at this level.                                                                                                                                                                                                                                |
|           2 | Qwen 3 Max      | Fill Blank      |       5 |      3.09 | The task fails on two key points. Firstly, the grammatical point tested (simple past tense with aspect) is more suitable for an A2/B1 level, not B2. Secondly, the correct answer is ambiguous regarding gender ('–ø—Ä–æ—á–∏—Ç–∞–ª' for masculine, '–ø—Ä–æ—á–∏—Ç–∞–ª–∞' for feminine), but only one form is provided, violating the guideline for a deterministic answer.                                                                                                                                                                                                                     |
|           3 | GPT-5.2         | Multiple Choice |       9 |     19.48 | This is a very good B2-level task. It correctly tests the agreement of a past passive participle with the noun it modifies in the accusative case, a key grammatical skill at this level. The sentence context (grant application) is appropriate. The options are well-constructed, representing different case endings of the same word. It follows all instructions, including the JSON format and the no-instructions rule.                                                                                                                                              |
|           3 | GPT-5.2         | Fill Blank      |       8 |      1.93 | The task is well-constructed and targets an appropriate B2/C1 level. The vocabulary ('–æ—Ç—á—ë—Ç', '–ø—Ä–∏–π—Ç–∏ –∫ –≤—ã–≤–æ–¥—É', '—É–ª–æ–∂–∏—Ç—å—Å—è –≤ —Å—Ä–æ–∫–∏') and the complex sentence structure are fitting. The context of a report aligns with the B2 writing description. The only minor drawback is that while '–ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å' is the best fit, another verb like '–¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å' (to refine) could also be considered a possible answer, slightly violating the 'only one correct answer' rule.                                                                                                    |
|           3 | Gemini 3 Flash  | Multiple Choice |       5 |    332.3  | The task targets an advanced distinction between near-synonyms ('–Ω–µ–≤–∑–∏—Ä–∞—è' vs. '–Ω–µ—Å–º–æ—Ç—Ä—è'), which is appropriate for B2/C1. However, the task is critically flawed because both '–Ω–µ–≤–∑–∏—Ä–∞—è' and '–Ω–µ—Å–º–æ—Ç—Ä—è' are grammatically correct and widely accepted in this context. This violates the core requirement for a single, deterministic correct answer, making it a poor multiple-choice question.                                                                                                                                                                           |
|           3 | Gemini 3 Flash  | Fill Blank      |       9 |      1.11 | This is an excellent task that perfectly meets the B2 level requirements. The vocabulary ('–ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã', '—Ç–æ—á–∫–∞ –∑—Ä–µ–Ω–∏—è', '–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å') is advanced and appropriate. The context of justifying a point of view directly aligns with the B2 writing skill description. The chosen word '–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å' is the most precise and direct translation for '(to justify)' in this context, making it a strong, single-best answer, even if other synonyms could technically fit.                                                                                             |
|           3 | Llama 4         | Multiple Choice |       7 |      0.6  | The task addresses a relevant B2 grammar point (tense and voice of verbs in a subordinate clause). However, the sentence is excessively long and complex, which can obscure the core objective. More importantly, the choice between the correct answer ('–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è' - are used) and the distractor ('–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å' - were used) is slightly ambiguous, potentially violating the guideline that the answer must be deterministic.                                                                                                                                      |
|           3 | Llama 4         | Fill Blank      |       6 |      0.54 | The task is grammatically sound and correctly formatted. However, it tests the use of multidirectional verbs of motion ('—Ö–æ–∂—É') with an adverb of frequency ('—á–∞—Å—Ç–æ'). This is a standard topic for A2/B1 levels and is not sufficiently challenging for a B2 learner. The context is simple and does not align with the advanced writing skills described for the level.                                                                                                                                                                                                    |
|           3 | Mistral Large 3 | Multiple Choice |       6 |      2.77 | The task itself, testing the conditional mood ('–µ—Å–ª–∏ –±—ã...'), is excellent and perfectly suited for the B2 level. However, the candidate failed to follow a strict guideline by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:') within the 'question' field. The prompt explicitly forbids including any instructions for the task.                                                                                                                                                                                                     |
|           3 | Mistral Large 3 | Fill Blank      |       6 |      2.8  | The task is grammatically correct and the JSON format is valid. However, it tests the choice of a perfective verb of motion ('–ø–æ–π—Ç–∏'), which is a core concept typically mastered at the B1 level. The task does not adequately challenge a B2 learner or reflect the complexity described in the proficiency level (e.g., writing reports, essays).                                                                                                                                                                                                                         |
|           3 | Qwen 3 Max      | Multiple Choice |      10 |      4.12 | An excellent task that perfectly matches the B2 level and all instructions. It tests vocabulary nuance and collocation ('–ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏' - to overcome difficulties), which is a key skill for advanced learners. The sentence structure is complex enough for B2, the context is natural, and the distractors are plausible but incorrect synonyms. It's a well-designed, deterministic question.                                                                                                                                                                     |
|           3 | Qwen 3 Max      | Fill Blank      |       3 |      3.67 | The task is fundamentally flawed as the blank is placed incorrectly and the word intended for the blank ('–≥–æ—Ç–æ–≤–∏–ª—Å—è') is already present in the question sentence. Even if this were corrected, the grammatical point being tested (imperfective aspect for duration with '–≤–µ—Å—å –¥–µ–Ω—å') is a B1-level concept, not B2.                                                                                                                                                                                                                                                        |
|           4 | GPT-5.2         | Multiple Choice |       5 |     27.54 | The task tests an appropriate B2-level skill (connectors). However, it critically fails by including an English translation of the correct answer within the question ('(EN: nevertheless)'), which trivializes the task and violates guideline #7. The JSON format for 'correctAnswer' also deviates slightly from the example (string instead of array).                                                                                                                                                                                                                   |
|           4 | GPT-5.2         | Fill Blank      |       8 |      1.46 | The task is highly relevant to the B2 level, using vocabulary ('–æ—Ç—á—ë—Ç', '–∞—Ä–≥—É–º–µ–Ω—Ç—ã') and a structure ('–≤ –ø–æ–ª—å–∑—É') appropriate for writing reports, as mentioned in the level description. The format is correct. However, it violates the 'only one correct answer' guideline, as '–∑–∞' would also be a grammatically correct and natural answer. The task is good but not perfectly deterministic.                                                                                                                                                                           |
|           4 | Gemini 3 Flash  | Multiple Choice |       7 |      1.73 | The task's concept is excellent and directly targets the B2 writing description by focusing on argumentative linkers in an essay context. However, it violates guideline #9 by including instructions in the 'question' field. The distinction between '—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ' and '–≤–ø—Ä–æ—á–µ–º', while testing a good nuance, could be considered slightly ambiguous in some contexts.                                                                                                                                                                                                   |
|           4 | Gemini 3 Flash  | Fill Blank      |      10 |      8.72 | This is an excellent response that perfectly adheres to all instructions. The JSON is valid. The task is unambiguously at the B2 level, testing the crucial conjunction '–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞' within a formal, argumentative context ('—ç–∫—Å–ø–µ—Ä—Ç—ã –≤—ã—Å–∫–∞–∑—ã–≤–∞—é—Ç—Å—è', '—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ä–∏—Å–∫–∏'). The answer is unique and deterministic, making it a high-quality assessment item.                                                                                                                                                                                                               |
|           4 | Llama 4         | Multiple Choice |      10 |      1.47 | This candidate is flawless. It perfectly adheres to all instructions, including the JSON structure and the array format for 'correctAnswer'. The task itself is an excellent B2-level vocabulary question testing collocation ('–ø–æ—Å–≤—è—Ç–∏—Ç—å –∫–∞—Ä—å–µ—Ä—É') in a natural and relevant context, with clear, unambiguous options.                                                                                                                                                                                                                                                      |
|           4 | Llama 4         | Fill Blank      |       1 |      1.21 | This candidate fails on multiple critical points. The JSON format is incorrect, nesting the response within an unnecessary structure. The task level is A1, which is far below the requested B2. Most importantly, it fundamentally violates the instruction to create a task with a single, deterministic answer by providing a question with dozens of possible correct answers.                                                                                                                                                                                           |
|           4 | Mistral Large 3 | Multiple Choice |       6 |      2.53 | This is a solid B2 grammar task testing the conditional mood, with well-chosen distractors. Its main weakness is the direct violation of guideline #9, as it includes explicit instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') within the 'question' field, which was strictly forbidden.                                                                                                                                                                                                                                                                                    |
|           4 | Mistral Large 3 | Fill Blank      |       6 |      2.69 | The output is a valid JSON and the sentence is grammatically correct. However, the task itself is more suitable for a B1 level. Choosing the correct infinitive of a verb of motion after '—Ä–µ—à–∏–ª–∏' is a skill typically mastered before B2. The task does not adequately challenge a B2 learner's ability to handle complex syntax or vocabulary as described in the prompt.                                                                                                                                                                                                 |
|           4 | Qwen 3 Max      | Multiple Choice |       9 |      4.21 | An excellent and precise task for the B2 level, effectively testing the choice of verb aspect within a complex clause. The question is clean, natural, and unambiguous. It adheres to almost all instructions, with the only minor flaw being the format of 'correctAnswer' as a string instead of a single-element array.                                                                                                                                                                                                                                                   |
|           4 | Qwen 3 Max      | Fill Blank      |       5 |      3.21 | The candidate followed the JSON format instruction, and the sentence is grammatically sound. The main issue is the difficulty level. The task, which tests a basic perfective past tense verb, is appropriate for an A2 or low B1 learner, not B2. It does not reflect the required proficiency in writing complex texts or arguments.                                                                                                                                                                                                                                       |
|           5 | GPT-5.2         | Multiple Choice |       8 |      9.79 | The task is good and tests a relevant B2 grammar point (use of infinitive after '–≤–∞–∂–Ω–æ'). The context of a project report aligns with the proficiency description. However, the grammatical point is somewhat basic for B2, and the JSON format for 'correctAnswer' should have been an array, not a string, as per the instructions.                                                                                                                                                                                                                                        |
|           5 | GPT-5.2         | Fill Blank      |       9 |      2    | This is a strong candidate. The task aligns well with the B2 level, using relevant vocabulary ('–æ—Ç—á—ë—Ç', '–∑–∞–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞') and a context (writing a report) that matches the proficiency description. The grammar tested (perfective aspect in a sequence of past actions) is appropriate. The answer is correct and the most likely choice.                                                                                                                                                                                                                                |
|           5 | Gemini 3 Flash  | Multiple Choice |      10 |      1.44 | This is an outstanding task that perfectly meets the user's requirements. The context of writing a formal report directly reflects the B2 proficiency description. The task tests a sophisticated and context-dependent vocabulary item ('–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –Ω–∞' meaning 'to dwell on'), which is an excellent indicator of B2/C1 proficiency. The sentence structure is complex and natural. Despite a minor format deviation ('correctAnswer' as a string), the overall high quality and relevance of the linguistic challenge make this the best candidate.                     |
|           5 | Gemini 3 Flash  | Fill Blank      |      10 |      1.27 | This is an outstanding task for the B2 level. It tests the use of a complex preposition ('–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞') to express concession, which is a key skill for constructing nuanced arguments. The vocabulary is formal and appropriate for the level. The answer is correct, deterministic, and the sentence structure is suitably complex.                                                                                                                                                                                                                                        |
|           5 | Llama 4         | Multiple Choice |       8 |      0.6  | The candidate created a strong B2-level task testing the subtle difference between perfective and imperfective aspects ('–∂–∏–ª–∞' vs. '–ø—Ä–æ–∂–∏–ª–∞'). It also correctly followed the JSON formatting instruction for 'correctAnswer' by using an array. However, the question contains a grammatical error ('–æ –∏—Å—Ç–æ—Ä–∏–∏' instead of '–æ–± –∏—Å—Ç–æ—Ä–∏–∏'), which is a significant flaw in a language task.                                                                                                                                                                                   |
|           5 | Llama 4         | Fill Blank      |       4 |      1.36 | This candidate has two significant issues. First, the difficulty is more suited for an A2/B1 level than B2. Second, it fails on the 'deterministic' instruction. The correct answer could be '–Ω–∞—á–∞–ª' (masculine) or '–Ω–∞—á–∞–ª–∞' (feminine), but the candidate only provided the feminine form, making the answer incomplete and assuming the speaker's gender.                                                                                                                                                                                                                  |
|           5 | Mistral Large 3 | Multiple Choice |       7 |      2.6  | The linguistic task itself is excellent, testing the subjunctive mood ('–µ—Å–ª–∏ –±—ã... —è –±—ã...') which is a perfect B2-level challenge. However, the candidate failed to follow a strict negative constraint by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') in the 'question' field, which was explicitly forbidden.                                                                                                                                                                                                                                               |
|           5 | Mistral Large 3 | Fill Blank      |       5 |      1.65 | The task is grammatically correct and the format is valid. However, the difficulty level is too low for B2. Testing a verb of motion after '—Ä–µ—à–∏—Ç—å' (to decide) is a concept typically mastered at the A2 or B1 level. It does not challenge a B2 learner sufficiently.                                                                                                                                                                                                                                                                                                      |
|           5 | Qwen 3 Max      | Multiple Choice |       9 |      4.01 | This is an excellent task. The complex sentence structure and the specific grammatical point (requiring a perfective infinitive after '—É–¥–∞–ª–æ—Å—å') are perfectly suited for the B2 level. The context aligns well with the prompt's guidelines. The only minor flaw is that the 'correctAnswer' was provided as a string instead of an array.                                                                                                                                                                                                                                  |
|           5 | Qwen 3 Max      | Fill Blank      |      10 |      4.04 | An excellent task that perfectly meets all requirements. The context of writing an essay and presenting arguments ('—ç—Å—Å–µ', '–∞—Ä–≥—É–º–µ–Ω—Ç—ã') directly reflects the B2 writing skills described in the original instruction. The vocabulary is appropriate, and the answer is the most fitting word for the sentence, making the task both relevant and deterministic.                                                                                                                                                                                                             |
|           6 | GPT-5.2         | Multiple Choice |       8 |     13.3  | The linguistic task is excellent and appropriate for the B2 level, testing verb aspect in a clause of purpose with advanced vocabulary. However, the output violates the specified JSON format by adding an unrequested 'english' field. The 'correctAnswer' is a string, which is a possible but less safe interpretation of the ambiguous instruction.                                                                                                                                                                                                                     |
|           6 | GPT-5.2         | Fill Blank      |       8 |      1.79 | The task is well-aligned with the B2 level, using relevant professional vocabulary ('–æ—Ç—á—ë—Ç', '–ø—Ä–æ–µ–∫—Ç') and context (writing a report) that matches the proficiency description. The grammar is correct. However, the instruction to have only one correct answer is not strictly met. While '–ø–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏–ª' is a good fit, a simpler '–æ–±—ä—è—Å–Ω–∏–ª' or other verbs like '–∏–∑–ª–æ–∂–∏–ª' or '–æ–ø–∏—Å–∞–ª' would also be grammatically correct and contextually appropriate, making the answer not entirely deterministic.                                                                |
|           6 | Gemini 3 Flash  | Multiple Choice |      10 |      1.32 | An exemplary task that perfectly aligns with the B2 level proficiency description. It tests knowledge of formal register and collocations ('–∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –ø–æ–ª—å–∑—É') directly relevant to writing reports and essays. The vocabulary, context, and distractors are all highly appropriate. It follows all instructions, with the only minor issue being the ambiguous 'correctAnswer' format.                                                                                                                                                                                    |
|           6 | Gemini 3 Flash  | Fill Blank      |       7 |      1.45 | The linguistic quality of this task is very high. It uses a complex sentence structure and advanced vocabulary ('–∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç', '–≤—ã—Å—Ç—É–ø–∞–ª–∏ –ø—Ä–æ—Ç–∏–≤') suitable for a B2 or even C1 level. However, it fails significantly on the 'only one correct answer' constraint. Both '–ø—Ä–∏–Ω—è—Ç—å' and '—É—Ç–≤–µ—Ä–¥–∏—Ç—å' are very strong and common alternatives to '–æ–¥–æ–±—Ä–∏—Ç—å' in the context of passing a bill, making the provided answer one of several possibilities.                                                                                                                         |
|           6 | Llama 4         | Multiple Choice |       7 |      1.64 | The task is grammatically correct and follows all formatting instructions, including the use of an array for 'correctAnswer'. However, the linguistic point being tested (imperfective infinitive after '–ª—é–±–∏—Ç—å') is more characteristic of a B1 level, making the task slightly too easy for a B2 assessment.                                                                                                                                                                                                                                                               |
|           6 | Llama 4         | Fill Blank      |       5 |      0.35 | The task attempts a B2-level professional context, but the sentence '–í –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —è ... –∫–∞–∂–¥—ã–π –∫–≤–∞—Ä—Ç–∞–ª' is slightly awkward due to the conflicting time markers ('lately' and 'every quarter'). The primary issue is the non-uniqueness of the answer. '–†–∞–±–æ—Ç–∞—é –Ω–∞–¥' is a direct synonym and equally correct alternative to '–∑–∞–Ω–∏–º–∞—é—Å—å', which is a clear violation of a key guideline.                                                                                                                                                                                 |
|           6 | Mistral Large 3 | Multiple Choice |       4 |      2.88 | The task is well below the target B2 level, testing a basic tense choice that would be more appropriate for A2/B1 learners. It also violates a strict guideline by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') directly in the 'question' field.                                                                                                                                                                                                                                                                                                               |
|           6 | Mistral Large 3 | Fill Blank      |       6 |      1.54 | This task tests the choice of verb aspect after '—Ä–µ—à–∏—Ç—å', which is a core grammar point, but it's more characteristic of the B1 level. The context is a simple daily routine, which doesn't fully reflect the complexity expected at B2 (writing reports, essays). Most importantly, the answer is not unique; '–æ—Ç–ø—Ä–∞–≤–∏—Ç—å—Å—è' is a very common and perfectly valid alternative to '–ø–æ–π—Ç–∏', which violates a strict guideline.                                                                                                                                                 |
|           6 | Qwen 3 Max      | Multiple Choice |      10 |      5.86 | This is an excellent B2-level task. It tests knowledge of sophisticated vocabulary and collocation ('–ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏') within a grammatically complex sentence. The context is appropriate, the options are well-chosen, and it adheres to all guidelines, with the minor exception of using a string for 'correctAnswer' based on an ambiguous instruction.                                                                                                                                                                                                            |
|           6 | Qwen 3 Max      | Fill Blank      |      10 |      3.02 | This is an excellent task that perfectly meets all the requirements. The context ('–Ω–∞–ø–∏—Å–∞–ª –ø–∏—Å—å–º–æ –¥—Ä—É–≥—É, —á—Ç–æ–±—ã ... –≤–∞–∂–Ω–æ—Å—Ç—å') directly reflects the B2 skill description ('write letters highlighting the personal significance'). The vocabulary ('–ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å') is appropriate for the level, and the phrase is a strong collocation, making '–ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å' the most natural and expected answer, thus closely adhering to the 'only one correct answer' rule. The format and accuracy are flawless.                                                               |
|           7 | GPT-5.2         | Multiple Choice |       8 |     20.63 | A very good task that correctly tests the use of concessive prepositions ('–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞'), which is appropriate for the B2 level. The vocabulary and context (business trip, report deadline) are well-suited for B2. The options are distinct and test a clear grammatical point. The only minor issue is the 'correctAnswer' format, which the prompt ambiguously suggested should be an array.                                                                                                                                                                             |
|           7 | GPT-5.2         | Fill Blank      |       8 |      1.89 | Good B2-level vocabulary and context (writing a report), aligning with the prompt's description. However, the answer is not strictly deterministic as '–æ–ø–∏—Å–∞–ª' (described) could also fit, and the verb form '–∏–∑–ª–æ–∂–∏–ª' is gender-specific, whereas '–∏–∑–ª–æ–∂–∏–ª–∞' is also correct for a female speaker, violating the 'only one correct answer' rule.                                                                                                                                                                                                                            |
|           7 | Gemini 3 Flash  | Multiple Choice |      10 |      1.26 | This is an outstanding task that perfectly aligns with the B2 level, bordering on C1. It uses a complex sentence structure with advanced vocabulary and tests a nuanced point of verb government (collocation with a specific preposition and case). This requires a sophisticated understanding of Russian syntax and lexis, directly contributing to the ability to write clear, detailed, and accurate text, as described for the B2 level.                                                                                                                               |
|           7 | Gemini 3 Flash  | Fill Blank      |      10 |      1.71 | Excellent task. It tests a key advanced B2 grammar point (the adverbial participle, '–¥–µ–µ–ø—Ä–∏—á–∞—Å—Ç–∏–µ') within a formal, relevant context ('experts', 'bill', 'economy'). The vocabulary is appropriate for the level, and the answer is completely deterministic, making it a high-quality assessment item.                                                                                                                                                                                                                                                                     |
|           7 | Llama 4         | Multiple Choice |       5 |      1.47 | This task is well-formed but the level is incorrect. Testing adjective-noun agreement in the instrumental case is a fundamental skill taught at A2/B1 levels. It does not challenge a B2 learner or reflect the proficiency described in the prompt (writing clear, detailed text on a wide range of subjects).                                                                                                                                                                                                                                                              |
|           7 | Llama 4         | Fill Blank      |       9 |      0.55 | A very strong candidate that directly reflects the B2 writing skills described in the prompt (arguing a point of view). The vocabulary is highly appropriate. The task is slightly less deterministic than others, as '–æ—Ç—Å—Ç–∞–∏–≤–∞—é' (I defend) could be a possible alternative, but '–∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä—É—é' is the best fit for the provided hint.                                                                                                                                                                                                                                      |
|           7 | Mistral Large 3 | Multiple Choice |       5 |      2.53 | The task tests the formation of unreal conditional sentences, a valid B2 grammar point. However, it violates a strict guideline by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:') directly in the 'question' field. The prompt explicitly stated 'Do not include any instructions for the task' and 'The task must consist of a single sentence'.                                                                                                                                                                                      |
|           7 | Mistral Large 3 | Fill Blank      |       5 |      1.41 | The task is grammatically correct and deterministic. However, the difficulty level is too low for B2. Testing '—Ä–µ—à–∏–ª–∏ –ø–æ–π—Ç–∏' (decided to go) is more appropriate for A2 or B1 levels and does not reflect the complexity of writing essays or reports as described in the prompt.                                                                                                                                                                                                                                                                                            |
|           7 | Qwen 3 Max      | Multiple Choice |       6 |      5.82 | The task is grammatically sound, but its difficulty is more aligned with the B1 level than B2. Choosing between perfective and imperfective aspect for a single, completed past action is a foundational skill consolidated at B1. A B2 task should test a more complex or nuanced application of aspect or grammar.                                                                                                                                                                                                                                                         |
|           7 | Qwen 3 Max      | Fill Blank      |      10 |      3.9  | Excellent task. It perfectly matches the B2 level by using a professional context (report for management) and testing a key collocation ('–æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ'). The question is unambiguous and has a single correct answer. The inclusion of '(–∞)' to account for gender is a thoughtful detail.                                                                                                                                                                                                                                                                             |
|           8 | GPT-5.2         | Multiple Choice |       7 |     16.58 | The candidate created a linguistically sound task appropriate for the B2 level, testing future tense and aspect in a complex sentence. However, it violates several strict guidelines: 1) Guideline 7 is violated by including an English translation '(will accept)' in the question. 2) The JSON format for the 'correctAnswer' field is a string, not an array as specified in the example schema. 3) The inclusion of non-sentence text violates Guideline 1.                                                                                                            |
|           8 | GPT-5.2         | Fill Blank      |       8 |      1.87 | This is a strong candidate. The vocabulary ('–∏–∑–ª–æ–∂–∏–ª') and the context (writing a report to persuade management) are perfectly aligned with the B2 level description. The sentence is natural and grammatically correct. The main weakness is that it doesn't fully adhere to the 'only one correct answer' rule. Verbs like '–ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª' (presented) or '–æ–ø–∏—Å–∞–ª' (described) would also fit the sentence, creating ambiguity.                                                                                                                                               |
|           8 | Gemini 3 Flash  | Multiple Choice |      10 |      1.72 | This is an outstanding task that perfectly aligns with the B2 level. The sentence structure is complex, the vocabulary is advanced and formal ('–æ—Ç—á—ë—Ç', '–ø—Ä–æ–¥–µ–ª–∞–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞'), and the question requires a nuanced understanding of verb government and aspect. It directly tests skills needed for writing reports as described in the proficiency description. The only minor issue is the 'correctAnswer' being a string and not an array, but the overall quality of the linguistic task is superior to all other candidates and best fulfills the spirit of the prompt. |
|           8 | Gemini 3 Flash  | Fill Blank      |       9 |      1.96 | An excellent task that aligns perfectly with the B2 level. The vocabulary ('–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å') and the collocation ('–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å —Å–≤–æ—é —Ç–æ—á–∫—É –∑—Ä–µ–Ω–∏—è') are highly relevant. The context, concerning an author justifying a viewpoint in an article, directly matches the prompt's description. Although a close synonym ('–∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å') exists, the chosen answer '–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å' is the most precise fit for the English hint '(justify)' and the adverb '—É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ' (convincingly), making it the most well-constrained and high-quality task among the candidates.              |
|           8 | Llama 4         | Multiple Choice |       6 |      0.53 | The candidate followed the JSON format instructions perfectly. However, the task itself is weak. The concept being tested (imperfective aspect for repeated past actions marked by '—á–∞—Å—Ç–æ') is more characteristic of the B1 level, not B2. Additionally, one of the distractors, '–≤—Å—Ç—Ä–µ—á–∞–ª—Å—è —Å —É—Ç—Ä–∞', is poorly constructed as it's not parallel to the other options and creates an awkward sentence, testing parsing rather than a specific grammar point.                                                                                                                |
|           8 | Llama 4         | Fill Blank      |       5 |      0.52 | This task is too simple for the B2 level, feeling more like a B1 grammar exercise on verb aspects. The context is generic and doesn't align with the prompt's focus on writing reports or essays. The most significant issue is the violation of the single-answer rule; '—É—á–∏—Ç—å' (imperfective aspect) and '–∑–Ω–∞—Ç—å' (to know) are also perfectly correct and logical answers in this context.                                                                                                                                                                                 |
|           8 | Mistral Large 3 | Multiple Choice |       9 |      2.6  | This is an excellent B2-level task testing the unreal conditional mood, a key competency for this level. The JSON format is perfect, including the 'correctAnswer' as an array. The only flaw is a clear violation of Guideline 9 ('Do not include any instructions for the task'), as the question string begins with '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:'.                                                                                                                                                                                          |
|           8 | Mistral Large 3 | Fill Blank      |       6 |      1.88 | The task is grammatically correct, but its complexity is more suited for a B1 level rather than B2. The vocabulary (verbs of motion) is typically mastered at a lower level. The context of 'going for a walk' does not reflect the specified B2 writing skills. Furthermore, it violates the single-answer constraint, as '–æ—Ç–ø—Ä–∞–≤–∏—Ç—å—Å—è' (to set off) is an equally valid answer.                                                                                                                                                                                            |
|           8 | Qwen 3 Max      | Multiple Choice |       9 |      4.79 | The candidate produced a high-quality B2-level task that effectively tests verb government ('—É–¥–∞–ª–æ—Å—å' + infinitive) and aspectual choice (perfective for a completed action). The context is appropriate and the distractors are well-chosen. It follows all guidelines except for a minor formatting error: 'correctAnswer' is a string instead of an array as shown in the instruction's example.                                                                                                                                                                          |
|           8 | Qwen 3 Max      | Fill Blank      |       5 |      2.67 | While the context of writing a report to express a point of view is appropriate for B2, the task fails significantly on the 'only one correct answer' rule. There are numerous valid, and arguably better, answers like '–æ–±–æ—Å–Ω–æ–≤–∞—Ç—å' (to justify), '–∏–∑–ª–æ–∂–∏—Ç—å' (to state), or '–æ—Ç—Å—Ç–æ—è—Ç—å' (to defend). The chosen answer, '–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å' (to support), is not the most idiomatic choice in this specific collocation.                                                                                                                                                            |
|           9 | GPT-5.2         | Multiple Choice |       8 |     18.21 | A well-constructed task that is grammatically accurate and suitable for the B2 level, testing verb forms in a relevant context. It adheres to most guidelines. Points are deducted for minor JSON format deviations: `correctAnswer` is a string instead of an array, and an extra `translation` field was included, which was not part of the final requested schema.                                                                                                                                                                                                       |
|           9 | GPT-5.2         | Fill Blank      |      10 |      1.84 | This is an excellent task for the B2 level. The sentence structure ('–•–æ—Ç—è..., ...') is appropriately complex. The vocabulary ('–¥–æ–∫–ª–∞–¥', '–≤—ã–≤–æ–¥—ã') aligns with the B2 skill of writing reports. Most importantly, it tests a key grammatical point for this level: the use of the instrumental case after the verb '–æ–∫–∞–∑–∞—Ç—å—Å—è'. The answer is unambiguous and the task is natural.                                                                                                                                                                                            |
|           9 | Gemini 3 Flash  | Multiple Choice |       9 |      2    | An outstanding task that aligns perfectly with the B2 level description, testing knowledge of collocations ('–∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –ø–æ–ª—å–∑—É') within a formal context. The vocabulary and scenario are highly appropriate for the level. It follows all major guidelines, with a minor point off for incorrect JSON formatting of the `correctAnswer` field (string instead of array).                                                                                                                                                                                                   |
|           9 | Gemini 3 Flash  | Fill Blank      |      10 |      1.12 | An outstanding task that perfectly aligns with the B2 level description. It uses a complex sentence structure ('...–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ —á—Ç–æ...'), advanced academic vocabulary ('–∞—Ä–≥—É–º–µ–Ω—Ç–∏—Ä—É–µ—Ç', '–ø–æ–∑–∏—Ü–∏—è', '–æ—Å–ø–∞—Ä–∏–≤–∞—é—Ç'), and a context directly related to argumentation and expressing points of view. The verb '–æ—Å–ø–∞—Ä–∏–≤–∞—é—Ç' is a precise, high-level vocabulary choice.                                                                                                                                                                                                        |
|           9 | Llama 4         | Multiple Choice |       1 |      1.1  | This candidate fundamentally misunderstood the prompt. Instead of creating a language learning task to test proficiency, it generated a meta-linguistic question about grammatical theory. This does not assess a user's ability to use Russian as required. It also violated the 'no instructions' rule.                                                                                                                                                                                                                                                                    |
|           9 | Llama 4         | Fill Blank      |       9 |      0.4  | This is a very good task that tests the common and important collocation '—É–¥–µ–ª—è—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ' (to pay attention). Mastery of such set phrases is a key indicator of B2 proficiency. The context of business is relevant, and the use of '–í –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è' correctly signals the imperfective aspect, making the answer unambiguous.                                                                                                                                                                                                                                          |
|           9 | Mistral Large 3 | Multiple Choice |       7 |      2.56 | The linguistic task itself is excellent, perfectly targeting a key B2 grammar point (subjunctive mood with verb aspect). The JSON format is also correct. However, it scores lower because it directly violates a strict negative constraint by including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') within the 'question' field.                                                                                                                                                                                                                                       |
|           9 | Mistral Large 3 | Fill Blank      |       7 |      1.88 | The task is grammatically correct and natural. The structure '–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞...' is suitable for B2. However, the core challenge ‚Äî choosing the perfective infinitive '–ø–æ–π—Ç–∏' after '—Ä–µ—à–∏–ª–∏' ‚Äî is a concept often mastered at the B1 level. While verbs of motion are complex, this particular task doesn't fully challenge a B2 learner's writing skills as described in the prompt.                                                                                                                                                                                           |
|           9 | Qwen 3 Max      | Multiple Choice |       9 |      4.15 | An excellent task that tests a nuanced understanding of verb aspect in a subordinate clause, which is a hallmark of the B2 level. The context is natural and the options are well-chosen. It follows nearly all instructions perfectly, with only a minor deduction for the `correctAnswer` field being a string instead of the requested array format.                                                                                                                                                                                                                      |
|           9 | Qwen 3 Max      | Fill Blank      |       9 |      3.89 | A very strong candidate. The topic (climate change, renewable energy) is highly relevant for B2-level discussions. The task effectively tests the important collocation '–∏–≥—Ä–∞—Ç—å —Ä–æ–ª—å' (to play a role), which is crucial for producing more natural and advanced text. The vocabulary is appropriate and the answer is deterministic.                                                                                                                                                                                                                                        |
|          10 | GPT-5.2         | Multiple Choice |       8 |     26.51 | The task correctly tests the use of conjunctions to show contrast, which is a B2 skill. The sentence is natural and the context is clear. It loses points for two reasons: the difficulty is on the lower end of B2, and the `correctAnswer` field is a string instead of an array, which does not match the format specified in the prompt's example.                                                                                                                                                                                                                       |
|          10 | GPT-5.2         | Fill Blank      |       6 |      1.47 | The task's context (writing a report) and vocabulary ('–∏–∑–ª–æ–∂–∏–ª') are well-suited for the B2 level. However, it violates the strict non-ambiguity rule, as several other verbs like '–æ–±—ä—è—Å–Ω–∏–ª' (explained) or '–æ–ø–∏—Å–∞–ª' (described) are also perfectly valid. Furthermore, the answer only includes the masculine form ('–∏–∑–ª–æ–∂–∏–ª'), omitting the necessary feminine counterpart ('–∏–∑–ª–æ–∂–∏–ª–∞').                                                                                                                                                                                  |
|          10 | Gemini 3 Flash  | Multiple Choice |       9 |      1.89 | This is a high-quality, challenging task that perfectly aligns with B2+ proficiency. It tests the agreement and case of participles within a complex sentence, a skill essential for writing the 'clear, detailed text' mentioned in the level description. The vocabulary and context are sophisticated. It loses one point only for the minor formatting error of providing `correctAnswer` as a string instead of an array.                                                                                                                                               |
|          10 | Gemini 3 Flash  | Fill Blank      |       3 |      1.14 | While the task aims for an appropriate B2/C1 level of complexity, it contains a major grammatical error. The proposed answer '–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç' (contradicts) is incompatible with the preposition '—Å' used in the sentence. The verb '–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç—å' governs the dative case without a preposition. This fundamental flaw makes the task incorrect as presented.                                                                                                                                                                                                                |
|          10 | Llama 4         | Multiple Choice |      10 |      2    | This candidate perfectly adheres to all instructions. The JSON is valid and strictly follows the specified format, including the `correctAnswer` field as an array. The task itself is a solid B2-level question that tests verb aspect after a modal verb ('–Ω—É–∂–Ω–æ') within a clause of purpose, a key skill for this level. The context is clear and the distractors are appropriate.                                                                                                                                                                                       |
|          10 | Llama 4         | Fill Blank      |       8 |      1.5  | This is the best candidate. It effectively tests a B2-level grammatical structure (passive voice with a modal verb) on a relevant topic. While '–º–æ–≥—É—Ç' (can) is a possible alternative, the context and the English hint '(must)' strongly point to '–¥–æ–ª–∂–Ω—ã' as the single intended answer, making it the least ambiguous of the options. The task is well-constructed and level-appropriate.                                                                                                                                                                                |
|          10 | Mistral Large 3 | Multiple Choice |       5 |      2.34 | While the linguistic task itself is excellent, testing a common but difficult point of Russian grammar (verbs of motion and aspect), the candidate failed to follow a strict guideline. It explicitly violates guideline #9 ('Do not include any instructions for the task') by including '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:' in the question field. This is a significant deviation from the instructions.                                                                                                                                          |
|          10 | Mistral Large 3 | Fill Blank      |       4 |      1.67 | The task is grammatically correct but is too simple for the B2 level; choosing a verb of motion in this context is typically an A2/B1 skill. Most importantly, it fails the non-ambiguity requirement, as '–ø–æ–π—Ç–∏' (to go) and '–æ—Ç–ø—Ä–∞–≤–∏—Ç—å—Å—è' (to set off) are equally correct and common alternatives to '–≤—ã–π—Ç–∏'.                                                                                                                                                                                                                                                             |
|          10 | Qwen 3 Max      | Multiple Choice |       9 |      7.04 | This is an excellent B2-level task. It tests verb aspect following a specific construction ('—É–¥–∞–ª–æ—Å—å' + infinitive) within a complex sentence, which is highly appropriate for the level. The vocabulary and grammar are well-chosen. The only flaw is a minor formatting error where `correctAnswer` is provided as a string instead of an array.                                                                                                                                                                                                                           |
|          10 | Qwen 3 Max      | Fill Blank      |       7 |      3.26 | This is a strong submission that aligns excellently with the B2 level description, using a relevant context (writing a letter) and correctly providing both gender forms for the answer. However, it fails the strict non-ambiguity rule, as '—Ä–∞—Å—Å–∫–∞–∑–∞–ª(–∞)' (told/narrated) is a very common and perfectly suitable alternative to '–æ–±—ä—è—Å–Ω–∏–ª(–∞)' (explained).                                                                                                                                                                                                                |
|          11 | GPT-5.2         | Multiple Choice |       7 |     13.81 | The task is a good B2-level grammar question testing prepositional cases. However, it violates a guideline by including an English translation in the question, likely due to a contradictory instruction in the original prompt. Additionally, the `correctAnswer` format is a string instead of an array as specified in the prompt's description.                                                                                                                                                                                                                         |
|          11 | GPT-5.2         | Fill Blank      |       8 |      1.74 | The task is excellent for the B2 level, with a context (writing a report) and vocabulary ('–∞—Ä–≥—É–º–µ–Ω—Ç—ã', '–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ') that perfectly match the proficiency description. It tests the specific construction '–≤ –ø–æ–ª—å–∑—É' (in favor of). However, it loses points because there are other equally valid answers, such as '–∑–∞' or '–≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É', which were not included in the 'correctAnswer' array, thus violating the instruction about deterministic answers.                                                                                                                  |
|          11 | Gemini 3 Flash  | Multiple Choice |      10 |      1.38 | An outstanding task that directly tests vocabulary for academic writing, a core component of the B2 level description ('writing an essay', 'giving reasons'). It follows all non-contradictory instructions perfectly, uses appropriate formal vocabulary, and has clear, well-differentiated options. The only minor deviation is the `correctAnswer` format (string vs. array).                                                                                                                                                                                            |
|          11 | Gemini 3 Flash  | Fill Blank      |      10 |     11.92 | This is an outstanding task that perfectly meets all criteria. The topic (global warming) and vocabulary ('–≤—ã–±—Ä–æ—Å—ã', '—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ') are appropriate for a B2+ level. It tests a specific and useful verb-preposition combination ('–Ω–∞—Å—Ç–∞–∏–≤–∞—Ç—å –Ω–∞' - to insist on) that is key for expressing opinions and arguments. The answer is unambiguous, and the sentence is natural and well-formed.                                                                                                                                                                                  |
|          11 | Llama 4         | Multiple Choice |       9 |      0.52 | A very good B2-level task testing vocabulary and collocations ('—Å–æ–≤–µ—Ä—à–∞—Ç—å –ø—Ä–æ–≥—É–ª–∫–∏'). It follows all instructions, including the specified array format for the correct answer. The task has clear options and a natural context, targeting common learner errors effectively.                                                                                                                                                                                                                                                                                               |
|          11 | Llama 4         | Fill Blank      |       4 |      0.37 | The task is grammatically correct and the answer is unambiguous. However, the level is incorrect. Testing the difference between '—Ö–æ–∂—É' and '–∏–¥—Ç–∏' (verbs of motion) is a classic A2 or B1 level grammar point. The context and vocabulary are too simple for a B2 learner, failing to meet the requirements of the prompt.                                                                                                                                                                                                                                                  |
|          11 | Mistral Large 3 | Multiple Choice |       6 |      2.32 | The task itself is a valid B2-level grammar question on the conditional mood. However, it receives a lower score for failing to follow a strict guideline: it includes instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') in the 'question' field, which was explicitly forbidden.                                                                                                                                                                                                                                                                                              |
|          11 | Mistral Large 3 | Fill Blank      |       6 |      3.3  | The task is grammatically correct, and the sentence is natural. It correctly tests Russian verb aspect after the verb '—Ä–µ—à–∏—Ç—å'. However, the topic and vocabulary are more suited for a B1 level rather than B2. It does not reflect the complexity described in the B2 writing skills (essays, reports, argumentation). Additionally, '–æ—Ç–ø—Ä–∞–≤–∏—Ç—å—Å—è' is another possible correct answer that was not listed.                                                                                                                                                                 |
|          11 | Qwen 3 Max      | Multiple Choice |       9 |      4.61 | Excellent task. It adheres to all guidelines, presenting a B2-level vocabulary question on collocations. The context of 'getting a job' described in a letter aligns well with the CEFR level description. The `correctAnswer` format is a string instead of an array, which is a minor format deviation.                                                                                                                                                                                                                                                                    |
|          11 | Qwen 3 Max      | Fill Blank      |       5 |      2.77 | While the task attempts to use a B2-level context (report, arguments, project), the collocation '–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å —Å–≤–æ–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã' (to support one's arguments) is slightly unnatural in Russian. A more natural verb choice would be '–ø–æ–¥–∫—Ä–µ–ø–∏—Ç—å' (to reinforce). This unnatural phrasing makes the task confusing and less effective for assessment.                                                                                                                                                                                                                              |
|          12 | GPT-5.2         | Multiple Choice |      10 |      9.98 | Excellent task that perfectly aligns with the B2 level. It tests a key grammatical concept (passive vs. active participles) within a formal context ('report', 'data', 'experts'), which is relevant to the writing skills described in the prompt. The distractors are well-chosen and test for common errors. It adheres to all instructions.                                                                                                                                                                                                                              |
|          12 | GPT-5.2         | Fill Blank      |      10 |      5.96 | The candidate provides a high-quality task that is fully compliant with all instructions. The sentence structure `–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ —á—Ç–æ... –º–Ω–µ —É–¥–∞–ª–æ—Å—å...` is complex and highly appropriate for the B2 level. The chosen vocabulary is specific and the task is unambiguous, making it an excellent measure of both grammatical and lexical proficiency.                                                                                                                                                                                                                       |
|          12 | Gemini 3 Flash  | Multiple Choice |      10 |      1.22 | An outstanding task that exemplifies the B2 level. It tests nuanced vocabulary by focusing on paronyms (verbs with different prefixes but the same root), a common challenge for advanced learners. The formal business context is perfectly aligned with the B2 proficiency description (writing reports, essays). It follows all instructions flawlessly.                                                                                                                                                                                                                  |
|          12 | Gemini 3 Flash  | Fill Blank      |       8 |      1.03 | This candidate created a task with an excellent topic and advanced vocabulary (`–≤–µ—Å–æ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã`, `–≤ –∑–∞—â–∏—Ç—É —Å–≤–æ–µ–π –ø–æ–∑–∏—Ü–∏–∏`) that perfectly matches the B2 skill description of writing essays and giving reasons. However, the task violates the 'only one correct answer' guideline. The verb `–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å` is an equally valid and common synonym for `–ø—Ä–∏–≤–µ—Å—Ç–∏` in this context but was not included in the `correctAnswer` array. This ambiguity detracts from the task's quality.                                                                                     |
|          12 | Llama 4         | Multiple Choice |       2 |      1.03 | This candidate fundamentally fails to meet the requirements. It includes instructions in the 'question' field. More importantly, it creates a subjective, open-ended question ('choose the best continuation') with no single deterministic correct answer; all options are logically plausible reasons. This violates the core principle of a deterministic language task.                                                                                                                                                                                                  |
|          12 | Llama 4         | Fill Blank      |      10 |      0.53 | Excellent task that is very similar in quality and grammatical focus to Candidate 3. It correctly identifies a key B2-level grammar point (tense/aspect usage for ongoing actions) and places it in a relevant, professional context. The task is clear, accurate, and unambiguous.                                                                                                                                                                                                                                                                                          |
|          12 | Mistral Large 3 | Multiple Choice |       4 |      2.43 | Fails to follow key instructions. It includes explicit instructions in the 'question' field ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...'), violating a negative constraint. Furthermore, the vocabulary tested ('—Å–ª–∏—à–∫–æ–º') is more appropriate for an A2/B1 level, not the requested B2.                                                                                                                                                                                                                                                                                                |
|          12 | Mistral Large 3 | Fill Blank      |       8 |      1.8  | The task is valid and tests relevant vocabulary (`—É–ø—Ä–∞–≤–ª—è—Ç—å`) for the B2 level. However, the overall sentence structure is somewhat simpler compared to other candidates. While a good task, it borders on the B1 level and is less challenging than what a B2 learner should be able to handle.                                                                                                                                                                                                                                                                             |
|          12 | Qwen 3 Max      | Multiple Choice |       8 |      6.43 | A good and compliant task. It correctly tests vocabulary (verb collocation) in a complex sentence relevant to the level description ('received a letter... described in detail'). The level is appropriate for B2, though the core collocation '–ø—Ä–µ–æ–¥–æ–ª–µ—Ç—å —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏' might be familiar to some B1 learners, making it slightly less challenging than other top candidates.                                                                                                                                                                                                  |
|          12 | Qwen 3 Max      | Fill Blank      |      10 |      3.12 | This is an exemplary task. It perfectly tests a core grammatical concept for the B2 level: the use of the imperfective present tense to describe an action that has been ongoing for a period of time. The sentence is natural, the answer is unambiguous, and the context is relatable.                                                                                                                                                                                                                                                                                     |
|          13 | GPT-5.2         | Multiple Choice |       8 |     20.77 | The task is well-designed, level-appropriate (B2), and deterministic. It correctly tests the use of discourse markers ('–æ–¥–Ω–∞–∫–æ') in a relevant business context, which aligns with the B2 skill of writing reports. The JSON format is correct. A minor deduction is made because including the question and its translation within the 'question' field is slightly awkward, though it is a reasonable interpretation of the instructions.                                                                                                                                  |
|          13 | GPT-5.2         | Fill Blank      |       9 |      1.93 | The task is very well-constructed and appropriate for the B2 level. It uses a complex sentence structure within a formal context (a report), which aligns perfectly with the CEFR description provided. The required phrase '—Ä–µ—à–∏–ª–∏ –æ—Ç–∫–∞–∑–∞—Ç—å—Å—è' tests both vocabulary and grammar (aspect and modality). The task is accurate, natural-sounding, and has a deterministic answer. It's an excellent example of a B2-level task.                                                                                                                                               |
|          13 | Gemini 3 Flash  | Multiple Choice |       9 |      1.25 | This is an excellent task that perfectly aligns with the B2 level and the prompt's description of writing skills ('–∏–∑–ª–∞–≥–∞—Ç—å —Å–≤–æ—é –ø–æ–∑–∏—Ü–∏—é –≤ —ç—Å—Å–µ'). It tests a clear and important grammatical point (use of the infinitive after '–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ') with well-chosen distractors. The answer is deterministic and the context is highly relevant. The only minor flaw is the failure to include a small English translation as requested by the original instructions.                                                                                                            |
|          13 | Gemini 3 Flash  | Fill Blank      |      10 |      1.26 | This is a perfect B2-level task. It tests the knowledge of a fixed prepositional phrase, '–≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É', which is crucial for formal and argumentative writing. This aligns directly with the B2 skill description 'giving reasons in support of or against a particular point of view'. The task is concise, unambiguous, and tests a key piece of vocabulary for academic and formal contexts.                                                                                                                                                                              |
|          13 | Llama 4         | Multiple Choice |       2 |      0.74 | This candidate completely fails to create a valid language task. The question is not deterministic; all options are grammatically correct and plausible continuations of the long, convoluted sentence. It does not test a specific language skill but rather asks the user to guess an arbitrary detail. This violates the core requirement for a clear objective and a single correct answer.                                                                                                                                                                              |
|          13 | Llama 4         | Fill Blank      |       6 |      0.66 | The candidate provides a valid JSON and a grammatically correct sentence. However, the grammatical point being tested‚Äîthe use of the present imperfective tense with '–≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è'‚Äîis more appropriate for the B1 level. A B2 learner is expected to have already mastered this. The task does not challenge the complex writing skills specified for the B2 level.                                                                                                                                                                                                    |
|          13 | Mistral Large 3 | Multiple Choice |       5 |      2.54 | The candidate fails on several instructions. It includes explicit instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...'), which was forbidden. It also fails to provide any English translation. While the grammar point (subjunctive mood) is relevant, the task's difficulty is borderline B1/B2, and the context is very simple. The format is correct, but the instruction-following is poor.                                                                                                                                                                                   |
|          13 | Mistral Large 3 | Fill Blank      |       6 |      1.63 | While the format is correct and the sentence is grammatically sound, the task itself is too simple for the B2 level. The structure '—Ä–µ—à–∏–ª–∏ + perfective infinitive' (—Ä–µ—à–∏–ª–∏ –ø–æ–π—Ç–∏) is typically mastered at the A2 or B1 level. It does not test the specific B2 writing skills mentioned in the prompt, such as constructing complex arguments or writing detailed reports.                                                                                                                                                                                                 |
|          13 | Qwen 3 Max      | Multiple Choice |       3 |      3.34 | This task is fundamentally flawed because it is not deterministic. The choice between '–ø–æ—à—ë–ª' and '—Ö–æ–¥–∏–ª' (verbs of motion) is highly context-dependent, and in this sentence, '—Ö–æ–¥–∏–ª' could also be argued as the correct answer, representing a completed round trip. A multiple-choice question must have a single, unambiguously correct answer. This ambiguity makes it a poor assessment item.                                                                                                                                                                         |
|          13 | Qwen 3 Max      | Fill Blank      |      10 |      3    | This is an outstanding candidate. The task tests the use of a past adverbial participle ('–æ–±–æ–±—â–∏–≤'), which is an advanced grammatical structure characteristic of sophisticated B2/C1 writing. The context of summarizing findings in a report directly corresponds to the writing skills described in the original instruction. The task is unambiguous, accurate, and highly relevant.                                                                                                                                                                                     |
|          14 | GPT-5.2         | Multiple Choice |       8 |     20.46 | The task is well-designed and appropriate for the B2 level, testing the use of complex linking words ('–ø—Ä–∏ —ç—Ç–æ–º') in a formal context, which aligns with the writing skills described. The grammar is accurate, and the distractors are plausible. However, it slightly violates the instruction to avoid including instructions by adding '–ö–∞–∫–∞—è —Ñ—Ä–∞–∑–∞ –¥–æ–ª–∂–Ω–∞ —Å—Ç–æ—è—Ç—å –Ω–∞ –º–µ—Å—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏' to the 'question' field.                                                                                                                                              |
|          14 | GPT-5.2         | Fill Blank      |       8 |      1.36 | The task is excellent in terms of level-appropriateness. The vocabulary ('–æ—Ç—á—ë—Ç', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ') and the context (writing a report) directly align with the B2 proficiency description. The main flaw is that it violates guideline #9. For the subject '—è' (I), the past tense verb could be masculine ('–æ–±–æ–±—â–∏–ª') or feminine ('–æ–±–æ–±—â–∏–ª–∞'). The 'correctAnswer' array should have included both forms.                                                                                                                                                     |
|          14 | Gemini 3 Flash  | Multiple Choice |      10 |      1.34 | This is an excellent B2-level task. It tests a nuanced grammatical point: the difference between a participial adjective modifying a noun ('–∞—Ä–≥—É–º–µ–Ω—Ç—ã, –æ–±–æ—Å–Ω–æ–≤—ã–≤–∞—é—â–∏–µ...') and an adverbial participle. This is a key skill for constructing complex, precise sentences in formal writing, directly aligning with the level description. The context ('–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç') is perfect, the options are well-chosen, and all instructions have been followed meticulously.                                                                                                  |
|          14 | Gemini 3 Flash  | Fill Blank      |      10 |      1.49 | This is an outstanding submission that perfectly adheres to all guidelines. The task is deterministic with only one correct answer. The vocabulary ('–≥–ª–æ–±–∞–ª—å–Ω–æ–µ –ø–æ—Ç–µ–ø–ª–µ–Ω–∏–µ', '–ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è', '–Ω–µ–æ–±—Ä–∞—Ç–∏–º—ã–º–∏', '–ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π') is advanced and perfectly suited for the B2 level. The grammatical point being tested (the use of '–µ—Å–ª–∏... –Ω–µ' for 'unless') is subtle and appropriate for B2. The context is complex and relevant.                                                                                                                          |
|          14 | Llama 4         | Multiple Choice |       2 |      1.65 | This candidate has two major flaws. First, the task level is A2/B1, testing basic adjectival agreement in the instrumental case, which is far below the B2 standard. Second, it violates the instructions by providing duplicate options ('–æ–≥—Ä–æ–º–Ω—ã–º–∏' appears twice), making the choice ambiguous and the task poorly constructed.                                                                                                                                                                                                                                           |
|          14 | Llama 4         | Fill Blank      |       5 |      1.5  | This task has two significant issues. First, it violates guideline #7 regarding ambiguity. The verb '–ø—ã—Ç–∞–ª—Å—è' is a direct synonym for '—Å—Ç–∞—Ä–∞–ª—Å—è' in this context and would be an equally correct answer. Second, it fails to adhere to guideline #9 by not including the feminine form '—Å—Ç–∞—Ä–∞–ª–∞—Å—å' in the array of correct answers.                                                                                                                                                                                                                                          |
|          14 | Mistral Large 3 | Multiple Choice |       4 |      2.87 | The task explicitly violates the guideline 'Do not include any instructions for the task' by starting the question with '–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:'. Furthermore, the grammatical point being tested (future tense agreement with '–º–Ω–æ–≥–æ –¥–µ–ª') is at an A2/B1 level, making it too simple for the specified B2 proficiency.                                                                                                                                                                                                                  |
|          14 | Mistral Large 3 | Fill Blank      |       6 |      1.46 | The task is grammatically correct and unambiguous. However, it does not meet the B2 level requirement. The vocabulary ('–ø–æ–≥–æ–¥–∞', '–ø—Ä–æ–≥—É–ª–∫–∞') and the grammatical structure (verb of motion after '—Ä–µ—à–∏—Ç—å') are typically mastered at the B1 level. The context is too simple for a B2 learner described as being able to write essays and reports.                                                                                                                                                                                                                           |
|          14 | Qwen 3 Max      | Multiple Choice |       2 |      4.73 | The task is fundamentally flawed. The provided correct answer, '—Å–ø—Ä–∞–≤–∏—Ç—å—Å—è', is grammatically incorrect in the given sentence, as it requires the preposition '—Å' and the instrumental case, not the accusative case ('—Å–ª–æ–∂–Ω—É—é —Å–∏—Ç—É–∞—Ü–∏—é'). Another option, '—Ä–∞–∑—Ä–µ—à–∏—Ç—å', fits perfectly, making the task incorrect and confusing. The core idea of testing vocabulary nuance is good, but the execution is poor.                                                                                                                                                              |
|          14 | Qwen 3 Max      | Fill Blank      |       7 |      3.23 | This candidate successfully uses a context ('–Ω–∞–ø–∏—Å–∞–ª –ø–∏—Å—å–º–æ, –≤ –∫–æ—Ç–æ—Ä–æ–º...') that is directly from the B2 level description. The vocabulary is appropriate. However, like Candidate 1, it fails to provide both possible gender forms for the past tense verb ('–æ–±—ä—è—Å–Ω–∏–ª' and '–æ–±—ä—è—Å–Ω–∏–ª–∞'), violating guideline #9. Additionally, another verb like '—Ä–∞—Å—Å–∫–∞–∑–∞–ª' (told) could also fit, creating slight ambiguity.                                                                                                                                                             |
|          15 | GPT-5.2         | Multiple Choice |       8 |     11.39 | A strong candidate that follows the instructions well. The task tests a key B2 grammar point (verb aspect) within a relevant context (writing a report). The question is clear, and the options are well-constructed. It successfully avoids including instructions in the question field, adhering to a key negative constraint.                                                                                                                                                                                                                                            |
|          15 | GPT-5.2         | Fill Blank      |       8 |      1.35 | The task correctly tests a key B2 grammar point (verb aspect). The sentence structure and vocabulary are appropriate for the level. However, the answer is not strictly unique as instructed; another perfective verb like '–∑–∞–≤–µ—Ä—à–∏—Ç—å' (a more formal synonym) would also be grammatically correct in this context, making the question slightly ambiguous.                                                                                                                                                                                                                  |
|          15 | Gemini 3 Flash  | Multiple Choice |      10 |      1.42 | This is an outstanding candidate that perfectly matches all requirements. The task, which tests vocabulary and prepositional government ('–∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –ø–æ–ª—å–∑—É'), is highly relevant to the B2 level, particularly the skill of presenting arguments in a report. The vocabulary is level-appropriate and sophisticated. The submission adheres strictly to all formatting and content guidelines, making it the best of the set.                                                                                                                                              |
|          15 | Gemini 3 Flash  | Fill Blank      |      10 |      1.08 | An outstanding task that aligns perfectly with the B2 proficiency description. It uses formal, academic language ('–ü—Ä–∏–Ω–∏–º–∞—è –≤–æ –≤–Ω–∏–º–∞–Ω–∏–µ', '–ø—Ä–∏—Ö–æ–¥–∏—Ç –∫ –≤—ã–≤–æ–¥—É') and tests both vocabulary and grammar (genitive case in a comparative construction). The complex sentence structure and context make it an ideal B2-level question.                                                                                                                                                                                                                                           |
|          15 | Llama 4         | Multiple Choice |       2 |      2.38 | This candidate fails on multiple critical points. The task is not deterministic and tests logical coherence rather than a specific grammar or vocabulary point, allowing for multiple valid answers. It violates instructions by including a prompt in the 'question' field. Furthermore, the JSON format is incorrect, containing a redundant and improperly structured nested field.                                                                                                                                                                                       |
|          15 | Llama 4         | Fill Blank      |       1 |      0.84 | This candidate fails on two fundamental requirements. Firstly, the JSON format is invalid, containing nested JSON as a string and a duplicate key. Secondly, the linguistic task itself, testing the basic possessive '—É –º–µ–Ω—è –µ—Å—Ç—å', is at an A1 (beginner) level and is completely inappropriate for a B2 learner.                                                                                                                                                                                                                                                          |
|          15 | Mistral Large 3 | Multiple Choice |       6 |      2.79 | The linguistic task itself, testing the conditional mood, is appropriate for the B2 level. The JSON format also correctly interprets an ambiguous instruction regarding the 'correctAnswer' field. However, it is penalized for explicitly including instructions ('–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç...') in the 'question' field, which violates a specific guideline.                                                                                                                                                                                                           |
|          15 | Mistral Large 3 | Fill Blank      |       9 |      2.08 | A very strong task. It effectively tests the distinction between imperfective ('–¥–æ—Å—Ç–∏–≥–∞—Ç—å') and perfective verb aspects, a core B2 skill. The context makes the choice of the imperfective aspect for a general truth unambiguous. The topic and vocabulary are well-suited for the B2 level.                                                                                                                                                                                                                                                                                |
|          15 | Qwen 3 Max      | Multiple Choice |       9 |      5    | An excellent candidate that adheres to all instructions. The complex sentence structure, testing the use of the infinitive after '—É–¥–∞–ª–æ—Å—å', is perfectly suited for the B2 level. The context of receiving a letter aligns directly with the proficiency description provided in the prompt. The task is clear, deterministic, and well-formed.                                                                                                                                                                                                                              |
|          15 | Qwen 3 Max      | Fill Blank      |      10 |      2.75 | An excellent task that is perfectly calibrated for the B2 level. It tests the use of adverbial participles ('–¥–µ–µ–ø—Ä–∏—á–∞—Å—Ç–∏—è'), an advanced grammatical structure that is crucial for the formal writing skills described in the proficiency level. The answer is unambiguous and the context is very clear.                                                                                                                                                                                                                                                                    |

